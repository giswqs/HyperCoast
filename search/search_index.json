{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to hypercoast","text":"<p>A Python package for visualizing and analyzing hyperspectral data in coastal regions</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://hypercoast.org</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Interactive visualization and analysis of hyperspectral data (e.g., EMIT, PACE)</li> <li>Interactive extraction and visualization of spectral signatures</li> <li>Saving spectral signatures as CSV files</li> </ul>"},{"location":"#demo","title":"Demo","text":"<ul> <li>Visualizing spectral signature interactively</li> </ul>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>This projects draws inspiration and adapts source code from the nasa/EMIT-Data-Resources repository. Credit goes to the original authors.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"common/","title":"common module","text":"<p>The common module contains common functions and classes used by the other modules.</p>"},{"location":"common/#hypercoast.common.download_file","title":"<code>download_file(url=None, output=None, quiet=False, proxy=None, speed=None, use_cookies=True, verify=True, id=None, fuzzy=False, resume=False, unzip=True, overwrite=False, subfolder=False)</code>","text":"<p>Download a file from URL, including Google Drive shared URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Google Drive URL is also supported. Defaults to None.</p> <code>None</code> <code>output</code> <code>str</code> <p>Output filename. Default is basename of URL.</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>Suppress terminal output. Default is False.</p> <code>False</code> <code>proxy</code> <code>str</code> <p>Proxy. Defaults to None.</p> <code>None</code> <code>speed</code> <code>float</code> <p>Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.</p> <code>None</code> <code>use_cookies</code> <code>bool</code> <p>Flag to use cookies. Defaults to True.</p> <code>True</code> <code>verify</code> <code>bool | str</code> <p>Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string, in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.</p> <code>True</code> <code>id</code> <code>str</code> <p>Google Drive's file ID. Defaults to None.</p> <code>None</code> <code>fuzzy</code> <code>bool</code> <p>Fuzzy extraction of Google Drive's file Id. Defaults to False.</p> <code>False</code> <code>resume</code> <code>bool</code> <p>Resume the download from existing tmp file if possible. Defaults to False.</p> <code>False</code> <code>unzip</code> <code>bool</code> <p>Unzip the file. Defaults to True.</p> <code>True</code> <code>overwrite</code> <code>bool</code> <p>Overwrite the file if it already exists. Defaults to False.</p> <code>False</code> <code>subfolder</code> <code>bool</code> <p>Create a subfolder with the same name as the file. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The output file path.</p> Source code in <code>hypercoast/common.py</code> <pre><code>def download_file(\n    url=None,\n    output=None,\n    quiet=False,\n    proxy=None,\n    speed=None,\n    use_cookies=True,\n    verify=True,\n    id=None,\n    fuzzy=False,\n    resume=False,\n    unzip=True,\n    overwrite=False,\n    subfolder=False,\n):\n    \"\"\"Download a file from URL, including Google Drive shared URL.\n\n    Args:\n        url (str, optional): Google Drive URL is also supported. Defaults to None.\n        output (str, optional): Output filename. Default is basename of URL.\n        quiet (bool, optional): Suppress terminal output. Default is False.\n        proxy (str, optional): Proxy. Defaults to None.\n        speed (float, optional): Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.\n        use_cookies (bool, optional): Flag to use cookies. Defaults to True.\n        verify (bool | str, optional): Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string,\n            in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.\n        id (str, optional): Google Drive's file ID. Defaults to None.\n        fuzzy (bool, optional): Fuzzy extraction of Google Drive's file Id. Defaults to False.\n        resume (bool, optional): Resume the download from existing tmp file if possible. Defaults to False.\n        unzip (bool, optional): Unzip the file. Defaults to True.\n        overwrite (bool, optional): Overwrite the file if it already exists. Defaults to False.\n        subfolder (bool, optional): Create a subfolder with the same name as the file. Defaults to False.\n\n    Returns:\n        str: The output file path.\n    \"\"\"\n    import zipfile\n    import tarfile\n    import gdown\n\n    if output is None:\n        if isinstance(url, str) and url.startswith(\"http\"):\n            output = os.path.basename(url)\n\n    out_dir = os.path.abspath(os.path.dirname(output))\n    if not os.path.exists(out_dir):\n        os.makedirs(out_dir)\n\n    if isinstance(url, str):\n        if os.path.exists(os.path.abspath(output)) and (not overwrite):\n            print(\n                f\"{output} already exists. Skip downloading. Set overwrite=True to overwrite.\"\n            )\n            return os.path.abspath(output)\n        else:\n            url = github_raw_url(url)\n\n    if \"https://drive.google.com/file/d/\" in url:\n        fuzzy = True\n\n    output = gdown.download(\n        url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume\n    )\n\n    if unzip:\n        if output.endswith(\".zip\"):\n            with zipfile.ZipFile(output, \"r\") as zip_ref:\n                if not quiet:\n                    print(\"Extracting files...\")\n                if subfolder:\n                    basename = os.path.splitext(os.path.basename(output))[0]\n\n                    output = os.path.join(out_dir, basename)\n                    if not os.path.exists(output):\n                        os.makedirs(output)\n                    zip_ref.extractall(output)\n                else:\n                    zip_ref.extractall(os.path.dirname(output))\n        elif output.endswith(\".tar.gz\") or output.endswith(\".tar\"):\n            if output.endswith(\".tar.gz\"):\n                mode = \"r:gz\"\n            else:\n                mode = \"r\"\n\n            with tarfile.open(output, mode) as tar_ref:\n                if not quiet:\n                    print(\"Extracting files...\")\n                if subfolder:\n                    basename = os.path.splitext(os.path.basename(output))[0]\n                    output = os.path.join(out_dir, basename)\n                    if not os.path.exists(output):\n                        os.makedirs(output)\n                    tar_ref.extractall(output)\n                else:\n                    tar_ref.extractall(os.path.dirname(output))\n\n    return os.path.abspath(output)\n</code></pre>"},{"location":"common/#hypercoast.common.github_raw_url","title":"<code>github_raw_url(url)</code>","text":"<p>Get the raw URL for a GitHub file.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The GitHub URL.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The raw URL.</p> Source code in <code>hypercoast/common.py</code> <pre><code>def github_raw_url(url):\n    \"\"\"Get the raw URL for a GitHub file.\n\n    Args:\n        url (str): The GitHub URL.\n    Returns:\n        str: The raw URL.\n    \"\"\"\n    if isinstance(url, str) and url.startswith(\"https://github.com/\") and \"blob\" in url:\n        url = url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\n            \"blob/\", \"\"\n        )\n    return url\n</code></pre>"},{"location":"common/#hypercoast.common.netcdf_groups","title":"<code>netcdf_groups(filepath)</code>","text":"<p>Get the list of groups in a NetCDF file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The path to the NetCDF file.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of group names in the NetCDF file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; netcdf_groups('path/to/netcdf/file')\n['group1', 'group2', 'group3']\n</code></pre> Source code in <code>hypercoast/common.py</code> <pre><code>def netcdf_groups(filepath: str) -&gt; List[str]:\n    \"\"\"\n    Get the list of groups in a NetCDF file.\n\n    Args:\n        filepath (str): The path to the NetCDF file.\n\n    Returns:\n        list: A list of group names in the NetCDF file.\n\n    Example:\n        &gt;&gt;&gt; netcdf_groups('path/to/netcdf/file')\n        ['group1', 'group2', 'group3']\n    \"\"\"\n    import h5netcdf\n\n    with h5netcdf.File(filepath) as file:\n        groups = list(file)\n    return groups\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/opengeos/HyperCoast/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>HyperCoast could always use more documentation, whether as part of the official HyperCoast docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/opengeos/HyperCoast/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up HyperCoast for local development.</p> <ol> <li> <p>Fork the HyperCoast repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/HyperCoast.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv HyperCoast\n$ cd HyperCoast/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 HyperCoast tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/opengeos/HyperCoast/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"emit/","title":"emit module","text":"<p>This Module has the functions related to working with an EMIT dataset. This includes doing things like opening and flattening the data to work in xarray, orthorectification, and visualization.</p> <p>Some source code is adapted from https://github.com/nasa/EMIT-Data-Resources. Credits to the original authors, including Erik Bolch, Alex Leigh, and others.</p>"},{"location":"emit/#hypercoast.emit.apply_glt","title":"<code>apply_glt(ds_array, glt_array, fill_value=-9999, GLT_NODATA_VALUE=0)</code>","text":"<p>Applies the GLT array to a numpy array of either 2 or 3 dimensions to orthorectify the data.</p> <p>Parameters:</p> Name Type Description Default <code>ds_array</code> <code>numpy.ndarray</code> <p>A numpy array of the desired variable.</p> required <code>glt_array</code> <code>numpy.ndarray</code> <p>A GLT array constructed from EMIT GLT data.</p> required <code>fill_value</code> <code>int</code> <p>The value to fill in the output array where the GLT array has no data. Defaults to -9999.</p> <code>-9999</code> <code>GLT_NODATA_VALUE</code> <code>int</code> <p>The value in the GLT array that indicates no data. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>A numpy array of orthorectified data.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def apply_glt(ds_array, glt_array, fill_value=-9999, GLT_NODATA_VALUE=0):\n    \"\"\"\n    Applies the GLT array to a numpy array of either 2 or 3 dimensions to orthorectify the data.\n\n    Args:\n        ds_array (numpy.ndarray): A numpy array of the desired variable.\n        glt_array (numpy.ndarray): A GLT array constructed from EMIT GLT data.\n        fill_value (int, optional): The value to fill in the output array where the GLT array has no data. Defaults to -9999.\n        GLT_NODATA_VALUE (int, optional): The value in the GLT array that indicates no data. Defaults to 0.\n\n    Returns:\n        numpy.ndarray: A numpy array of orthorectified data.\n    \"\"\"\n\n    # Build Output Dataset\n    if ds_array.ndim == 2:\n        ds_array = ds_array[:, :, np.newaxis]\n    out_ds = np.full(\n        (glt_array.shape[0], glt_array.shape[1], ds_array.shape[-1]),\n        fill_value,\n        dtype=np.float32,\n    )\n    valid_glt = np.all(glt_array != GLT_NODATA_VALUE, axis=-1)\n\n    # Adjust for One based Index - make a copy to prevent decrementing multiple times inside ortho_xr when applying the glt to elev\n    glt_array_copy = glt_array.copy()\n    glt_array_copy[valid_glt] -= 1\n    out_ds[valid_glt, :] = ds_array[\n        glt_array_copy[valid_glt, 1], glt_array_copy[valid_glt, 0], :\n    ]\n    return out_ds\n</code></pre>"},{"location":"emit/#hypercoast.emit.band_mask","title":"<code>band_mask(filepath)</code>","text":"<p>Unpacks the packed band mask to apply to the dataset. Can be used manually or as an input in the emit_xarray() function.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>An EMIT L2A Mask netCDF file.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>A numpy array that can be used with the emit_xarray function to apply a band mask.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def band_mask(filepath):\n    \"\"\"\n    Unpacks the packed band mask to apply to the dataset. Can be used manually or as an input in the emit_xarray() function.\n\n    Args:\n        filepath (str): An EMIT L2A Mask netCDF file.\n\n    Returns:\n        numpy.ndarray: A numpy array that can be used with the emit_xarray function to apply a band mask.\n    \"\"\"\n    # Open Dataset\n    mask_ds = xr.open_dataset(filepath, engine=\"h5netcdf\")\n    # Open band_mask and convert to uint8\n    bmask = mask_ds.band_mask.data.astype(\"uint8\")\n    # Print Flags used\n    unpacked_bmask = np.unpackbits(bmask, axis=-1)\n    # Remove bands &gt; 285\n    unpacked_bmask = unpacked_bmask[:, :, 0:285]\n    # Check for data bands and build mask\n    return unpacked_bmask\n</code></pre>"},{"location":"emit/#hypercoast.emit.coord_vects","title":"<code>coord_vects(ds)</code>","text":"<p>This function calculates the Lat and Lon Coordinate Vectors using the GLT and Metadata from an EMIT dataset read into xarray.</p> <p>lon, lat (numpy.array): longitute and latitude array grid for the dataset</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def coord_vects(ds):\n    \"\"\"\n    This function calculates the Lat and Lon Coordinate Vectors using the GLT and Metadata from an EMIT dataset read into xarray.\n\n    Parameters:\n    ds: an xarray.Dataset containing the root variable and metadata of an EMIT dataset\n    loc: an xarray.Dataset containing the 'location' group of an EMIT dataset\n\n    Returns:\n    lon, lat (numpy.array): longitute and latitude array grid for the dataset\n\n    \"\"\"\n    # Retrieve Geotransform from Metadata\n    GT = ds.geotransform\n    # Create Array for Lat and Lon and fill\n    dim_x = ds.glt_x.shape[1]\n    dim_y = ds.glt_x.shape[0]\n    lon = np.zeros(dim_x)\n    lat = np.zeros(dim_y)\n    # Note: no rotation for EMIT Data\n    for x in np.arange(dim_x):\n        x_geo = (GT[0] + 0.5 * GT[1]) + x * GT[1]  # Adjust coordinates to pixel-center\n        lon[x] = x_geo\n    for y in np.arange(dim_y):\n        y_geo = (GT[3] + 0.5 * GT[5]) + y * GT[5]\n        lat[y] = y_geo\n    return lon, lat\n</code></pre>"},{"location":"emit/#hypercoast.emit.emit_to_image","title":"<code>emit_to_image(data, wavelengths=None, method='nearest', output=None, **kwargs)</code>","text":"<p>Converts an EMIT dataset to an image.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>xarray.Dataset or str</code> <p>The dataset containing the EMIT data or the file path to the dataset.</p> required <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>output</code> <code>str</code> <p>The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>leafmap.array_to_image</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>rasterio.Dataset or None</code> <p>The image converted from the dataset. If <code>output</code> is provided, the image will be saved to the specified file and the function will return None.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def emit_to_image(data, wavelengths=None, method=\"nearest\", output=None, **kwargs):\n    \"\"\"\n    Converts an EMIT dataset to an image.\n\n    Args:\n        data (xarray.Dataset or str): The dataset containing the EMIT data or the file path to the dataset.\n        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n        output (str, optional): The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.\n        **kwargs: Additional keyword arguments to be passed to `leafmap.array_to_image`.\n\n    Returns:\n        rasterio.Dataset or None: The image converted from the dataset. If `output` is provided, the image will be saved to the specified file and the function will return None.\n    \"\"\"\n    from leafmap import array_to_image\n\n    if isinstance(data, str):\n        data = read_emit(data, ortho=True)\n\n    ds = data[\"reflectance\"]\n\n    if wavelengths is not None:\n        ds = ds.sel(wavelengths=wavelengths, method=method)\n    return array_to_image(ds, transpose=False, output=output, **kwargs)\n</code></pre>"},{"location":"emit/#hypercoast.emit.emit_to_netcdf","title":"<code>emit_to_netcdf(data, output, **kwargs)</code>","text":"<p>Transposes an EMIT dataset and saves it as a NetCDF file.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>xarray.Dataset or str</code> <p>The dataset containing the EMIT data or the file path to the dataset.</p> required <code>output</code> <code>str</code> <p>The file path where the NetCDF file will be saved.</p> required <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>xarray.Dataset.to_netcdf</code>.</p> <code>{}</code> Source code in <code>hypercoast/emit.py</code> <pre><code>def emit_to_netcdf(data, output, **kwargs):\n    \"\"\"\n    Transposes an EMIT dataset and saves it as a NetCDF file.\n\n    Args:\n        data (xarray.Dataset or str): The dataset containing the EMIT data or the file path to the dataset.\n        output (str): The file path where the NetCDF file will be saved.\n        **kwargs: Additional keyword arguments to be passed to `xarray.Dataset.to_netcdf`.\n\n    \"\"\"\n    if isinstance(data, str):\n        data = read_emit(data, ortho=True)\n\n    ds_geo = data.transpose(\"wavelengths\", \"latitude\", \"longitude\")\n    ds_geo.to_netcdf(output, **kwargs)\n</code></pre>"},{"location":"emit/#hypercoast.emit.emit_xarray","title":"<code>emit_xarray(filepath, ortho=False, qmask=None, unpacked_bmask=None, wavelengths=None, method='nearest')</code>","text":"<p>Streamlines opening an EMIT dataset as an xarray.Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>A filepath to an EMIT netCDF file.</p> required <code>ortho</code> <code>bool</code> <p>Whether to orthorectify the dataset or leave in crosstrack/downtrack coordinates. Defaults to False.</p> <code>False</code> <code>qmask</code> <code>numpy.ndarray</code> <p>A numpy array output from the quality_mask function used to mask pixels based on quality flags selected in that function. Any non-orthorectified array with the proper crosstrack and downtrack dimensions can also be used. Defaults to None.</p> <code>None</code> <code>unpacked_bmask</code> <code>numpy.ndarray</code> <p>A numpy array from the band_mask function that can be used to mask band-specific pixels that have been interpolated. Defaults to None.</p> <code>None</code> <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>An xarray.Dataset constructed based on the parameters provided.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def emit_xarray(\n    filepath,\n    ortho=False,\n    qmask=None,\n    unpacked_bmask=None,\n    wavelengths=None,\n    method=\"nearest\",\n):\n    \"\"\"\n    Streamlines opening an EMIT dataset as an xarray.Dataset.\n\n    Args:\n        filepath (str): A filepath to an EMIT netCDF file.\n        ortho (bool, optional): Whether to orthorectify the dataset or leave in crosstrack/downtrack coordinates. Defaults to False.\n        qmask (numpy.ndarray, optional): A numpy array output from the quality_mask function used to mask pixels based on quality flags selected in that function. Any non-orthorectified array with the proper crosstrack and downtrack dimensions can also be used. Defaults to None.\n        unpacked_bmask (numpy.ndarray, optional): A numpy array from the band_mask function that can be used to mask band-specific pixels that have been interpolated. Defaults to None.\n        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n\n    Returns:\n        xarray.Dataset: An xarray.Dataset constructed based on the parameters provided.\n    \"\"\"\n    # Grab granule filename to check product\n    import s3fs\n    from fsspec.implementations.http import HTTPFile\n\n    if type(filepath) == s3fs.core.S3File:\n        granule_id = filepath.info()[\"name\"].split(\"/\", -1)[-1].split(\".\", -1)[0]\n    elif type(filepath) == HTTPFile:\n        granule_id = filepath.path.split(\"/\", -1)[-1].split(\".\", -1)[0]\n    else:\n        granule_id = os.path.splitext(os.path.basename(filepath))[0]\n\n    # Read in Data as Xarray Datasets\n    engine, wvl_group = \"h5netcdf\", None\n\n    ds = xr.open_dataset(filepath, engine=engine)\n    loc = xr.open_dataset(filepath, engine=engine, group=\"location\")\n\n    # Check if mineral dataset and read in groups (only ds/loc for minunc)\n\n    if \"L2B_MIN_\" in granule_id:\n        wvl_group = \"mineral_metadata\"\n    elif \"L2B_MINUNC\" not in granule_id:\n        wvl_group = \"sensor_band_parameters\"\n\n    wvl = None\n\n    if wvl_group:\n        wvl = xr.open_dataset(filepath, engine=engine, group=wvl_group)\n\n    # Building Flat Dataset from Components\n    data_vars = {**ds.variables}\n\n    # Format xarray coordinates based upon emit product (no wvl for mineral uncertainty)\n    coords = {\n        \"downtrack\": ([\"downtrack\"], ds.downtrack.data),\n        \"crosstrack\": ([\"crosstrack\"], ds.crosstrack.data),\n        **loc.variables,\n    }\n\n    product_band_map = {\n        \"L2B_MIN_\": \"name\",\n        \"L2A_MASK_\": \"mask_bands\",\n        \"L1B_OBS_\": \"observation_bands\",\n        \"L2A_RFL_\": \"wavelengths\",\n        \"L1B_RAD_\": \"wavelengths\",\n        \"L2A_RFLUNCERT_\": \"wavelengths\",\n    }\n\n    # if band := product_band_map.get(next((k for k in product_band_map.keys() if k in granule_id), 'unknown'), None):\n    # coords['bands'] = wvl[band].data\n\n    if wvl:\n        coords = {**coords, **wvl.variables}\n\n    out_xr = xr.Dataset(data_vars=data_vars, coords=coords, attrs=ds.attrs)\n    out_xr.attrs[\"granule_id\"] = granule_id\n\n    if band := product_band_map.get(\n        next((k for k in product_band_map.keys() if k in granule_id), \"unknown\"), None\n    ):\n        if \"minerals\" in list(out_xr.dims):\n            out_xr = out_xr.swap_dims({\"minerals\": band})\n            out_xr = out_xr.rename({band: \"mineral_name\"})\n        else:\n            out_xr = out_xr.swap_dims({\"bands\": band})\n\n    # Apply Quality and Band Masks, set fill values to NaN\n    for var in list(ds.data_vars):\n        if qmask is not None:\n            out_xr[var].data[qmask == 1] = np.nan\n        if unpacked_bmask is not None:\n            out_xr[var].data[unpacked_bmask == 1] = np.nan\n        out_xr[var].data[out_xr[var].data == -9999] = np.nan\n\n    if ortho is True:\n        out_xr = ortho_xr(out_xr)\n        out_xr.attrs[\"Orthorectified\"] = \"True\"\n\n    if wavelengths is not None:\n        out_xr = out_xr.sel(wavelengths=wavelengths, method=method)\n    return out_xr\n</code></pre>"},{"location":"emit/#hypercoast.emit.envi_header","title":"<code>envi_header(inputpath)</code>","text":"<p>Convert a ENVI binary/header path to a header, handling extensions.</p> <p>Parameters:</p> Name Type Description Default <code>inputpath</code> <code>str</code> <p>Path to ENVI binary file.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The header file associated with the input reference. If the header file does not exist, it returns the expected header file path.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def envi_header(inputpath):\n    \"\"\"\n    Convert a ENVI binary/header path to a header, handling extensions.\n\n    Args:\n        inputpath (str): Path to ENVI binary file.\n\n    Returns:\n        str: The header file associated with the input reference. If the header file does not exist, it returns the expected header file path.\n    \"\"\"\n    if (\n        os.path.splitext(inputpath)[-1] == \".img\"\n        or os.path.splitext(inputpath)[-1] == \".dat\"\n        or os.path.splitext(inputpath)[-1] == \".raw\"\n    ):\n        # headers could be at either filename.img.hdr or filename.hdr.  Check both, return the one that exists if it\n        # does, if not return the latter (new file creation presumed).\n        hdrfile = os.path.splitext(inputpath)[0] + \".hdr\"\n        if os.path.isfile(hdrfile):\n            return hdrfile\n        elif os.path.isfile(inputpath + \".hdr\"):\n            return inputpath + \".hdr\"\n        return hdrfile\n    elif os.path.splitext(inputpath)[-1] == \".hdr\":\n        return inputpath\n    else:\n        return inputpath + \".hdr\"\n</code></pre>"},{"location":"emit/#hypercoast.emit.is_adjacent","title":"<code>is_adjacent(scene, same_orbit)</code>","text":"<p>Checks if the scene numbers from the same orbit are adjacent/sequential.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>str</code> <p>The scene number to check.</p> required <code>same_orbit</code> <code>list</code> <p>A list of scene numbers from the same orbit.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the scene numbers are adjacent/sequential, False otherwise.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def is_adjacent(scene: str, same_orbit: list):\n    \"\"\"\n    Checks if the scene numbers from the same orbit are adjacent/sequential.\n\n    Args:\n        scene (str): The scene number to check.\n        same_orbit (list): A list of scene numbers from the same orbit.\n\n    Returns:\n        bool: True if the scene numbers are adjacent/sequential, False otherwise.\n    \"\"\"\n    scene_nums = [int(scene.split(\".\")[-2].split(\"_\")[-1]) for scene in same_orbit]\n    return all(b - a == 1 for a, b in zip(scene_nums[:-1], scene_nums[1:]))\n</code></pre>"},{"location":"emit/#hypercoast.emit.merge_emit","title":"<code>merge_emit(datasets, gdf)</code>","text":"<p>Merges xarray datasets formatted using emit_xarray. Note: GDF may only work with a single geometry.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>dict</code> <p>A dictionary of xarray datasets formatted using emit_xarray.</p> required <code>gdf</code> <code>gpd.GeoDataFrame</code> <p>A GeoDataFrame containing the geometry to be used for merging.</p> required <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>A merged xarray dataset.</p> <p>Exceptions:</p> Type Description <code>Exception</code> <p>If there are inconsistencies in the 1D variables across datasets.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def merge_emit(datasets: dict, gdf: gpd.GeoDataFrame):\n    \"\"\"\n    Merges xarray datasets formatted using emit_xarray. Note: GDF may only work with a single geometry.\n\n    Args:\n        datasets (dict): A dictionary of xarray datasets formatted using emit_xarray.\n        gdf (gpd.GeoDataFrame): A GeoDataFrame containing the geometry to be used for merging.\n\n    Returns:\n        xarray.Dataset: A merged xarray dataset.\n\n    Raises:\n        Exception: If there are inconsistencies in the 1D variables across datasets.\n    \"\"\"\n    from rioxarray.merge import merge_arrays\n\n    nested_data_arrays = {}\n    # loop over datasets\n    for dataset in datasets:\n        # create dictionary of arrays for each dataset\n\n        # create dictionary of 1D variables, which should be consistent across datasets\n        one_d_arrays = {}\n\n        # Dictionary of variables to merge\n        data_arrays = {}\n        # Loop over variables in dataset including elevation\n        for var in list(datasets[dataset].data_vars) + [\"elev\"]:\n            # Get 1D for this variable and add to dictionary\n            if not one_d_arrays:\n                # These should be an array describing the others (wavelengths, mask_bands, etc.)\n                one_dim = [\n                    item\n                    for item in list(datasets[dataset].coords)\n                    if item not in [\"latitude\", \"longitude\", \"spatial_ref\"]\n                    and len(datasets[dataset][item].dims) == 1\n                ]\n                # print(one_dim)\n                for od in one_dim:\n                    one_d_arrays[od] = datasets[dataset].coords[od].data\n\n                # Update format for merging - This could probably be improved\n            da = datasets[dataset][var].reset_coords(\"elev\", drop=False)\n            da = da.rename({\"latitude\": \"y\", \"longitude\": \"x\"})\n            if len(da.dims) == 3:\n                if any(item in list(da.coords) for item in one_dim):\n                    da = da.drop_vars(one_dim)\n                da = da.drop_vars(\"elev\")\n                da = da.to_array(name=var).squeeze(\"variable\", drop=True)\n                da = da.transpose(da.dims[-1], da.dims[0], da.dims[1])\n                # print(da.dims)\n            if var == \"elev\":\n                da = da.to_array(name=var).squeeze(\"variable\", drop=True)\n            data_arrays[var] = da\n            nested_data_arrays[dataset] = data_arrays\n\n            # Transpose the nested arrays dict. This is horrible to read, but works to pair up variables (ie mask) from the different granules\n    transposed_dict = {\n        inner_key: {\n            outer_key: inner_dict[inner_key]\n            for outer_key, inner_dict in nested_data_arrays.items()\n        }\n        for inner_key in nested_data_arrays[next(iter(nested_data_arrays))]\n    }\n\n    # remove some unused data\n    del nested_data_arrays, data_arrays, da\n\n    # Merge the arrays using rioxarray.merge_arrays()\n    merged = {}\n    for _var in transposed_dict:\n        merged[_var] = merge_arrays(\n            list(transposed_dict[_var].values()),\n            bounds=gdf.unary_union.bounds,\n            nodata=np.nan,\n        )\n\n    # Create a new xarray dataset from the merged arrays\n    # Create Merged Dataset\n    merged_ds = xr.Dataset(data_vars=merged, coords=one_d_arrays)\n    # Rename x and y to longitude and latitude\n    merged_ds = merged_ds.rename({\"y\": \"latitude\", \"x\": \"longitude\"})\n    del transposed_dict, merged\n    return merged_ds\n</code></pre>"},{"location":"emit/#hypercoast.emit.ortho_browse","title":"<code>ortho_browse(url, glt, spatial_ref, geotransform, white_background=True)</code>","text":"<p>Use an EMIT GLT, geotransform, and spatial ref to orthorectify a browse image. (browse images are in native resolution)</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of the browse image.</p> required <code>glt</code> <code>numpy.ndarray</code> <p>A GLT array constructed from EMIT GLT data.</p> required <code>spatial_ref</code> <code>str</code> <p>Spatial reference system.</p> required <code>geotransform</code> <code>list</code> <p>A list of six numbers that define the affine transform between pixel coordinates and map coordinates.</p> required <code>white_background</code> <code>bool</code> <p>If True, the fill value for the orthorectified image is white (255). If False, the fill value is black (0). Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>An orthorectified browse image in the form of an xarray DataArray.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def ortho_browse(url, glt, spatial_ref, geotransform, white_background=True):\n    \"\"\"\n    Use an EMIT GLT, geotransform, and spatial ref to orthorectify a browse image. (browse images are in native resolution)\n\n    Args:\n        url (str): URL of the browse image.\n        glt (numpy.ndarray): A GLT array constructed from EMIT GLT data.\n        spatial_ref (str): Spatial reference system.\n        geotransform (list): A list of six numbers that define the affine transform between pixel coordinates and map coordinates.\n        white_background (bool, optional): If True, the fill value for the orthorectified image is white (255). If False, the fill value is black (0). Defaults to True.\n\n    Returns:\n        xarray.DataArray: An orthorectified browse image in the form of an xarray DataArray.\n    \"\"\"\n    from skimage import io\n\n    # Read Data\n    data = io.imread(url)\n    # Orthorectify using GLT and transpose so band is first dimension\n    if white_background == True:\n        fill = 255\n    else:\n        fill = 0\n    ortho_data = apply_glt(data, glt, fill_value=fill).transpose(2, 0, 1)\n    coords = {\n        \"y\": (\n            [\"y\"],\n            (geotransform[3] + 0.5 * geotransform[5])\n            + np.arange(glt.shape[0]) * geotransform[5],\n        ),\n        \"x\": (\n            [\"x\"],\n            (geotransform[0] + 0.5 * geotransform[1])\n            + np.arange(glt.shape[1]) * geotransform[1],\n        ),\n    }\n    ortho_data = ortho_data.astype(int)\n    ortho_data[ortho_data == -1] = 0\n    # Place in xarray.datarray\n    da = xr.DataArray(ortho_data, dims=[\"band\", \"y\", \"x\"], coords=coords)\n    da.rio.write_crs(spatial_ref, inplace=True)\n    return da\n</code></pre>"},{"location":"emit/#hypercoast.emit.ortho_xr","title":"<code>ortho_xr(ds, GLT_NODATA_VALUE=0, fill_value=-9999)</code>","text":"<p>Uses <code>apply_glt</code> to create an orthorectified xarray dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset</code> <p>An xarray dataset produced by emit_xarray.</p> required <code>GLT_NODATA_VALUE</code> <code>int</code> <p>No data value for the GLT tables. Defaults to 0.</p> <code>0</code> <code>fill_value</code> <code>int</code> <p>The fill value for EMIT datasets. Defaults to -9999.</p> <code>-9999</code> <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>An orthocorrected xarray dataset.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def ortho_xr(ds, GLT_NODATA_VALUE=0, fill_value=-9999):\n    \"\"\"\n    Uses `apply_glt` to create an orthorectified xarray dataset.\n\n    Args:\n        ds (xarray.Dataset): An xarray dataset produced by emit_xarray.\n        GLT_NODATA_VALUE (int, optional): No data value for the GLT tables. Defaults to 0.\n        fill_value (int, optional): The fill value for EMIT datasets. Defaults to -9999.\n\n    Returns:\n        xarray.Dataset: An orthocorrected xarray dataset.\n    \"\"\"\n    # Build glt_ds\n\n    glt_ds = np.nan_to_num(\n        np.stack([ds[\"glt_x\"].data, ds[\"glt_y\"].data], axis=-1), nan=GLT_NODATA_VALUE\n    ).astype(int)\n\n    # List Variables\n    var_list = list(ds.data_vars)\n\n    # Remove flat field from data vars - the flat field is only useful with additional information before orthorectification\n    if \"flat_field_update\" in var_list:\n        var_list.remove(\"flat_field_update\")\n\n    # Create empty dictionary for orthocorrected data vars\n    data_vars = {}\n\n    # Extract Rawspace Dataset Variable Values (Typically Reflectance)\n    for var in var_list:\n        raw_ds = ds[var].data\n        var_dims = ds[var].dims\n        # Apply GLT to dataset\n        out_ds = apply_glt(raw_ds, glt_ds, GLT_NODATA_VALUE=GLT_NODATA_VALUE)\n\n        # Mask fill values\n        out_ds[out_ds == fill_value] = np.nan\n\n        # Update variables - Only works for 2 or 3 dimensional arays\n        if raw_ds.ndim == 2:\n            out_ds = out_ds.squeeze()\n            data_vars[var] = ([\"latitude\", \"longitude\"], out_ds)\n        else:\n            data_vars[var] = ([\"latitude\", \"longitude\", var_dims[-1]], out_ds)\n\n        del raw_ds\n\n    # Calculate Lat and Lon Vectors\n    lon, lat = coord_vects(\n        ds\n    )  # Reorder this function to make sense in case of multiple variables\n\n    # Apply GLT to elevation\n    elev_ds = apply_glt(ds[\"elev\"].data, glt_ds)\n    elev_ds[elev_ds == fill_value] = np.nan\n\n    # Delete glt_ds - no longer needed\n    del glt_ds\n\n    # Create Coordinate Dictionary\n    coords = {\n        \"latitude\": ([\"latitude\"], lat),\n        \"longitude\": ([\"longitude\"], lon),\n        **ds.coords,\n    }  # unpack to add appropriate coordinates\n\n    # Remove Unnecessary Coords\n    for key in [\"downtrack\", \"crosstrack\", \"lat\", \"lon\", \"glt_x\", \"glt_y\", \"elev\"]:\n        del coords[key]\n\n    # Add Orthocorrected Elevation\n    coords[\"elev\"] = ([\"latitude\", \"longitude\"], np.squeeze(elev_ds))\n\n    # Build Output xarray Dataset and assign data_vars array attributes\n    out_xr = xr.Dataset(data_vars=data_vars, coords=coords, attrs=ds.attrs)\n\n    del out_ds\n    # Assign Attributes from Original Datasets\n    for var in var_list:\n        out_xr[var].attrs = ds[var].attrs\n    out_xr.coords[\"latitude\"].attrs = ds[\"lat\"].attrs\n    out_xr.coords[\"longitude\"].attrs = ds[\"lon\"].attrs\n    out_xr.coords[\"elev\"].attrs = ds[\"elev\"].attrs\n\n    # Add Spatial Reference in recognizable format\n    out_xr.rio.write_crs(ds.spatial_ref, inplace=True)\n\n    return out_xr\n</code></pre>"},{"location":"emit/#hypercoast.emit.plot_emit","title":"<code>plot_emit(ds, longitude=None, latitude=None, downtrack=None, crosstrack=None, remove_nans=True, x='wavelengths', y='reflectance', color='black', frame_height=400, frame_width=600, title=None, method='nearest', ortho=True, options={}, **kwargs)</code>","text":"<p>Plots a line graph of the reflectance data from a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset or str</code> <p>The dataset containing the reflectance data or the file path to the dataset.</p> required <code>longitude</code> <code>float</code> <p>The longitude coordinate to select for orthorectified data. Defaults to None.</p> <code>None</code> <code>latitude</code> <code>float</code> <p>The latitude coordinate to select for orthorectified data. Defaults to None.</p> <code>None</code> <code>downtrack</code> <code>int</code> <p>The downtrack coordinate to select for non-orthorectified data. Defaults to None.</p> <code>None</code> <code>crosstrack</code> <code>int</code> <p>The crosstrack coordinate to select for non-orthorectified data. Defaults to None.</p> <code>None</code> <code>remove_nans</code> <code>bool</code> <p>If True, replace non-good wavelengths with NaN. Defaults to True.</p> <code>True</code> <code>x</code> <code>str</code> <p>The x-axis label. Defaults to \"wavelengths\".</p> <code>'wavelengths'</code> <code>y</code> <code>str</code> <p>The y-axis label. Defaults to \"reflectance\".</p> <code>'reflectance'</code> <code>color</code> <code>str</code> <p>The color of the line. Defaults to \"black\".</p> <code>'black'</code> <code>frame_height</code> <code>int</code> <p>The height of the frame. Defaults to 400.</p> <code>400</code> <code>frame_width</code> <code>int</code> <p>The width of the frame. Defaults to 600.</p> <code>600</code> <code>title</code> <code>str</code> <p>The title of the plot. If None, a default title will be generated. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>ortho</code> <code>bool</code> <p>If True, the function will use longitude and latitude for data selection. Defaults to True.</p> <code>True</code> <code>options</code> <code>dict</code> <p>Additional options to be passed to <code>hvplot.line</code>. Defaults to {}.</p> <code>{}</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>hvplot.line</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>hvplot.Plot</code> <p>The line plot of the reflectance data.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def plot_emit(\n    ds,\n    longitude=None,\n    latitude=None,\n    downtrack=None,\n    crosstrack=None,\n    remove_nans=True,\n    x=\"wavelengths\",\n    y=\"reflectance\",\n    color=\"black\",\n    frame_height=400,\n    frame_width=600,\n    title=None,\n    method=\"nearest\",\n    ortho=True,\n    options={},\n    **kwargs,\n):\n    \"\"\"\n    Plots a line graph of the reflectance data from a given dataset.\n\n    Args:\n        ds (xarray.Dataset or str): The dataset containing the reflectance data or the file path to the dataset.\n        longitude (float, optional): The longitude coordinate to select for orthorectified data. Defaults to None.\n        latitude (float, optional): The latitude coordinate to select for orthorectified data. Defaults to None.\n        downtrack (int, optional): The downtrack coordinate to select for non-orthorectified data. Defaults to None.\n        crosstrack (int, optional): The crosstrack coordinate to select for non-orthorectified data. Defaults to None.\n        remove_nans (bool, optional): If True, replace non-good wavelengths with NaN. Defaults to True.\n        x (str, optional): The x-axis label. Defaults to \"wavelengths\".\n        y (str, optional): The y-axis label. Defaults to \"reflectance\".\n        color (str, optional): The color of the line. Defaults to \"black\".\n        frame_height (int, optional): The height of the frame. Defaults to 400.\n        frame_width (int, optional): The width of the frame. Defaults to 600.\n        title (str, optional): The title of the plot. If None, a default title will be generated. Defaults to None.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n        ortho (bool, optional): If True, the function will use longitude and latitude for data selection. Defaults to True.\n        options (dict, optional): Additional options to be passed to `hvplot.line`. Defaults to {}.\n        **kwargs: Additional keyword arguments to be passed to `hvplot.line`.\n\n    Returns:\n        hvplot.Plot: The line plot of the reflectance data.\n    \"\"\"\n\n    import hvplot.xarray\n\n    if ortho == True:\n        if longitude is None or latitude is None:\n            raise ValueError(\n                \"Longitude and Latitude must be provided for orthorectified data.\"\n            )\n    else:\n        if downtrack is None or crosstrack is None:\n            raise ValueError(\n                \"Downtrack and Crosstrack must be provided for non-orthorectified data.\"\n            )\n\n    if longitude is not None and latitude is not None:\n        ortho = True\n\n    if downtrack is not None and crosstrack is not None:\n        ortho = False\n\n    if isinstance(ds, str):\n        ds = read_emit(ds, ortho=ortho)\n\n    if remove_nans:\n        ds[\"reflectance\"].data[:, :, ds[\"good_wavelengths\"].data == 0] = np.nan\n\n    if ortho:\n        example = ds[\"reflectance\"].sel(\n            longitude=longitude, latitude=latitude, method=method\n        )\n        if title is None:\n            title = f\"Reflectance at longitude={longitude:.3f}, latitude={latitude:.3f}\"\n\n    else:\n        example = ds[\"reflectance\"].sel(\n            downtrack=downtrack, crosstrack=crosstrack, method=method\n        )\n        if title is None:\n            title = f\"Reflectance at downtrack={downtrack}, crosstrack={crosstrack}\"\n\n    line = example.hvplot.line(\n        y=y,\n        x=x,\n        color=color,\n        frame_height=frame_height,\n        frame_width=frame_width,\n        **kwargs,\n    ).opts(title=title, **options)\n    return line\n</code></pre>"},{"location":"emit/#hypercoast.emit.quality_mask","title":"<code>quality_mask(filepath, quality_bands)</code>","text":"<p>Builds a single layer mask to apply based on the bands selected from an EMIT L2A Mask file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>An EMIT L2A Mask netCDF file.</p> required <code>quality_bands</code> <code>list</code> <p>A list of bands (quality flags only) from the mask file that should be used in creation of mask.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>A numpy array that can be used with the emit_xarray function to apply a quality mask.</p> <p>Exceptions:</p> Type Description <code>AttributeError</code> <p>If the selected flags include a data band (5 or 6) not just flag bands.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def quality_mask(filepath, quality_bands):\n    \"\"\"\n    Builds a single layer mask to apply based on the bands selected from an EMIT L2A Mask file.\n\n    Args:\n        filepath (str): An EMIT L2A Mask netCDF file.\n        quality_bands (list): A list of bands (quality flags only) from the mask file that should be used in creation of mask.\n\n    Returns:\n        numpy.ndarray: A numpy array that can be used with the emit_xarray function to apply a quality mask.\n\n    Raises:\n        AttributeError: If the selected flags include a data band (5 or 6) not just flag bands.\n    \"\"\"\n    # Open Dataset\n    mask_ds = xr.open_dataset(filepath, engine=\"h5netcdf\")\n    # Open Sensor band Group\n    mask_parameters_ds = xr.open_dataset(\n        filepath, engine=\"h5netcdf\", group=\"sensor_band_parameters\"\n    )\n    # Print Flags used\n    flags_used = mask_parameters_ds[\"mask_bands\"].data[quality_bands]\n    print(f\"Flags used: {flags_used}\")\n    # Check for data bands and build mask\n    if any(x in quality_bands for x in [5, 6]):\n        err_str = f\"Selected flags include a data band (5 or 6) not just flag bands\"\n        raise AttributeError(err_str)\n    else:\n        qmask = np.sum(mask_ds[\"mask\"][:, :, quality_bands].values, axis=-1)\n        qmask[qmask &gt; 1] = 1\n    return qmask\n</code></pre>"},{"location":"emit/#hypercoast.emit.raw_spatial_crop","title":"<code>raw_spatial_crop(ds, shape)</code>","text":"<p>Use a polygon to clip the file GLT, then a bounding box to crop the spatially raw data. Regions clipped in the GLT are set to 0 so a mask will be applied when used to orthorectify the data at a later point in a workflow.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset</code> <p>Raw spatial EMIT data (non-orthorectified) opened with the <code>emit_xarray</code> function.</p> required <code>shape</code> <code>geopandas.GeoDataFrame</code> <p>A polygon opened with geopandas.</p> required <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>A clipped GLT and raw spatial data clipped to a bounding box.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def raw_spatial_crop(ds, shape):\n    \"\"\"\n    Use a polygon to clip the file GLT, then a bounding box to crop the spatially raw data. Regions clipped in the GLT are set to 0 so a mask will be applied when\n    used to orthorectify the data at a later point in a workflow.\n\n    Args:\n        ds (xarray.Dataset): Raw spatial EMIT data (non-orthorectified) opened with the `emit_xarray` function.\n        shape (geopandas.GeoDataFrame): A polygon opened with geopandas.\n\n    Returns:\n        xarray.Dataset: A clipped GLT and raw spatial data clipped to a bounding box.\n    \"\"\"\n    # Reformat the GLT\n    lon, lat = coord_vects(ds)\n    data_vars = {\n        \"glt_x\": ([\"latitude\", \"longitude\"], ds.glt_x.data),\n        \"glt_y\": ([\"latitude\", \"longitude\"], ds.glt_y.data),\n    }\n    coords = {\n        \"latitude\": ([\"latitude\"], lat),\n        \"longitude\": ([\"longitude\"], lon),\n        \"ortho_y\": ([\"latitude\"], ds.ortho_y.data),\n        \"ortho_x\": ([\"longitude\"], ds.ortho_x.data),\n    }\n    glt_ds = xr.Dataset(data_vars=data_vars, coords=coords, attrs=ds.attrs)\n    glt_ds.rio.write_crs(glt_ds.spatial_ref, inplace=True)\n\n    # Clip the emit glt\n    clipped = glt_ds.rio.clip(shape.geometry.values, shape.crs, all_touched=True)\n\n    # Pull new geotransform from clipped glt\n    clipped_gt = np.array(\n        [float(i) for i in clipped[\"spatial_ref\"].GeoTransform.split(\" \")]\n    )  # THIS GEOTRANSFORM IS OFF BY HALF A PIXEL\n\n    # Create Crosstrack and Downtrack masks for spatially raw dataset -1 is to account for 1 based index. May be a more robust way to do this exists\n    crosstrack_mask = (ds.crosstrack &gt;= np.nanmin(clipped.glt_x.data) - 1) &amp; (\n        ds.crosstrack &lt;= np.nanmax(clipped.glt_x.data) - 1\n    )\n    downtrack_mask = (ds.downtrack &gt;= np.nanmin(clipped.glt_y.data) - 1) &amp; (\n        ds.downtrack &lt;= np.nanmax(clipped.glt_y.data) - 1\n    )\n\n    # Mask Areas outside of crosstrack and downtrack covered by the shape\n    clipped_ds = ds.where((crosstrack_mask &amp; downtrack_mask), drop=True)\n    # Replace Full dataset geotransform with clipped geotransform\n    clipped_ds.attrs[\"geotransform\"] = clipped_gt\n\n    # Drop unnecessary vars from dataset\n    clipped_ds = clipped_ds.drop_vars([\"glt_x\", \"glt_y\", \"downtrack\", \"crosstrack\"])\n\n    # Re-index the GLT to the new array\n    glt_x_data = clipped.glt_x.data - np.nanmin(clipped.glt_x)\n    glt_y_data = clipped.glt_y.data - np.nanmin(clipped.glt_y)\n    clipped_ds = clipped_ds.assign_coords(\n        {\n            \"glt_x\": ([\"ortho_y\", \"ortho_x\"], np.nan_to_num(glt_x_data)),\n            \"glt_y\": ([\"ortho_y\", \"ortho_x\"], np.nan_to_num(glt_y_data)),\n        }\n    )\n    clipped_ds = clipped_ds.assign_coords(\n        {\n            \"downtrack\": (\n                [\"downtrack\"],\n                np.arange(0, clipped_ds[list(ds.data_vars.keys())[0]].shape[0]),\n            ),\n            \"crosstrack\": (\n                [\"crosstrack\"],\n                np.arange(0, clipped_ds[list(ds.data_vars.keys())[0]].shape[1]),\n            ),\n        }\n    )\n\n    return clipped_ds\n</code></pre>"},{"location":"emit/#hypercoast.emit.read_emit","title":"<code>read_emit(filepath, ortho=True, wavelengths=None, method='nearest', **kwargs)</code>","text":"<p>Opens an EMIT dataset from a file path and assigns new coordinates to it.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The file path to the EMIT dataset.</p> required <code>ortho</code> <code>bool</code> <p>If True, the function will return an orthorectified dataset. Defaults to True.</p> <code>True</code> <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>xr.open_dataset</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>The dataset with new coordinates assigned.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def read_emit(filepath, ortho=True, wavelengths=None, method=\"nearest\", **kwargs):\n    \"\"\"\n    Opens an EMIT dataset from a file path and assigns new coordinates to it.\n\n    Args:\n        filepath (str): The file path to the EMIT dataset.\n        ortho (bool, optional): If True, the function will return an orthorectified dataset. Defaults to True.\n        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to be passed to `xr.open_dataset`.\n\n    Returns:\n        xarray.Dataset: The dataset with new coordinates assigned.\n\n    \"\"\"\n\n    if ortho == True:\n        return emit_xarray(\n            filepath, ortho=True, wavelengths=wavelengths, method=method, **kwargs\n        )\n    else:\n        ds = xr.open_dataset(filepath, **kwargs)\n        wvl = xr.open_dataset(filepath, group=\"sensor_band_parameters\")\n        loc = xr.open_dataset(filepath, group=\"location\")\n        ds = ds.assign_coords(\n            {\n                \"downtrack\": ([\"downtrack\"], ds.downtrack.data),\n                \"crosstrack\": ([\"crosstrack\"], ds.crosstrack.data),\n                **wvl.variables,\n                **loc.variables,\n            }\n        )\n        ds = ds.swap_dims({\"bands\": \"wavelengths\"})\n        del wvl\n        del loc\n\n        if wavelengths is not None:\n            ds = ds.sel(wavelengths=wavelengths, method=method)\n\n        return ds\n</code></pre>"},{"location":"emit/#hypercoast.emit.viz_emit","title":"<code>viz_emit(ds, wavelengths, cmap='viridis', frame_width=720, method='nearest', ortho=True, aspect='equal', tiles='ESRI', alpha=0.8, title=None, options={}, **kwargs)</code>","text":"<p>Visualizes the reflectance data from a given dataset at specific wavelengths.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset or str</code> <p>The dataset containing the reflectance data or the file path to the dataset.</p> required <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to visualize.</p> required <code>cmap</code> <code>str</code> <p>The colormap to use. Defaults to \"viridis\".</p> <code>'viridis'</code> <code>frame_width</code> <code>int</code> <p>The width of the frame. Defaults to 720.</p> <code>720</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>ortho</code> <code>bool</code> <p>If True, the function will return an orthorectified image. Defaults to True.</p> <code>True</code> <code>aspect</code> <code>str</code> <p>The aspect ratio of the plot. Defaults to \"equal\".</p> <code>'equal'</code> <code>tiles</code> <code>str</code> <p>The tile source to use for the background map. Defaults to \"ESRI\".</p> <code>'ESRI'</code> <code>alpha</code> <code>float</code> <p>The alpha value for the image. Defaults to 0.8.</p> <code>0.8</code> <code>title</code> <code>str</code> <p>The title of the plot. If None, a default title will be generated. Defaults to None.</p> <code>None</code> <code>options</code> <code>dict</code> <p>Additional options to be passed to <code>hvplot.image</code>. Defaults to {}.</p> <code>{}</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>hvplot.image</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>hvplot.Plot</code> <p>The image plot of the reflectance data at the specified wavelengths.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def viz_emit(\n    ds,\n    wavelengths,\n    cmap=\"viridis\",\n    frame_width=720,\n    method=\"nearest\",\n    ortho=True,\n    aspect=\"equal\",\n    tiles=\"ESRI\",\n    alpha=0.8,\n    title=None,\n    options={},\n    **kwargs,\n):\n    \"\"\"\n    Visualizes the reflectance data from a given dataset at specific wavelengths.\n\n    Args:\n        ds (xarray.Dataset or str): The dataset containing the reflectance data or the file path to the dataset.\n        wavelengths (array-like): The specific wavelengths to visualize.\n        cmap (str, optional): The colormap to use. Defaults to \"viridis\".\n        frame_width (int, optional): The width of the frame. Defaults to 720.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n        ortho (bool, optional): If True, the function will return an orthorectified image. Defaults to True.\n        aspect (str, optional): The aspect ratio of the plot. Defaults to \"equal\".\n        tiles (str, optional): The tile source to use for the background map. Defaults to \"ESRI\".\n        alpha (float, optional): The alpha value for the image. Defaults to 0.8.\n        title (str, optional): The title of the plot. If None, a default title will be generated. Defaults to None.\n        options (dict, optional): Additional options to be passed to `hvplot.image`. Defaults to {}.\n        **kwargs: Additional keyword arguments to be passed to `hvplot.image`.\n\n    Returns:\n        hvplot.Plot: The image plot of the reflectance data at the specified wavelengths.\n    \"\"\"\n    import hvplot.xarray\n\n    if isinstance(ds, str):\n        ds = read_emit(ds, ortho=ortho)\n    example = ds.sel(wavelengths=wavelengths, method=method)\n\n    if title is None:\n        title = f\"Reflectance at {example.wavelengths.values:.3f} {example.wavelengths.units}\"\n\n    if ortho:\n        image = example.hvplot.image(\n            cmap=cmap,\n            geo=ortho,\n            tiles=tiles,\n            alpha=alpha,\n            frame_width=frame_width,\n            **kwargs,\n        ).opts(title=title, **options)\n    else:\n        image = example.hvplot.image(\n            cmap=cmap, aspect=aspect, alpha=alpha, frame_width=frame_width, **kwargs\n        ).opts(title=title, **options)\n\n    return image\n</code></pre>"},{"location":"emit/#hypercoast.emit.write_envi","title":"<code>write_envi(xr_ds, output_dir, overwrite=False, extension='.img', interleave='BIL', glt_file=False)</code>","text":"<p>Takes an EMIT dataset read into an xarray dataset using the emit_xarray function and writes an ENVI file and header.</p> <p>Parameters:</p> Name Type Description Default <code>xr_ds</code> <code>xarray.Dataset</code> <p>An EMIT dataset read into xarray using the emit_xarray function.</p> required <code>output_dir</code> <code>str</code> <p>Output directory.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite existing file if True. Defaults to False.</p> <code>False</code> <code>extension</code> <code>str</code> <p>The file extension for the envi formatted file, .img by default. Defaults to \".img\".</p> <code>'.img'</code> <code>interleave</code> <code>str</code> <p>The interleave option for the ENVI file. Defaults to \"BIL\".</p> <code>'BIL'</code> <code>glt_file</code> <code>bool</code> <p>Also create a GLT ENVI file for later use to reproject. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing:     - envi_ds (spectral.io.envi.Image): ENVI file in the output directory.     - glt_ds (spectral.io.envi.Image): GLT file in the output directory.</p> <p>Exceptions:</p> Type Description <code>Exception</code> <p>If the data is already orthorectified but a GLT file is still requested.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def write_envi(\n    xr_ds,\n    output_dir,\n    overwrite=False,\n    extension=\".img\",\n    interleave=\"BIL\",\n    glt_file=False,\n):\n    \"\"\"\n    Takes an EMIT dataset read into an xarray dataset using the emit_xarray function and writes an ENVI file and header.\n\n    Args:\n        xr_ds (xarray.Dataset): An EMIT dataset read into xarray using the emit_xarray function.\n        output_dir (str): Output directory.\n        overwrite (bool, optional): Overwrite existing file if True. Defaults to False.\n        extension (str, optional): The file extension for the envi formatted file, .img by default. Defaults to \".img\".\n        interleave (str, optional): The interleave option for the ENVI file. Defaults to \"BIL\".\n        glt_file (bool, optional): Also create a GLT ENVI file for later use to reproject. Defaults to False.\n\n    Returns:\n        tuple: A tuple containing:\n            - envi_ds (spectral.io.envi.Image): ENVI file in the output directory.\n            - glt_ds (spectral.io.envi.Image): GLT file in the output directory.\n\n    Raises:\n        Exception: If the data is already orthorectified but a GLT file is still requested.\n    \"\"\"\n    from spectral.io import envi\n\n    # Check if xr_ds has been orthorectified, raise exception if it has been but GLT is still requested\n    if (\n        \"Orthorectified\" in xr_ds.attrs.keys()\n        and xr_ds.attrs[\"Orthorectified\"] == \"True\"\n        and glt_file == True\n    ):\n        raise Exception(\"Data is already orthorectified.\")\n\n    # Typemap dictionary for ENVI files\n    envi_typemap = {\n        \"uint8\": 1,\n        \"int16\": 2,\n        \"int32\": 3,\n        \"float32\": 4,\n        \"float64\": 5,\n        \"complex64\": 6,\n        \"complex128\": 9,\n        \"uint16\": 12,\n        \"uint32\": 13,\n        \"int64\": 14,\n        \"uint64\": 15,\n    }\n\n    # Get CRS/geotransform for creation of Orthorectified ENVI file or optional GLT file\n    gt = xr_ds.attrs[\"geotransform\"]\n    mapinfo = (\n        \"{Geographic Lat/Lon, 1, 1, \"\n        + str(gt[0])\n        + \", \"\n        + str(gt[3])\n        + \", \"\n        + str(gt[1])\n        + \", \"\n        + str(gt[5] * -1)\n        + \", WGS-84, units=Degrees}\"\n    )\n\n    # This creates the coordinate system string\n    # hard-coded replacement of wkt crs could probably be improved, though should be the same for all EMIT datasets\n    csstring = '{ GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]] }'\n    # List data variables (typically reflectance/radiance)\n    var_names = list(xr_ds.data_vars)\n\n    # Loop through variable names\n    for var in var_names:\n        # Define output filename\n        output_name = os.path.join(output_dir, xr_ds.attrs[\"granule_id\"] + \"_\" + var)\n\n        nbands = 1\n        if len(xr_ds[var].data.shape) &gt; 2:\n            nbands = xr_ds[var].data.shape[2]\n\n        # Start building metadata\n        metadata = {\n            \"lines\": xr_ds[var].data.shape[0],\n            \"samples\": xr_ds[var].data.shape[1],\n            \"bands\": nbands,\n            \"interleave\": interleave,\n            \"header offset\": 0,\n            \"file type\": \"ENVI Standard\",\n            \"data type\": envi_typemap[str(xr_ds[var].data.dtype)],\n            \"byte order\": 0,\n        }\n\n        for key in list(xr_ds.attrs.keys()):\n            if key == \"summary\":\n                metadata[\"description\"] = xr_ds.attrs[key]\n            elif key not in [\"geotransform\", \"spatial_ref\"]:\n                metadata[key] = f\"{{ {xr_ds.attrs[key]} }}\"\n\n        # List all variables in dataset (including coordinate variables)\n        meta_vars = list(xr_ds.variables)\n\n        # Add band parameter information to metadata (ie wavelengths/obs etc.)\n        for m in meta_vars:\n            if m == \"wavelengths\" or m == \"radiance_wl\":\n                metadata[\"wavelength\"] = np.array(xr_ds[m].data).astype(str).tolist()\n            elif m == \"fwhm\" or m == \"radiance_fwhm\":\n                metadata[\"fwhm\"] = np.array(xr_ds[m].data).astype(str).tolist()\n            elif m == \"good_wavelengths\":\n                metadata[\"good_wavelengths\"] = (\n                    np.array(xr_ds[m].data).astype(int).tolist()\n                )\n            elif m == \"observation_bands\":\n                metadata[\"band names\"] = np.array(xr_ds[m].data).astype(str).tolist()\n            elif m == \"mask_bands\":\n                if var == \"band_mask\":\n                    metadata[\"band names\"] = [\n                        \"packed_bands_\" + bn\n                        for bn in np.arange(285 / 8).astype(str).tolist()\n                    ]\n                else:\n                    metadata[\"band names\"] = (\n                        np.array(xr_ds[m].data).astype(str).tolist()\n                    )\n            if \"wavelength\" in list(metadata.keys()) and \"band names\" not in list(\n                metadata.keys()\n            ):\n                metadata[\"band names\"] = metadata[\"wavelength\"]\n\n        # Add CRS/mapinfo if xarray dataset has been orthorectified\n        if (\n            \"Orthorectified\" in xr_ds.attrs.keys()\n            and xr_ds.attrs[\"Orthorectified\"] == \"True\"\n        ):\n            metadata[\"coordinate system string\"] = csstring\n            metadata[\"map info\"] = mapinfo\n\n        # Replace NaN values in each layer with fill_value\n        # np.nan_to_num(xr_ds[var].data, copy=False, nan=-9999)\n\n        # Write Variables as ENVI Output\n        envi_ds = envi.create_image(\n            envi_header(output_name), metadata, ext=extension, force=overwrite\n        )\n        mm = envi_ds.open_memmap(interleave=\"bip\", writable=True)\n\n        dat = xr_ds[var].data\n\n        if len(dat.shape) == 2:\n            dat = dat.reshape((dat.shape[0], dat.shape[1], 1))\n\n        mm[...] = dat\n\n    # Create GLT Metadata/File\n    if glt_file == True:\n        # Output Name\n        glt_output_name = os.path.join(\n            output_dir, xr_ds.attrs[\"granule_id\"] + \"_\" + \"glt\"\n        )\n\n        # Write GLT Metadata\n        glt_metadata = metadata\n\n        # Remove Unwanted Metadata\n        glt_metadata.pop(\"wavelength\", None)\n        glt_metadata.pop(\"fwhm\", None)\n\n        # Replace Metadata\n        glt_metadata[\"lines\"] = xr_ds[\"glt_x\"].data.shape[0]\n        glt_metadata[\"samples\"] = xr_ds[\"glt_x\"].data.shape[1]\n        glt_metadata[\"bands\"] = 2\n        glt_metadata[\"data type\"] = envi_typemap[\"int32\"]\n        glt_metadata[\"band names\"] = [\"glt_x\", \"glt_y\"]\n        glt_metadata[\"coordinate system string\"] = csstring\n        glt_metadata[\"map info\"] = mapinfo\n\n        # Write GLT Outputs as ENVI File\n        glt_ds = envi.create_image(\n            envi_header(glt_output_name), glt_metadata, ext=extension, force=overwrite\n        )\n        mmglt = glt_ds.open_memmap(interleave=\"bip\", writable=True)\n        mmglt[...] = np.stack(\n            (xr_ds[\"glt_x\"].values, xr_ds[\"glt_y\"].values), axis=-1\n        ).astype(\"int32\")\n</code></pre>"},{"location":"faq/","title":"FAQ","text":""},{"location":"hypercoast/","title":"hypercoast module","text":"<p>Main module.</p>"},{"location":"hypercoast/#hypercoast.hypercoast.Map","title":"<code> Map            (Map)         </code>","text":"<p>A class that extends leafmap.Map to provide additional functionality for hypercoast.</p> <p>Methods</p> <p>Any methods inherited from leafmap.Map.</p> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>class Map(leafmap.Map):\n    \"\"\"\n    A class that extends leafmap.Map to provide additional functionality for hypercoast.\n\n    Attributes:\n        Any attributes inherited from leafmap.Map.\n\n    Methods:\n        Any methods inherited from leafmap.Map.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes a new instance of the Map class.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments that are passed to the parent class's constructor.\n        \"\"\"\n        super().__init__(**kwargs)\n\n    def add(self, obj, position=\"topright\", **kwargs):\n        \"\"\"Add a layer to the map.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments that are passed to the parent class's add_layer method.\n        \"\"\"\n\n        if isinstance(obj, str):\n            if obj == \"spectral\":\n                from .ui import SpectralWidget\n\n                SpectralWidget(self, position=position)\n                self.set_plot_options(add_marker_cluster=True)\n            else:\n                super().add(obj, **kwargs)\n\n        else:\n            super().add(obj, **kwargs)\n\n    def search_emit(self, default_dataset=\"EMITL2ARFL\"):\n        \"\"\"\n        Adds a NASA Earth Data search tool to the map with a default dataset for EMIT.\n\n        Args:\n            default_dataset (str, optional): The default dataset to search for. Defaults to \"EMITL2ARFL\".\n        \"\"\"\n        self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n\n    def search_pace(self, default_dataset=\"PACE_OCI_L2_AOP_NRT\"):\n        \"\"\"\n        Adds a NASA Earth Data search tool to the map with a default dataset for PACE.\n\n        Args:\n            default_dataset (str, optional): The default dataset to search for. Defaults to \"PACE_OCI_L2_AOP_NRT\".\n        \"\"\"\n        self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n\n    def add_raster(\n        self,\n        source,\n        indexes=None,\n        colormap=None,\n        vmin=None,\n        vmax=None,\n        nodata=None,\n        attribution=None,\n        layer_name=\"Raster\",\n        zoom_to_layer=True,\n        visible=True,\n        array_args={},\n        **kwargs,\n    ):\n        \"\"\"Add a local raster dataset to the map.\n            If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and\n            if the raster does not render properly, try installing jupyter-server-proxy using `pip install jupyter-server-proxy`,\n            then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.\n\n            import os\n            os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n        Args:\n            source (str): The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.\n            indexes (int, optional): The band(s) to use. Band indexing starts at 1. Defaults to None.\n            colormap (str, optional): The name of the colormap from `matplotlib` to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.\n            vmin (float, optional): The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.\n            vmax (float, optional): The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.\n            nodata (float, optional): The value from the band to use to interpret as not valid data. Defaults to None.\n            attribution (str, optional): Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.\n            layer_name (str, optional): The layer name to use. Defaults to 'Raster'.\n            zoom_to_layer (bool, optional): Whether to zoom to the extent of the layer. Defaults to True.\n            visible (bool, optional): Whether the layer is visible. Defaults to True.\n            array_args (dict, optional): Additional arguments to pass to `array_to_memory_file` when reading the raster. Defaults to {}.\n        \"\"\"\n\n        import numpy as np\n\n        if nodata is None:\n            nodata = np.nan\n        super().add_raster(\n            source,\n            indexes=indexes,\n            colormap=colormap,\n            vmin=vmin,\n            vmax=vmax,\n            nodata=nodata,\n            attribution=attribution,\n            layer_name=layer_name,\n            zoom_to_layer=zoom_to_layer,\n            visible=visible,\n            array_args=array_args,\n            **kwargs,\n        )\n\n    def add_emit(\n        self,\n        source,\n        wavelengths=None,\n        indexes=None,\n        colormap=None,\n        vmin=None,\n        vmax=None,\n        nodata=np.nan,\n        attribution=None,\n        layer_name=\"EMIT\",\n        zoom_to_layer=True,\n        visible=True,\n        array_args={},\n        **kwargs,\n    ):\n        \"\"\"Add a local raster dataset to the map.\n            If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and\n            if the raster does not render properly, try installing jupyter-server-proxy using `pip install jupyter-server-proxy`,\n            then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.\n\n            import os\n            os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n        Args:\n            source (str): The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.\n            indexes (int, optional): The band(s) to use. Band indexing starts at 1. Defaults to None.\n            colormap (str, optional): The name of the colormap from `matplotlib` to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.\n            vmin (float, optional): The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.\n            vmax (float, optional): The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.\n            nodata (float, optional): The value from the band to use to interpret as not valid data. Defaults to None.\n            attribution (str, optional): Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.\n            layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n            zoom_to_layer (bool, optional): Whether to zoom to the extent of the layer. Defaults to True.\n            visible (bool, optional): Whether the layer is visible. Defaults to True.\n            array_args (dict, optional): Additional arguments to pass to `array_to_memory_file` when reading the raster. Defaults to {}.\n        \"\"\"\n\n        xds = None\n        if isinstance(source, str):\n\n            xds = read_emit(source)\n            source = emit_to_image(xds, wavelengths=wavelengths)\n        elif isinstance(source, xr.Dataset):\n            xds = source\n            source = emit_to_image(xds, wavelengths=wavelengths)\n\n        self.add_raster(\n            source,\n            indexes=indexes,\n            colormap=colormap,\n            vmin=vmin,\n            vmax=vmax,\n            nodata=nodata,\n            attribution=attribution,\n            layer_name=layer_name,\n            zoom_to_layer=zoom_to_layer,\n            visible=visible,\n            array_args=array_args,\n            **kwargs,\n        )\n\n        self.cog_layer_dict[layer_name][\"xds\"] = xds\n\n    def add_pace(\n        self,\n        source,\n        wavelengths=None,\n        indexes=None,\n        colormap=\"jet\",\n        vmin=None,\n        vmax=None,\n        nodata=np.nan,\n        attribution=None,\n        layer_name=\"PACE\",\n        zoom_to_layer=True,\n        visible=True,\n        method=\"nearest\",\n        gridded=False,\n        array_args={},\n        **kwargs,\n    ):\n        \"\"\"Add a PACE dataset to the map.\n            If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and\n            if the raster does not render properly, try installing jupyter-server-proxy using `pip install jupyter-server-proxy`,\n            then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.\n\n            import os\n            os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n        Args:\n            source (str): The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.\n            indexes (int, optional): The band(s) to use. Band indexing starts at 1. Defaults to None.\n            colormap (str, optional): The name of the colormap from `matplotlib` to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.\n            vmin (float, optional): The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.\n            vmax (float, optional): The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.\n            nodata (float, optional): The value from the band to use to interpret as not valid data. Defaults to None.\n            attribution (str, optional): Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.\n            layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n            zoom_to_layer (bool, optional): Whether to zoom to the extent of the layer. Defaults to True.\n            visible (bool, optional): Whether the layer is visible. Defaults to True.\n            array_args (dict, optional): Additional arguments to pass to `array_to_memory_file` when reading the raster. Defaults to {}.\n        \"\"\"\n\n        if isinstance(source, str):\n\n            source = read_pace(source)\n\n        image = pace_to_image(\n            source, wavelengths=wavelengths, method=method, gridded=gridded\n        )\n\n        if isinstance(wavelengths, list) and len(wavelengths) &gt; 1:\n            colormap = None\n\n        self.add_raster(\n            image,\n            indexes=indexes,\n            colormap=colormap,\n            vmin=vmin,\n            vmax=vmax,\n            nodata=nodata,\n            attribution=attribution,\n            layer_name=layer_name,\n            zoom_to_layer=zoom_to_layer,\n            visible=visible,\n            array_args=array_args,\n            **kwargs,\n        )\n\n        self.cog_layer_dict[layer_name][\"xds\"] = source\n\n    def set_plot_options(\n        self,\n        add_marker_cluster=False,\n        plot_type=None,\n        overlay=False,\n        position=\"bottomright\",\n        min_width=None,\n        max_width=None,\n        min_height=None,\n        max_height=None,\n        **kwargs,\n    ):\n        \"\"\"Sets plotting options.\n\n        Args:\n            add_marker_cluster (bool, optional): Whether to add a marker cluster. Defaults to False.\n            sample_scale (float, optional):  A nominal scale in meters of the projection to sample in . Defaults to None.\n            plot_type (str, optional): The plot type can be one of \"None\", \"bar\", \"scatter\" or \"hist\". Defaults to None.\n            overlay (bool, optional): Whether to overlay plotted lines on the figure. Defaults to False.\n            position (str, optional): Position of the control, can be \u2018bottomleft\u2019, \u2018bottomright\u2019, \u2018topleft\u2019, or \u2018topright\u2019. Defaults to 'bottomright'.\n            min_width (int, optional): Min width of the widget (in pixels), if None it will respect the content size. Defaults to None.\n            max_width (int, optional): Max width of the widget (in pixels), if None it will respect the content size. Defaults to None.\n            min_height (int, optional): Min height of the widget (in pixels), if None it will respect the content size. Defaults to None.\n            max_height (int, optional): Max height of the widget (in pixels), if None it will respect the content size. Defaults to None.\n\n        \"\"\"\n        plot_options_dict = {}\n        plot_options_dict[\"add_marker_cluster\"] = add_marker_cluster\n        plot_options_dict[\"plot_type\"] = plot_type\n        plot_options_dict[\"overlay\"] = overlay\n        plot_options_dict[\"position\"] = position\n        plot_options_dict[\"min_width\"] = min_width\n        plot_options_dict[\"max_width\"] = max_width\n        plot_options_dict[\"min_height\"] = min_height\n        plot_options_dict[\"max_height\"] = max_height\n\n        for key in kwargs:\n            plot_options_dict[key] = kwargs[key]\n\n        self._plot_options = plot_options_dict\n\n        if not hasattr(self, \"_plot_marker_cluster\"):\n            self._plot_marker_cluster = ipyleaflet.MarkerCluster(name=\"Marker Cluster\")\n\n        if add_marker_cluster and (self._plot_marker_cluster not in self.layers):\n            self.add(self._plot_marker_cluster)\n\n    def spectral_to_df(self, **kwargs):\n        \"\"\"Converts the spectral data to a pandas DataFrame.\n\n        Returns:\n            pd.DataFrame: The spectral data as a pandas DataFrame.\n        \"\"\"\n        import pandas as pd\n\n        df = pd.DataFrame(self._spectral_data, **kwargs)\n        return df\n\n    def spectral_to_csv(self, filename, index=True, **kwargs):\n        \"\"\"Saves the spectral data to a CSV file.\n\n        Args:\n            filename (str): The output CSV file.\n            index (bool, optional): Whether to write the index. Defaults to True.\n        \"\"\"\n        df = self.spectral_to_df()\n        df = df.rename_axis(\"band\")\n        df.to_csv(filename, index=index, **kwargs)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.__init__","title":"<code>__init__(self, **kwargs)</code>  <code>special</code>","text":"<p>Initializes a new instance of the Map class.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments that are passed to the parent class's constructor.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes a new instance of the Map class.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments that are passed to the parent class's constructor.\n    \"\"\"\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add","title":"<code>add(self, obj, position='topright', **kwargs)</code>","text":"<p>Add a layer to the map.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments that are passed to the parent class's add_layer method.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add(self, obj, position=\"topright\", **kwargs):\n    \"\"\"Add a layer to the map.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments that are passed to the parent class's add_layer method.\n    \"\"\"\n\n    if isinstance(obj, str):\n        if obj == \"spectral\":\n            from .ui import SpectralWidget\n\n            SpectralWidget(self, position=position)\n            self.set_plot_options(add_marker_cluster=True)\n        else:\n            super().add(obj, **kwargs)\n\n    else:\n        super().add(obj, **kwargs)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add_emit","title":"<code>add_emit(self, source, wavelengths=None, indexes=None, colormap=None, vmin=None, vmax=None, nodata=nan, attribution=None, layer_name='EMIT', zoom_to_layer=True, visible=True, array_args={}, **kwargs)</code>","text":"<p>Add a local raster dataset to the map.     If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and     if the raster does not render properly, try installing jupyter-server-proxy using <code>pip install jupyter-server-proxy</code>,     then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.</p> <pre><code>import os\nos.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.</p> required <code>indexes</code> <code>int</code> <p>The band(s) to use. Band indexing starts at 1. Defaults to None.</p> <code>None</code> <code>colormap</code> <code>str</code> <p>The name of the colormap from <code>matplotlib</code> to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.</p> <code>None</code> <code>vmin</code> <code>float</code> <p>The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>nodata</code> <code>float</code> <p>The value from the band to use to interpret as not valid data. Defaults to None.</p> <code>nan</code> <code>attribution</code> <code>str</code> <p>Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.</p> <code>None</code> <code>layer_name</code> <code>str</code> <p>The layer name to use. Defaults to 'EMIT'.</p> <code>'EMIT'</code> <code>zoom_to_layer</code> <code>bool</code> <p>Whether to zoom to the extent of the layer. Defaults to True.</p> <code>True</code> <code>visible</code> <code>bool</code> <p>Whether the layer is visible. Defaults to True.</p> <code>True</code> <code>array_args</code> <code>dict</code> <p>Additional arguments to pass to <code>array_to_memory_file</code> when reading the raster. Defaults to {}.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add_emit(\n    self,\n    source,\n    wavelengths=None,\n    indexes=None,\n    colormap=None,\n    vmin=None,\n    vmax=None,\n    nodata=np.nan,\n    attribution=None,\n    layer_name=\"EMIT\",\n    zoom_to_layer=True,\n    visible=True,\n    array_args={},\n    **kwargs,\n):\n    \"\"\"Add a local raster dataset to the map.\n        If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and\n        if the raster does not render properly, try installing jupyter-server-proxy using `pip install jupyter-server-proxy`,\n        then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.\n\n        import os\n        os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n    Args:\n        source (str): The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.\n        indexes (int, optional): The band(s) to use. Band indexing starts at 1. Defaults to None.\n        colormap (str, optional): The name of the colormap from `matplotlib` to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.\n        vmin (float, optional): The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.\n        vmax (float, optional): The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.\n        nodata (float, optional): The value from the band to use to interpret as not valid data. Defaults to None.\n        attribution (str, optional): Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.\n        layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n        zoom_to_layer (bool, optional): Whether to zoom to the extent of the layer. Defaults to True.\n        visible (bool, optional): Whether the layer is visible. Defaults to True.\n        array_args (dict, optional): Additional arguments to pass to `array_to_memory_file` when reading the raster. Defaults to {}.\n    \"\"\"\n\n    xds = None\n    if isinstance(source, str):\n\n        xds = read_emit(source)\n        source = emit_to_image(xds, wavelengths=wavelengths)\n    elif isinstance(source, xr.Dataset):\n        xds = source\n        source = emit_to_image(xds, wavelengths=wavelengths)\n\n    self.add_raster(\n        source,\n        indexes=indexes,\n        colormap=colormap,\n        vmin=vmin,\n        vmax=vmax,\n        nodata=nodata,\n        attribution=attribution,\n        layer_name=layer_name,\n        zoom_to_layer=zoom_to_layer,\n        visible=visible,\n        array_args=array_args,\n        **kwargs,\n    )\n\n    self.cog_layer_dict[layer_name][\"xds\"] = xds\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add_pace","title":"<code>add_pace(self, source, wavelengths=None, indexes=None, colormap='jet', vmin=None, vmax=None, nodata=nan, attribution=None, layer_name='PACE', zoom_to_layer=True, visible=True, method='nearest', gridded=False, array_args={}, **kwargs)</code>","text":"<p>Add a PACE dataset to the map.     If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and     if the raster does not render properly, try installing jupyter-server-proxy using <code>pip install jupyter-server-proxy</code>,     then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.</p> <pre><code>import os\nos.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.</p> required <code>indexes</code> <code>int</code> <p>The band(s) to use. Band indexing starts at 1. Defaults to None.</p> <code>None</code> <code>colormap</code> <code>str</code> <p>The name of the colormap from <code>matplotlib</code> to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.</p> <code>'jet'</code> <code>vmin</code> <code>float</code> <p>The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>nodata</code> <code>float</code> <p>The value from the band to use to interpret as not valid data. Defaults to None.</p> <code>nan</code> <code>attribution</code> <code>str</code> <p>Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.</p> <code>None</code> <code>layer_name</code> <code>str</code> <p>The layer name to use. Defaults to 'EMIT'.</p> <code>'PACE'</code> <code>zoom_to_layer</code> <code>bool</code> <p>Whether to zoom to the extent of the layer. Defaults to True.</p> <code>True</code> <code>visible</code> <code>bool</code> <p>Whether the layer is visible. Defaults to True.</p> <code>True</code> <code>array_args</code> <code>dict</code> <p>Additional arguments to pass to <code>array_to_memory_file</code> when reading the raster. Defaults to {}.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add_pace(\n    self,\n    source,\n    wavelengths=None,\n    indexes=None,\n    colormap=\"jet\",\n    vmin=None,\n    vmax=None,\n    nodata=np.nan,\n    attribution=None,\n    layer_name=\"PACE\",\n    zoom_to_layer=True,\n    visible=True,\n    method=\"nearest\",\n    gridded=False,\n    array_args={},\n    **kwargs,\n):\n    \"\"\"Add a PACE dataset to the map.\n        If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and\n        if the raster does not render properly, try installing jupyter-server-proxy using `pip install jupyter-server-proxy`,\n        then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.\n\n        import os\n        os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n    Args:\n        source (str): The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.\n        indexes (int, optional): The band(s) to use. Band indexing starts at 1. Defaults to None.\n        colormap (str, optional): The name of the colormap from `matplotlib` to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.\n        vmin (float, optional): The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.\n        vmax (float, optional): The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.\n        nodata (float, optional): The value from the band to use to interpret as not valid data. Defaults to None.\n        attribution (str, optional): Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.\n        layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n        zoom_to_layer (bool, optional): Whether to zoom to the extent of the layer. Defaults to True.\n        visible (bool, optional): Whether the layer is visible. Defaults to True.\n        array_args (dict, optional): Additional arguments to pass to `array_to_memory_file` when reading the raster. Defaults to {}.\n    \"\"\"\n\n    if isinstance(source, str):\n\n        source = read_pace(source)\n\n    image = pace_to_image(\n        source, wavelengths=wavelengths, method=method, gridded=gridded\n    )\n\n    if isinstance(wavelengths, list) and len(wavelengths) &gt; 1:\n        colormap = None\n\n    self.add_raster(\n        image,\n        indexes=indexes,\n        colormap=colormap,\n        vmin=vmin,\n        vmax=vmax,\n        nodata=nodata,\n        attribution=attribution,\n        layer_name=layer_name,\n        zoom_to_layer=zoom_to_layer,\n        visible=visible,\n        array_args=array_args,\n        **kwargs,\n    )\n\n    self.cog_layer_dict[layer_name][\"xds\"] = source\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add_raster","title":"<code>add_raster(self, source, indexes=None, colormap=None, vmin=None, vmax=None, nodata=None, attribution=None, layer_name='Raster', zoom_to_layer=True, visible=True, array_args={}, **kwargs)</code>","text":"<p>Add a local raster dataset to the map.     If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and     if the raster does not render properly, try installing jupyter-server-proxy using <code>pip install jupyter-server-proxy</code>,     then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.</p> <pre><code>import os\nos.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.</p> required <code>indexes</code> <code>int</code> <p>The band(s) to use. Band indexing starts at 1. Defaults to None.</p> <code>None</code> <code>colormap</code> <code>str</code> <p>The name of the colormap from <code>matplotlib</code> to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.</p> <code>None</code> <code>vmin</code> <code>float</code> <p>The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>nodata</code> <code>float</code> <p>The value from the band to use to interpret as not valid data. Defaults to None.</p> <code>None</code> <code>attribution</code> <code>str</code> <p>Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.</p> <code>None</code> <code>layer_name</code> <code>str</code> <p>The layer name to use. Defaults to 'Raster'.</p> <code>'Raster'</code> <code>zoom_to_layer</code> <code>bool</code> <p>Whether to zoom to the extent of the layer. Defaults to True.</p> <code>True</code> <code>visible</code> <code>bool</code> <p>Whether the layer is visible. Defaults to True.</p> <code>True</code> <code>array_args</code> <code>dict</code> <p>Additional arguments to pass to <code>array_to_memory_file</code> when reading the raster. Defaults to {}.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add_raster(\n    self,\n    source,\n    indexes=None,\n    colormap=None,\n    vmin=None,\n    vmax=None,\n    nodata=None,\n    attribution=None,\n    layer_name=\"Raster\",\n    zoom_to_layer=True,\n    visible=True,\n    array_args={},\n    **kwargs,\n):\n    \"\"\"Add a local raster dataset to the map.\n        If you are using this function in JupyterHub on a remote server (e.g., Binder, Microsoft Planetary Computer) and\n        if the raster does not render properly, try installing jupyter-server-proxy using `pip install jupyter-server-proxy`,\n        then running the following code before calling this function. For more info, see https://bit.ly/3JbmF93.\n\n        import os\n        os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n    Args:\n        source (str): The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.\n        indexes (int, optional): The band(s) to use. Band indexing starts at 1. Defaults to None.\n        colormap (str, optional): The name of the colormap from `matplotlib` to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.\n        vmin (float, optional): The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.\n        vmax (float, optional): The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.\n        nodata (float, optional): The value from the band to use to interpret as not valid data. Defaults to None.\n        attribution (str, optional): Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.\n        layer_name (str, optional): The layer name to use. Defaults to 'Raster'.\n        zoom_to_layer (bool, optional): Whether to zoom to the extent of the layer. Defaults to True.\n        visible (bool, optional): Whether the layer is visible. Defaults to True.\n        array_args (dict, optional): Additional arguments to pass to `array_to_memory_file` when reading the raster. Defaults to {}.\n    \"\"\"\n\n    import numpy as np\n\n    if nodata is None:\n        nodata = np.nan\n    super().add_raster(\n        source,\n        indexes=indexes,\n        colormap=colormap,\n        vmin=vmin,\n        vmax=vmax,\n        nodata=nodata,\n        attribution=attribution,\n        layer_name=layer_name,\n        zoom_to_layer=zoom_to_layer,\n        visible=visible,\n        array_args=array_args,\n        **kwargs,\n    )\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.search_emit","title":"<code>search_emit(self, default_dataset='EMITL2ARFL')</code>","text":"<p>Adds a NASA Earth Data search tool to the map with a default dataset for EMIT.</p> <p>Parameters:</p> Name Type Description Default <code>default_dataset</code> <code>str</code> <p>The default dataset to search for. Defaults to \"EMITL2ARFL\".</p> <code>'EMITL2ARFL'</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def search_emit(self, default_dataset=\"EMITL2ARFL\"):\n    \"\"\"\n    Adds a NASA Earth Data search tool to the map with a default dataset for EMIT.\n\n    Args:\n        default_dataset (str, optional): The default dataset to search for. Defaults to \"EMITL2ARFL\".\n    \"\"\"\n    self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.search_pace","title":"<code>search_pace(self, default_dataset='PACE_OCI_L2_AOP_NRT')</code>","text":"<p>Adds a NASA Earth Data search tool to the map with a default dataset for PACE.</p> <p>Parameters:</p> Name Type Description Default <code>default_dataset</code> <code>str</code> <p>The default dataset to search for. Defaults to \"PACE_OCI_L2_AOP_NRT\".</p> <code>'PACE_OCI_L2_AOP_NRT'</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def search_pace(self, default_dataset=\"PACE_OCI_L2_AOP_NRT\"):\n    \"\"\"\n    Adds a NASA Earth Data search tool to the map with a default dataset for PACE.\n\n    Args:\n        default_dataset (str, optional): The default dataset to search for. Defaults to \"PACE_OCI_L2_AOP_NRT\".\n    \"\"\"\n    self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.set_plot_options","title":"<code>set_plot_options(self, add_marker_cluster=False, plot_type=None, overlay=False, position='bottomright', min_width=None, max_width=None, min_height=None, max_height=None, **kwargs)</code>","text":"<p>Sets plotting options.</p> <p>Parameters:</p> Name Type Description Default <code>add_marker_cluster</code> <code>bool</code> <p>Whether to add a marker cluster. Defaults to False.</p> <code>False</code> <code>sample_scale</code> <code>float</code> <p>A nominal scale in meters of the projection to sample in . Defaults to None.</p> required <code>plot_type</code> <code>str</code> <p>The plot type can be one of \"None\", \"bar\", \"scatter\" or \"hist\". Defaults to None.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay plotted lines on the figure. Defaults to False.</p> <code>False</code> <code>position</code> <code>str</code> <p>Position of the control, can be \u2018bottomleft\u2019, \u2018bottomright\u2019, \u2018topleft\u2019, or \u2018topright\u2019. Defaults to 'bottomright'.</p> <code>'bottomright'</code> <code>min_width</code> <code>int</code> <p>Min width of the widget (in pixels), if None it will respect the content size. Defaults to None.</p> <code>None</code> <code>max_width</code> <code>int</code> <p>Max width of the widget (in pixels), if None it will respect the content size. Defaults to None.</p> <code>None</code> <code>min_height</code> <code>int</code> <p>Min height of the widget (in pixels), if None it will respect the content size. Defaults to None.</p> <code>None</code> <code>max_height</code> <code>int</code> <p>Max height of the widget (in pixels), if None it will respect the content size. Defaults to None.</p> <code>None</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def set_plot_options(\n    self,\n    add_marker_cluster=False,\n    plot_type=None,\n    overlay=False,\n    position=\"bottomright\",\n    min_width=None,\n    max_width=None,\n    min_height=None,\n    max_height=None,\n    **kwargs,\n):\n    \"\"\"Sets plotting options.\n\n    Args:\n        add_marker_cluster (bool, optional): Whether to add a marker cluster. Defaults to False.\n        sample_scale (float, optional):  A nominal scale in meters of the projection to sample in . Defaults to None.\n        plot_type (str, optional): The plot type can be one of \"None\", \"bar\", \"scatter\" or \"hist\". Defaults to None.\n        overlay (bool, optional): Whether to overlay plotted lines on the figure. Defaults to False.\n        position (str, optional): Position of the control, can be \u2018bottomleft\u2019, \u2018bottomright\u2019, \u2018topleft\u2019, or \u2018topright\u2019. Defaults to 'bottomright'.\n        min_width (int, optional): Min width of the widget (in pixels), if None it will respect the content size. Defaults to None.\n        max_width (int, optional): Max width of the widget (in pixels), if None it will respect the content size. Defaults to None.\n        min_height (int, optional): Min height of the widget (in pixels), if None it will respect the content size. Defaults to None.\n        max_height (int, optional): Max height of the widget (in pixels), if None it will respect the content size. Defaults to None.\n\n    \"\"\"\n    plot_options_dict = {}\n    plot_options_dict[\"add_marker_cluster\"] = add_marker_cluster\n    plot_options_dict[\"plot_type\"] = plot_type\n    plot_options_dict[\"overlay\"] = overlay\n    plot_options_dict[\"position\"] = position\n    plot_options_dict[\"min_width\"] = min_width\n    plot_options_dict[\"max_width\"] = max_width\n    plot_options_dict[\"min_height\"] = min_height\n    plot_options_dict[\"max_height\"] = max_height\n\n    for key in kwargs:\n        plot_options_dict[key] = kwargs[key]\n\n    self._plot_options = plot_options_dict\n\n    if not hasattr(self, \"_plot_marker_cluster\"):\n        self._plot_marker_cluster = ipyleaflet.MarkerCluster(name=\"Marker Cluster\")\n\n    if add_marker_cluster and (self._plot_marker_cluster not in self.layers):\n        self.add(self._plot_marker_cluster)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.spectral_to_csv","title":"<code>spectral_to_csv(self, filename, index=True, **kwargs)</code>","text":"<p>Saves the spectral data to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The output CSV file.</p> required <code>index</code> <code>bool</code> <p>Whether to write the index. Defaults to True.</p> <code>True</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def spectral_to_csv(self, filename, index=True, **kwargs):\n    \"\"\"Saves the spectral data to a CSV file.\n\n    Args:\n        filename (str): The output CSV file.\n        index (bool, optional): Whether to write the index. Defaults to True.\n    \"\"\"\n    df = self.spectral_to_df()\n    df = df.rename_axis(\"band\")\n    df.to_csv(filename, index=index, **kwargs)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.spectral_to_df","title":"<code>spectral_to_df(self, **kwargs)</code>","text":"<p>Converts the spectral data to a pandas DataFrame.</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>The spectral data as a pandas DataFrame.</p> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def spectral_to_df(self, **kwargs):\n    \"\"\"Converts the spectral data to a pandas DataFrame.\n\n    Returns:\n        pd.DataFrame: The spectral data as a pandas DataFrame.\n    \"\"\"\n    import pandas as pd\n\n    df = pd.DataFrame(self._spectral_data, **kwargs)\n    return df\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>hypercoast is available on PyPI. To install hypercoast, run this command in your terminal:</p> <pre><code>pip install hypercoast\n</code></pre>"},{"location":"installation/#install-from-conda-forge","title":"Install from conda-forge","text":"<p>hypercoast is also available on conda-forge. If you have Anaconda or Miniconda installed on your computer, you can install hypercoast using the following command:</p> <pre><code>conda install -c conda-forge hypercoast\n</code></pre> <p>Alternatively, you can create a new conda environment and install hypercoast in the new environment. This is a good practice because it avoids potential conflicts with other packages installed in your base environment.</p> <pre><code>conda install -n base mamba -c conda-forge\nconda create -n hyper python=3.11\nconda activate hyper\nmamba install -c conda-forge hypercoast\n</code></pre>"},{"location":"installation/#install-from-github","title":"Install from GitHub","text":"<p>To install the development version from GitHub using Git, run the following command in your terminal:</p> <pre><code>pip install git+https://github.com/opengeos/hypercoast\n</code></pre>"},{"location":"pace/","title":"pace module","text":"<p>This module contains functions to read and process PACE data.</p>"},{"location":"pace/#hypercoast.pace.filter_pace","title":"<code>filter_pace(dataset, latitude, longitude, drop=True, return_plot=False, **kwargs)</code>","text":"<p>Filters a PACE dataset based on latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xr.Dataset</code> <p>The PACE dataset to filter.</p> required <code>latitude</code> <code>float or tuple</code> <p>The latitude to filter by. If a tuple or list, it represents a range.</p> required <code>longitude</code> <code>float or tuple</code> <p>The longitude to filter by. If a tuple or list, it represents a range.</p> required <code>drop</code> <code>bool</code> <p>Whether to drop the filtered out data. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>xr.DataArray</code> <p>The filtered PACE data.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def filter_pace(dataset, latitude, longitude, drop=True, return_plot=False, **kwargs):\n    \"\"\"\n    Filters a PACE dataset based on latitude and longitude.\n\n    Args:\n        dataset (xr.Dataset): The PACE dataset to filter.\n        latitude (float or tuple): The latitude to filter by. If a tuple or list, it represents a range.\n        longitude (float or tuple): The longitude to filter by. If a tuple or list, it represents a range.\n        drop (bool, optional): Whether to drop the filtered out data. Defaults to True.\n\n    Returns:\n        xr.DataArray: The filtered PACE data.\n    \"\"\"\n    if isinstance(latitude, list) or isinstance(latitude, tuple):\n        lat_con = (dataset[\"latitude\"] &gt; latitude[0]) &amp; (\n            dataset[\"latitude\"] &lt; latitude[1]\n        )\n    else:\n        lat_con = dataset[\"latitude\"] == latitude\n\n    if isinstance(longitude, list) or isinstance(longitude, tuple):\n        lon_con = (dataset[\"longitude\"] &gt; longitude[0]) &amp; (\n            dataset[\"longitude\"] &lt; longitude[1]\n        )\n    else:\n        lon_con = dataset[\"longitude\"] == longitude\n\n    da = dataset[\"Rrs\"].where(lat_con &amp; lon_con, drop=drop, **kwargs)\n    da_filtered = da.dropna(dim=\"latitude\", how=\"all\")\n    da_filtered = da_filtered.dropna(dim=\"longitude\", how=\"all\")\n\n    if return_plot:\n        rrs_stack = da_filtered.stack(\n            {\"pixel\": [\"latitude\", \"longitude\"]},\n            create_index=False,\n        )\n        rrs_stack.plot.line(hue=\"pixel\")\n    else:\n        return da_filtered\n</code></pre>"},{"location":"pace/#hypercoast.pace.grid_pace","title":"<code>grid_pace(dataset, wavelengths=None, method='nearest', **kwargs)</code>","text":"<p>Grids a PACE dataset based on latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xr.Dataset</code> <p>The PACE dataset to grid.</p> required <code>wavelengths</code> <code>float or int</code> <p>The wavelength to select.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for griddata interpolation. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the xr.Dataset constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>xr.DataArray</code> <p>The gridded PACE data.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def grid_pace(dataset, wavelengths=None, method=\"nearest\", **kwargs):\n    \"\"\"\n    Grids a PACE dataset based on latitude and longitude.\n\n    Args:\n        dataset (xr.Dataset): The PACE dataset to grid.\n        wavelengths (float or int): The wavelength to select.\n        method (str, optional): The method to use for griddata interpolation.\n            Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to pass to the xr.Dataset constructor.\n\n    Returns:\n        xr.DataArray: The gridded PACE data.\n    \"\"\"\n    from scipy.interpolate import griddata\n\n    if wavelengths is None:\n        wavelengths = dataset.coords[\"wavelength\"].values[0]\n\n    # Ensure wavelengths is a list\n    if not isinstance(wavelengths, list):\n        wavelengths = [wavelengths]\n\n    lat = dataset.latitude\n    lon = dataset.longitude\n\n    grid_lat = np.linspace(lat.min(), lat.max(), lat.shape[0])\n    grid_lon = np.linspace(lon.min(), lon.max(), lon.shape[1])\n    grid_lon_2d, grid_lat_2d = np.meshgrid(grid_lon, grid_lat)\n\n    gridded_data_dict = {}\n    for wavelength in wavelengths:\n        data = dataset.sel(wavelength=wavelength)[\"Rrs\"]\n        gridded_data = griddata(\n            (lat.data.flatten(), lon.data.flatten()),\n            data.data.flatten(),\n            (grid_lat_2d, grid_lon_2d),\n            method=method,\n        )\n        gridded_data_dict[wavelength] = gridded_data\n\n    # Create a 3D array with dimensions latitude, longitude, and wavelength\n    gridded_data_3d = np.dstack(list(gridded_data_dict.values()))\n\n    dataset2 = xr.Dataset(\n        {\"Rrs\": ((\"latitude\", \"longitude\", \"wavelength\"), gridded_data_3d)},\n        coords={\n            \"latitude\": (\"latitude\", grid_lat),\n            \"longitude\": (\"longitude\", grid_lon),\n            \"wavelength\": (\"wavelength\", list(gridded_data_dict.keys())),\n        },\n        **kwargs,\n    )\n\n    dataset2[\"Rrs\"].rio.write_crs(\"EPSG:4326\", inplace=True)\n\n    return dataset2\n</code></pre>"},{"location":"pace/#hypercoast.pace.pace_to_image","title":"<code>pace_to_image(dataset, wavelengths=None, method='nearest', gridded=False, output=None, **kwargs)</code>","text":"<p>Converts an PACE dataset to an image.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xarray.Dataset or str</code> <p>The dataset containing the EMIT data or the file path to the dataset.</p> required <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data interpolation. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>gridded</code> <code>bool</code> <p>Whether the dataset is a gridded dataset. Defaults to False,</p> <code>False</code> <code>output</code> <code>str</code> <p>The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>leafmap.array_to_image</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>rasterio.Dataset or None</code> <p>The image converted from the dataset. If <code>output</code> is provided, the image will be saved to the specified file and the function will return None.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def pace_to_image(\n    dataset, wavelengths=None, method=\"nearest\", gridded=False, output=None, **kwargs\n):\n    \"\"\"\n    Converts an PACE dataset to an image.\n\n    Args:\n        dataset (xarray.Dataset or str): The dataset containing the EMIT data or the file path to the dataset.\n        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data interpolation. Defaults to \"nearest\".\n        gridded (bool, optional): Whether the dataset is a gridded dataset. Defaults to False,\n        output (str, optional): The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.\n        **kwargs: Additional keyword arguments to be passed to `leafmap.array_to_image`.\n\n    Returns:\n        rasterio.Dataset or None: The image converted from the dataset. If `output` is provided, the image will be saved to the specified file and the function will return None.\n    \"\"\"\n    from leafmap import array_to_image\n\n    if isinstance(dataset, str):\n        dataset = read_pace(dataset, wavelengths=wavelengths, method=\"nearest\")\n\n    if wavelengths is not None:\n        dataset = dataset.sel(wavelength=wavelengths, method=\"nearest\")\n\n    if not gridded:\n        grid = grid_pace(dataset, wavelengths=wavelengths, method=method)\n    else:\n        grid = dataset\n    data = grid[\"Rrs\"]\n    data.rio.write_crs(\"EPSG:4326\", inplace=True)\n\n    return array_to_image(data, transpose=False, output=output, **kwargs)\n</code></pre>"},{"location":"pace/#hypercoast.pace.read_pace","title":"<code>read_pace(filepath, wavelengths=None, method='nearest', **kwargs)</code>","text":"<p>Reads PACE data from a given file and returns an xarray Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the file to read.</p> required <code>wavelengths</code> <code>array-like</code> <p>Specific wavelengths to select. If None, all wavelengths are selected.</p> <code>None</code> <code>method</code> <code>str</code> <p>Method to use for selection when wavelengths is not None. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the <code>sel</code> method when wavelengths is not None.</p> <code>{}</code> <p>Returns:</p> Type Description <code>xr.Dataset</code> <p>An xarray Dataset containing the PACE data.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def read_pace(filepath, wavelengths=None, method=\"nearest\", **kwargs):\n    \"\"\"\n    Reads PACE data from a given file and returns an xarray Dataset.\n\n    Args:\n        filepath (str): Path to the file to read.\n        wavelengths (array-like, optional): Specific wavelengths to select. If None, all wavelengths are selected.\n        method (str, optional): Method to use for selection when wavelengths is not None. Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to pass to the `sel` method when wavelengths is not None.\n\n    Returns:\n        xr.Dataset: An xarray Dataset containing the PACE data.\n    \"\"\"\n\n    rrs = xr.open_dataset(filepath, group=\"geophysical_data\")[\"Rrs\"]\n    wvl = xr.open_dataset(filepath, group=\"sensor_band_parameters\")\n    dataset = xr.open_dataset(filepath, group=\"navigation_data\")\n    dataset = dataset.set_coords((\"longitude\", \"latitude\"))\n    dataset = dataset.rename({\"pixel_control_points\": \"pixels_per_line\"})\n    dataset = xr.merge((rrs, dataset.coords))\n    dataset.coords[\"wavelength_3d\"] = wvl.coords[\"wavelength_3d\"]\n    dataset = dataset.rename(\n        {\n            \"number_of_lines\": \"latitude\",\n            \"pixels_per_line\": \"longitude\",\n            \"wavelength_3d\": \"wavelength\",\n        }\n    )\n\n    if wavelengths is not None:\n        dataset = dataset.sel(wavelength=wavelengths, method=method, **kwargs)\n\n    return dataset\n</code></pre>"},{"location":"pace/#hypercoast.pace.viz_pace","title":"<code>viz_pace(dataset, wavelengths=None, method='nearest', figsize=(6.4, 4.8), cmap='jet', vmin=0, vmax=0.02, ncols=1, crs=None, xlim=None, ylim=None, **kwargs)</code>","text":"<p>Plots PACE data from a given xarray Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xr.Dataset</code> <p>An xarray Dataset containing the PACE data.</p> required <code>wavelengths</code> <code>array-like</code> <p>Specific wavelengths to select. If None, all wavelengths are selected.</p> <code>None</code> <code>method</code> <code>str</code> <p>Method to use for selection when wavelengths is not None. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>figsize</code> <code>tuple</code> <p>Figure size. Defaults to (6.4, 4.8).</p> <code>(6.4, 4.8)</code> <code>cmap</code> <code>str</code> <p>Colormap to use. Defaults to \"jet\".</p> <code>'jet'</code> <code>vmin</code> <code>float</code> <p>Minimum value for the colormap. Defaults to 0.</p> <code>0</code> <code>vmax</code> <code>float</code> <p>Maximum value for the colormap. Defaults to 0.02.</p> <code>0.02</code> <code>ncols</code> <code>int</code> <p>Number of columns in the plot. Defaults to 1.</p> <code>1</code> <code>crs</code> <code>str or cartopy.crs.CRS</code> <p>Coordinate reference system to use. If None, a simple plot is created. Defaults to None. See https://scitools.org.uk/cartopy/docs/latest/reference/projections.html</p> <code>None</code> <code>xlim</code> <code>array-like</code> <p>Limits for the x-axis. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>array-like</code> <p>Limits for the y-axis. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the <code>plt.subplots</code> function.</p> <code>{}</code> Source code in <code>hypercoast/pace.py</code> <pre><code>def viz_pace(\n    dataset: Union[xr.Dataset, str],\n    wavelengths: Optional[Union[List[float], float]] = None,\n    method: str = \"nearest\",\n    figsize: Tuple[float, float] = (6.4, 4.8),\n    cmap: str = \"jet\",\n    vmin: float = 0,\n    vmax: float = 0.02,\n    ncols: int = 1,\n    crs: Optional[str] = None,\n    xlim: Optional[List[float]] = None,\n    ylim: Optional[List[float]] = None,\n    **kwargs,\n):\n    \"\"\"\n    Plots PACE data from a given xarray Dataset.\n\n    Args:\n        dataset (xr.Dataset): An xarray Dataset containing the PACE data.\n        wavelengths (array-like, optional): Specific wavelengths to select. If None, all wavelengths are selected.\n        method (str, optional): Method to use for selection when wavelengths is not None. Defaults to \"nearest\".\n        figsize (tuple, optional): Figure size. Defaults to (6.4, 4.8).\n        cmap (str, optional): Colormap to use. Defaults to \"jet\".\n        vmin (float, optional): Minimum value for the colormap. Defaults to 0.\n        vmax (float, optional): Maximum value for the colormap. Defaults to 0.02.\n        ncols (int, optional): Number of columns in the plot. Defaults to 1.\n        crs (str or cartopy.crs.CRS, optional): Coordinate reference system to use. If None, a simple plot is created. Defaults to None.\n            See https://scitools.org.uk/cartopy/docs/latest/reference/projections.html\n        xlim (array-like, optional): Limits for the x-axis. Defaults to None.\n        ylim (array-like, optional): Limits for the y-axis. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the `plt.subplots` function.\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import math\n\n    if isinstance(dataset, str):\n        dataset = read_pace(dataset, wavelengths, method)\n\n    if wavelengths is not None:\n        if not isinstance(wavelengths, list):\n            wavelengths = [wavelengths]\n        dataset = dataset.sel(wavelength=wavelengths, method=method)\n    else:\n        wavelengths = dataset.coords[\"wavelength\"][0].values.tolist()\n\n    lat = dataset.coords[\"latitude\"]\n    lon = dataset.coords[\"longitude\"]\n\n    nrows = math.ceil(len(wavelengths) / ncols)\n\n    if crs is None:\n\n        fig, axes = plt.subplots(\n            nrows=nrows,\n            ncols=ncols,\n            figsize=(figsize[0] * ncols, figsize[1] * nrows),\n            **kwargs,\n        )\n\n        for i in range(nrows):\n            for j in range(ncols):\n                index = i * ncols + j\n                if index &lt; len(wavelengths):\n                    wavelength = wavelengths[index]\n                    data = dataset.sel(wavelength=wavelength, method=method)[\"Rrs\"]\n\n                    if min(nrows, ncols) == 1:\n                        ax = axes[index]\n                    else:\n                        ax = axes[i, j]\n                    im = ax.pcolormesh(\n                        lon, lat, np.squeeze(data), cmap=cmap, vmin=vmin, vmax=vmax\n                    )\n                    ax.set_xlabel(\"Longitude\")\n                    ax.set_ylabel(\"Latitude\")\n                    ax.set_title(\n                        f\"wavelength = {dataset.coords['wavelength'].values[index]} [nm]\"\n                    )\n                    fig.colorbar(im, ax=ax, label=\"Reflectance\")\n\n        plt.tight_layout()\n        plt.show()\n\n    else:\n\n        import cartopy\n        from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n\n        if crs == \"default\":\n            crs = cartopy.crs.PlateCarree()\n\n        if xlim is None:\n            xlim = [math.floor(lon.min()), math.ceil(lon.max())]\n\n        if ylim is None:\n            ylim = [math.floor(lat.min()), math.ceil(lat.max())]\n\n        fig, axes = plt.subplots(\n            nrows=nrows,\n            ncols=ncols,\n            figsize=(figsize[0] * ncols, figsize[1] * nrows),\n            subplot_kw={\"projection\": cartopy.crs.PlateCarree()},\n            **kwargs,\n        )\n\n        for i in range(nrows):\n            for j in range(ncols):\n                index = i * ncols + j\n                if index &lt; len(wavelengths):\n                    wavelength = wavelengths[index]\n                    data = dataset.sel(wavelength=wavelength, method=method)[\"Rrs\"]\n\n                    if min(nrows, ncols) == 1:\n                        ax = axes[index]\n                    else:\n                        ax = axes[i, j]\n                    im = ax.pcolormesh(lon, lat, data, cmap=\"jet\", vmin=0, vmax=0.02)\n                    ax.coastlines()\n                    ax.add_feature(cartopy.feature.STATES, linewidth=0.5)\n                    ax.set_xticks(np.linspace(xlim[0], xlim[1], 5), crs=crs)\n                    ax.set_yticks(np.linspace(ylim[0], ylim[1], 5), crs=crs)\n                    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n                    lat_formatter = LatitudeFormatter()\n                    ax.xaxis.set_major_formatter(lon_formatter)\n                    ax.yaxis.set_major_formatter(lat_formatter)\n                    ax.set_xlabel(\"Longitude\")\n                    ax.set_ylabel(\"Latitude\")\n                    ax.set_title(\n                        f\"wavelength = {dataset.coords['wavelength'].values[index]} [nm]\"\n                    )\n                    plt.colorbar(im, label=\"Reflectance\")\n\n        plt.tight_layout()\n        plt.show()\n</code></pre>"},{"location":"ui/","title":"ui module","text":"<p>This module contains the user interface for the hypercoast package.</p>"},{"location":"ui/#hypercoast.ui.SpectralWidget","title":"<code> SpectralWidget            (HBox)         </code>","text":"<p>A widget for spectral data visualization on a map.</p> <p>Attributes:</p> Name Type Description <code>_host_map</code> <code>Map</code> <p>The map to host the widget.</p> <code>on_close</code> <code>function</code> <p>Function to be called when the widget is closed.</p> <code>_output_widget</code> <code>widgets.Output</code> <p>The output widget to display results.</p> <code>_output_control</code> <code>ipyleaflet.WidgetControl</code> <p>The control for the output widget.</p> <code>_on_map_interaction</code> <code>function</code> <p>Function to handle map interactions.</p> <code>_spectral_widget</code> <code>SpectralWidget</code> <p>The spectral widget itself.</p> <code>_spectral_control</code> <code>ipyleaflet.WidgetControl</code> <p>The control for the spectral widget.</p> Source code in <code>hypercoast/ui.py</code> <pre><code>class SpectralWidget(widgets.HBox):\n    \"\"\"\n    A widget for spectral data visualization on a map.\n\n    Attributes:\n        _host_map (Map): The map to host the widget.\n        on_close (function): Function to be called when the widget is closed.\n        _output_widget (widgets.Output): The output widget to display results.\n        _output_control (ipyleaflet.WidgetControl): The control for the output widget.\n        _on_map_interaction (function): Function to handle map interactions.\n        _spectral_widget (SpectralWidget): The spectral widget itself.\n        _spectral_control (ipyleaflet.WidgetControl): The control for the spectral widget.\n    \"\"\"\n\n    def __init__(self, host_map, position=\"topright\"):\n        \"\"\"\n        Initializes a new instance of the SpectralWidget class.\n\n        Args:\n            host_map (Map): The map to host the widget.\n            position (str, optional): The position of the widget on the map. Defaults to \"topright\".\n        \"\"\"\n        self._host_map = host_map\n        self.on_close = None\n\n        close_btn = widgets.Button(\n            icon=\"times\",\n            tooltip=\"Close the widget\",\n            button_style=\"primary\",\n            layout=widgets.Layout(width=\"32px\"),\n        )\n\n        reset_btn = widgets.Button(\n            icon=\"trash\",\n            tooltip=\"Remove all markers\",\n            button_style=\"primary\",\n            layout=widgets.Layout(width=\"32px\"),\n        )\n\n        def reset_btn_click(_):\n            if hasattr(self._host_map, \"_plot_marker_cluster\"):\n                self._host_map._plot_marker_cluster.markers = []\n                self._host_map._plot_markers = []\n\n            if hasattr(self._host_map, \"_spectral_data\"):\n                self._host_map._spectral_data = {}\n\n            self._output_widget.clear_output()\n\n        reset_btn.on_click(reset_btn_click)\n\n        save_btn = widgets.Button(\n            icon=\"floppy-o\",\n            tooltip=\"Save the data to a CSV\",\n            button_style=\"primary\",\n            layout=widgets.Layout(width=\"32px\"),\n        )\n\n        def chooser_callback(chooser):\n            if chooser.selected:\n                file_path = chooser.selected\n                self._host_map.spectral_to_csv(file_path)\n                if (\n                    hasattr(self._host_map, \"_file_chooser_control\")\n                    and self._host_map._file_chooser_control in self._host_map.controls\n                ):\n                    self._host_map.remove_control(self._host_map._file_chooser_control)\n                    self._host_map._file_chooser.close()\n\n        def save_btn_click(_):\n            if not hasattr(self._host_map, \"_spectral_data\"):\n                return\n\n            self._output_widget.clear_output()\n            file_chooser = FileChooser(\n                os.getcwd(), layout=widgets.Layout(width=\"454px\")\n            )\n            file_chooser.filter_pattern = \"*.csv\"\n            file_chooser.use_dir_icons = True\n            file_chooser.title = \"Save spectral data to a CSV file\"\n            file_chooser.default_filename = \"spectral_data.csv\"\n            file_chooser.show_hidden = False\n            file_chooser.register_callback(chooser_callback)\n            file_chooser_control = ipyleaflet.WidgetControl(\n                widget=file_chooser, position=\"topright\"\n            )\n            self._host_map.add(file_chooser_control)\n            setattr(self._host_map, \"_file_chooser\", file_chooser)\n            setattr(self._host_map, \"_file_chooser_control\", file_chooser_control)\n\n        save_btn.on_click(save_btn_click)\n\n        def close_widget(_):\n            self.cleanup()\n\n        close_btn.on_click(close_widget)\n\n        layer_names = list(host_map.cog_layer_dict.keys())\n        layers_widget = widgets.Dropdown(options=layer_names)\n        layers_widget.layout.width = \"18ex\"\n        super().__init__([layers_widget, reset_btn, save_btn, close_btn])\n\n        output = widgets.Output()\n        output_control = ipyleaflet.WidgetControl(widget=output, position=\"bottomright\")\n        self._output_widget = output\n        self._output_control = output_control\n        self._host_map.add(output_control)\n\n        if not hasattr(self._host_map, \"_spectral_data\"):\n            self._host_map._spectral_data = {}\n\n        def handle_interaction(**kwargs):\n\n            latlon = kwargs.get(\"coordinates\")\n            lat = latlon[0]\n            lon = latlon[1]\n            if kwargs.get(\"type\") == \"click\":\n                layer_name = layers_widget.value\n                with self._output_widget:\n                    self._output_widget.clear_output()\n\n                    if not hasattr(self._host_map, \"_plot_markers\"):\n                        self._host_map._plot_markers = []\n                    markers = self._host_map._plot_markers\n                    marker_cluster = self._host_map._plot_marker_cluster\n                    markers.append(ipyleaflet.Marker(location=latlon))\n                    marker_cluster.markers = markers\n                    self._host_map._plot_marker_cluster = marker_cluster\n\n                    ds = self._host_map.cog_layer_dict[layer_name][\"xds\"]\n                    da = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")[\n                        \"reflectance\"\n                    ]\n\n                    if \"wavelengths\" not in self._host_map._spectral_data:\n                        self._host_map._spectral_data[\"wavelengths\"] = ds[\n                            \"wavelengths\"\n                        ].values\n\n                    self._host_map._spectral_data[f\"({lat:.4f} {lon:.4f})\"] = da.values\n\n                    da[da &lt; 0] = np.nan\n                    # fig, ax = plt.subplots()\n                    # da.plot.line(ax=ax)\n                    # display(fig)\n                    fig_margin = {\"top\": 20, \"bottom\": 35, \"left\": 50, \"right\": 20}\n                    fig = plt.figure(\n                        # title=None,\n                        fig_margin=fig_margin,\n                        layout={\"width\": \"500px\", \"height\": \"300px\"},\n                    )\n                    plt.plot(da.coords[da.dims[0]].values, da.values)\n                    plt.xlabel(\"Wavelength (nm)\")\n                    plt.ylabel(\"Reflectance\")\n                    plt.show()\n\n                self._host_map.default_style = {\"cursor\": \"crosshair\"}\n\n        self._host_map.on_interaction(handle_interaction)\n        self._on_map_interaction = handle_interaction\n\n        self._spectral_widget = self\n        self._spectral_control = ipyleaflet.WidgetControl(\n            widget=self, position=position\n        )\n        self._host_map.add(self._spectral_control)\n\n    def cleanup(self):\n        \"\"\"Removes the widget from the map and performs cleanup.\"\"\"\n        if self._host_map:\n            self._host_map.default_style = {\"cursor\": \"default\"}\n            self._host_map.on_interaction(self._on_map_interaction, remove=True)\n\n            if self._output_control:\n                self._host_map.remove_control(self._output_control)\n\n                if self._output_widget:\n                    self._output_widget.close()\n                    self._output_widget = None\n\n            if self._spectral_control:\n                self._host_map.remove_control(self._spectral_control)\n                self._spectral_control = None\n\n                if self._spectral_widget:\n                    self._spectral_widget.close()\n                    self._spectral_widget = None\n\n            if hasattr(self._host_map, \"_plot_marker_cluster\"):\n                self._host_map._plot_marker_cluster.markers = []\n                self._host_map._plot_markers = []\n\n            if hasattr(self._host_map, \"_spectral_data\"):\n                self._host_map._spectral_data = {}\n\n            if hasattr(self, \"_output_widget\") and self._output_widget is not None:\n                self._output_widget.clear_output()\n\n        if self.on_close is not None:\n            self.on_close()\n</code></pre>"},{"location":"ui/#hypercoast.ui.SpectralWidget.__init__","title":"<code>__init__(self, host_map, position='topright')</code>  <code>special</code>","text":"<p>Initializes a new instance of the SpectralWidget class.</p> <p>Parameters:</p> Name Type Description Default <code>host_map</code> <code>Map</code> <p>The map to host the widget.</p> required <code>position</code> <code>str</code> <p>The position of the widget on the map. Defaults to \"topright\".</p> <code>'topright'</code> Source code in <code>hypercoast/ui.py</code> <pre><code>def __init__(self, host_map, position=\"topright\"):\n    \"\"\"\n    Initializes a new instance of the SpectralWidget class.\n\n    Args:\n        host_map (Map): The map to host the widget.\n        position (str, optional): The position of the widget on the map. Defaults to \"topright\".\n    \"\"\"\n    self._host_map = host_map\n    self.on_close = None\n\n    close_btn = widgets.Button(\n        icon=\"times\",\n        tooltip=\"Close the widget\",\n        button_style=\"primary\",\n        layout=widgets.Layout(width=\"32px\"),\n    )\n\n    reset_btn = widgets.Button(\n        icon=\"trash\",\n        tooltip=\"Remove all markers\",\n        button_style=\"primary\",\n        layout=widgets.Layout(width=\"32px\"),\n    )\n\n    def reset_btn_click(_):\n        if hasattr(self._host_map, \"_plot_marker_cluster\"):\n            self._host_map._plot_marker_cluster.markers = []\n            self._host_map._plot_markers = []\n\n        if hasattr(self._host_map, \"_spectral_data\"):\n            self._host_map._spectral_data = {}\n\n        self._output_widget.clear_output()\n\n    reset_btn.on_click(reset_btn_click)\n\n    save_btn = widgets.Button(\n        icon=\"floppy-o\",\n        tooltip=\"Save the data to a CSV\",\n        button_style=\"primary\",\n        layout=widgets.Layout(width=\"32px\"),\n    )\n\n    def chooser_callback(chooser):\n        if chooser.selected:\n            file_path = chooser.selected\n            self._host_map.spectral_to_csv(file_path)\n            if (\n                hasattr(self._host_map, \"_file_chooser_control\")\n                and self._host_map._file_chooser_control in self._host_map.controls\n            ):\n                self._host_map.remove_control(self._host_map._file_chooser_control)\n                self._host_map._file_chooser.close()\n\n    def save_btn_click(_):\n        if not hasattr(self._host_map, \"_spectral_data\"):\n            return\n\n        self._output_widget.clear_output()\n        file_chooser = FileChooser(\n            os.getcwd(), layout=widgets.Layout(width=\"454px\")\n        )\n        file_chooser.filter_pattern = \"*.csv\"\n        file_chooser.use_dir_icons = True\n        file_chooser.title = \"Save spectral data to a CSV file\"\n        file_chooser.default_filename = \"spectral_data.csv\"\n        file_chooser.show_hidden = False\n        file_chooser.register_callback(chooser_callback)\n        file_chooser_control = ipyleaflet.WidgetControl(\n            widget=file_chooser, position=\"topright\"\n        )\n        self._host_map.add(file_chooser_control)\n        setattr(self._host_map, \"_file_chooser\", file_chooser)\n        setattr(self._host_map, \"_file_chooser_control\", file_chooser_control)\n\n    save_btn.on_click(save_btn_click)\n\n    def close_widget(_):\n        self.cleanup()\n\n    close_btn.on_click(close_widget)\n\n    layer_names = list(host_map.cog_layer_dict.keys())\n    layers_widget = widgets.Dropdown(options=layer_names)\n    layers_widget.layout.width = \"18ex\"\n    super().__init__([layers_widget, reset_btn, save_btn, close_btn])\n\n    output = widgets.Output()\n    output_control = ipyleaflet.WidgetControl(widget=output, position=\"bottomright\")\n    self._output_widget = output\n    self._output_control = output_control\n    self._host_map.add(output_control)\n\n    if not hasattr(self._host_map, \"_spectral_data\"):\n        self._host_map._spectral_data = {}\n\n    def handle_interaction(**kwargs):\n\n        latlon = kwargs.get(\"coordinates\")\n        lat = latlon[0]\n        lon = latlon[1]\n        if kwargs.get(\"type\") == \"click\":\n            layer_name = layers_widget.value\n            with self._output_widget:\n                self._output_widget.clear_output()\n\n                if not hasattr(self._host_map, \"_plot_markers\"):\n                    self._host_map._plot_markers = []\n                markers = self._host_map._plot_markers\n                marker_cluster = self._host_map._plot_marker_cluster\n                markers.append(ipyleaflet.Marker(location=latlon))\n                marker_cluster.markers = markers\n                self._host_map._plot_marker_cluster = marker_cluster\n\n                ds = self._host_map.cog_layer_dict[layer_name][\"xds\"]\n                da = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")[\n                    \"reflectance\"\n                ]\n\n                if \"wavelengths\" not in self._host_map._spectral_data:\n                    self._host_map._spectral_data[\"wavelengths\"] = ds[\n                        \"wavelengths\"\n                    ].values\n\n                self._host_map._spectral_data[f\"({lat:.4f} {lon:.4f})\"] = da.values\n\n                da[da &lt; 0] = np.nan\n                # fig, ax = plt.subplots()\n                # da.plot.line(ax=ax)\n                # display(fig)\n                fig_margin = {\"top\": 20, \"bottom\": 35, \"left\": 50, \"right\": 20}\n                fig = plt.figure(\n                    # title=None,\n                    fig_margin=fig_margin,\n                    layout={\"width\": \"500px\", \"height\": \"300px\"},\n                )\n                plt.plot(da.coords[da.dims[0]].values, da.values)\n                plt.xlabel(\"Wavelength (nm)\")\n                plt.ylabel(\"Reflectance\")\n                plt.show()\n\n            self._host_map.default_style = {\"cursor\": \"crosshair\"}\n\n    self._host_map.on_interaction(handle_interaction)\n    self._on_map_interaction = handle_interaction\n\n    self._spectral_widget = self\n    self._spectral_control = ipyleaflet.WidgetControl(\n        widget=self, position=position\n    )\n    self._host_map.add(self._spectral_control)\n</code></pre>"},{"location":"ui/#hypercoast.ui.SpectralWidget.cleanup","title":"<code>cleanup(self)</code>","text":"<p>Removes the widget from the map and performs cleanup.</p> Source code in <code>hypercoast/ui.py</code> <pre><code>def cleanup(self):\n    \"\"\"Removes the widget from the map and performs cleanup.\"\"\"\n    if self._host_map:\n        self._host_map.default_style = {\"cursor\": \"default\"}\n        self._host_map.on_interaction(self._on_map_interaction, remove=True)\n\n        if self._output_control:\n            self._host_map.remove_control(self._output_control)\n\n            if self._output_widget:\n                self._output_widget.close()\n                self._output_widget = None\n\n        if self._spectral_control:\n            self._host_map.remove_control(self._spectral_control)\n            self._spectral_control = None\n\n            if self._spectral_widget:\n                self._spectral_widget.close()\n                self._spectral_widget = None\n\n        if hasattr(self._host_map, \"_plot_marker_cluster\"):\n            self._host_map._plot_marker_cluster.markers = []\n            self._host_map._plot_markers = []\n\n        if hasattr(self._host_map, \"_spectral_data\"):\n            self._host_map._spectral_data = {}\n\n        if hasattr(self, \"_output_widget\") and self._output_widget is not None:\n            self._output_widget.clear_output()\n\n    if self.on_close is not None:\n        self.on_close()\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use HyperCoast in a project:</p> <pre><code>import hypercoast\n</code></pre>"},{"location":"examples/emit/","title":"Emit","text":"In\u00a0[1]: Copied! <pre># %pip install hypercoast\n</pre> # %pip install hypercoast In\u00a0[2]: Copied! <pre>import hypercoast\n</pre> import hypercoast <p>Download a sample EMIT data file from here.</p> In\u00a0[3]: Copied! <pre>url = \"https://github.com/opengeos/datasets/releases/download/netcdf/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\"\n</pre> url = \"https://github.com/opengeos/datasets/releases/download/netcdf/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\" In\u00a0[4]: Copied! <pre>filepath = \"EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\"\nhypercoast.download_file(url)\n</pre> filepath = \"EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\" hypercoast.download_file(url) <pre>Downloading...\nFrom: https://github.com/opengeos/datasets/releases/download/netcdf/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\nTo: /home/runner/work/HyperCoast/HyperCoast/docs/examples/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\n</pre> <pre>\r  0%|          | 0.00/1.85G [00:00&lt;?, ?B/s]</pre> <pre>\r  0%|          | 4.72M/1.85G [00:00&lt;00:44, 41.6MB/s]</pre> <pre>\r  1%|          | 17.3M/1.85G [00:00&lt;00:24, 75.0MB/s]</pre> <pre>\r  1%|\u258f         | 24.6M/1.85G [00:00&lt;00:33, 55.0MB/s]</pre> <pre>\r  2%|\u258f         | 31.5M/1.85G [00:00&lt;00:31, 58.5MB/s]</pre> <pre>\r  2%|\u258f         | 38.3M/1.85G [00:00&lt;00:29, 60.5MB/s]</pre> <pre>\r  2%|\u258f         | 45.6M/1.85G [00:00&lt;00:28, 62.3MB/s]</pre> <pre>\r  3%|\u258e         | 52.4M/1.85G [00:00&lt;00:28, 62.6MB/s]</pre> <pre>\r  3%|\u258e         | 59.2M/1.85G [00:00&lt;00:29, 60.5MB/s]</pre> <pre>\r  4%|\u258e         | 68.2M/1.85G [00:01&lt;00:26, 67.3MB/s]</pre> <pre>\r  4%|\u258d         | 75.5M/1.85G [00:01&lt;00:26, 66.7MB/s]</pre> <pre>\r  4%|\u258d         | 82.3M/1.85G [00:01&lt;00:26, 66.9MB/s]</pre> <pre>\r  5%|\u258d         | 89.1M/1.85G [00:01&lt;00:26, 66.2MB/s]</pre> <pre>\r  5%|\u258c         | 95.9M/1.85G [00:01&lt;00:27, 64.9MB/s]</pre> <pre>\r  6%|\u258c         | 104M/1.85G [00:01&lt;00:25, 67.3MB/s] </pre> <pre>\r  6%|\u258c         | 111M/1.85G [00:01&lt;00:30, 56.7MB/s]</pre> <pre>\r  6%|\u258b         | 117M/1.85G [00:01&lt;00:30, 56.9MB/s]</pre> <pre>\r  7%|\u258b         | 123M/1.85G [00:02&lt;00:35, 48.6MB/s]</pre> <pre>\r  7%|\u258b         | 130M/1.85G [00:02&lt;00:32, 53.2MB/s]</pre> <pre>\r  7%|\u258b         | 136M/1.85G [00:02&lt;00:32, 53.6MB/s]</pre> <pre>\r  8%|\u258a         | 142M/1.85G [00:02&lt;00:35, 48.5MB/s]</pre> <pre>\r  8%|\u258a         | 148M/1.85G [00:02&lt;00:32, 52.6MB/s]</pre> <pre>\r  8%|\u258a         | 154M/1.85G [00:02&lt;00:31, 53.9MB/s]</pre> <pre>\r  9%|\u258a         | 160M/1.85G [00:02&lt;00:30, 56.3MB/s]</pre> <pre>\r  9%|\u2589         | 167M/1.85G [00:02&lt;00:29, 57.6MB/s]</pre> <pre>\r  9%|\u2589         | 174M/1.85G [00:02&lt;00:28, 59.9MB/s]</pre> <pre>\r 10%|\u2589         | 180M/1.85G [00:03&lt;00:31, 53.1MB/s]</pre> <pre>\r 10%|\u2588         | 186M/1.85G [00:03&lt;00:32, 51.9MB/s]</pre> <pre>\r 10%|\u2588         | 191M/1.85G [00:03&lt;00:35, 47.2MB/s]</pre> <pre>\r 11%|\u2588         | 198M/1.85G [00:03&lt;00:32, 50.4MB/s]</pre> <pre>\r 11%|\u2588         | 204M/1.85G [00:03&lt;00:30, 54.5MB/s]</pre> <pre>\r 11%|\u2588\u258f        | 211M/1.85G [00:03&lt;00:28, 56.6MB/s]</pre> <pre>\r 12%|\u2588\u258f        | 218M/1.85G [00:03&lt;00:27, 59.9MB/s]</pre> <pre>\r 12%|\u2588\u258f        | 225M/1.85G [00:03&lt;00:26, 62.0MB/s]</pre> <pre>\r 12%|\u2588\u258f        | 231M/1.85G [00:03&lt;00:26, 60.3MB/s]</pre> <pre>\r 13%|\u2588\u258e        | 240M/1.85G [00:04&lt;00:24, 64.5MB/s]</pre> <pre>\r 13%|\u2588\u258e        | 247M/1.85G [00:04&lt;00:24, 66.3MB/s]</pre> <pre>\r 14%|\u2588\u258e        | 254M/1.85G [00:04&lt;00:24, 65.5MB/s]</pre> <pre>\r 14%|\u2588\u258d        | 261M/1.85G [00:04&lt;00:26, 60.8MB/s]</pre> <pre>\r 15%|\u2588\u258d        | 269M/1.85G [00:04&lt;00:23, 66.7MB/s]</pre> <pre>\r 15%|\u2588\u258d        | 276M/1.85G [00:04&lt;00:24, 64.5MB/s]</pre> <pre>\r 15%|\u2588\u258c        | 283M/1.85G [00:04&lt;00:28, 54.8MB/s]</pre> <pre>\r 16%|\u2588\u258c        | 290M/1.85G [00:04&lt;00:27, 57.5MB/s]</pre> <pre>\r 16%|\u2588\u258c        | 297M/1.85G [00:05&lt;00:25, 59.8MB/s]</pre> <pre>\r 16%|\u2588\u258b        | 304M/1.85G [00:05&lt;00:25, 61.2MB/s]</pre> <pre>\r 17%|\u2588\u258b        | 310M/1.85G [00:05&lt;00:29, 51.5MB/s]</pre> <pre>\r 17%|\u2588\u258b        | 317M/1.85G [00:05&lt;00:28, 54.3MB/s]</pre> <pre>\r 18%|\u2588\u258a        | 324M/1.85G [00:05&lt;00:25, 59.1MB/s]</pre> <pre>\r 18%|\u2588\u258a        | 331M/1.85G [00:05&lt;00:25, 60.6MB/s]</pre> <pre>\r 18%|\u2588\u258a        | 338M/1.85G [00:05&lt;00:24, 62.6MB/s]</pre> <pre>\r 19%|\u2588\u258a        | 344M/1.85G [00:05&lt;00:23, 63.5MB/s]</pre> <pre>\r 19%|\u2588\u2589        | 351M/1.85G [00:05&lt;00:23, 62.6MB/s]</pre> <pre>\r 19%|\u2588\u2589        | 359M/1.85G [00:06&lt;00:22, 65.9MB/s]</pre> <pre>\r 20%|\u2588\u2589        | 366M/1.85G [00:06&lt;00:22, 65.8MB/s]</pre> <pre>\r 20%|\u2588\u2588        | 373M/1.85G [00:06&lt;00:22, 66.1MB/s]</pre> <pre>\r 21%|\u2588\u2588        | 380M/1.85G [00:06&lt;00:22, 66.2MB/s]</pre> <pre>\r 21%|\u2588\u2588        | 386M/1.85G [00:06&lt;00:22, 65.5MB/s]</pre> <pre>\r 21%|\u2588\u2588\u258f       | 394M/1.85G [00:06&lt;00:21, 66.6MB/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 401M/1.85G [00:06&lt;00:21, 65.9MB/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 408M/1.85G [00:06&lt;00:21, 66.6MB/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 415M/1.85G [00:06&lt;00:21, 66.6MB/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 422M/1.85G [00:07&lt;00:25, 56.1MB/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 428M/1.85G [00:07&lt;00:28, 50.2MB/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 434M/1.85G [00:07&lt;00:27, 51.1MB/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 440M/1.85G [00:07&lt;00:28, 49.3MB/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 445M/1.85G [00:07&lt;00:29, 47.7MB/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 453M/1.85G [00:07&lt;00:25, 54.7MB/s]</pre> <pre>\r 25%|\u2588\u2588\u258d       | 460M/1.85G [00:07&lt;00:24, 57.4MB/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 466M/1.85G [00:07&lt;00:23, 58.9MB/s]</pre> <pre>\r 26%|\u2588\u2588\u258c       | 473M/1.85G [00:08&lt;00:21, 62.7MB/s]</pre> <pre>\r 26%|\u2588\u2588\u258c       | 480M/1.85G [00:08&lt;00:21, 63.4MB/s]</pre> <pre>\r 26%|\u2588\u2588\u258b       | 487M/1.85G [00:08&lt;00:25, 53.9MB/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 493M/1.85G [00:08&lt;00:25, 54.2MB/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 500M/1.85G [00:08&lt;00:22, 59.1MB/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 507M/1.85G [00:08&lt;00:21, 61.2MB/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 514M/1.85G [00:08&lt;00:21, 63.1MB/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 521M/1.85G [00:08&lt;00:22, 58.9MB/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 527M/1.85G [00:08&lt;00:25, 52.6MB/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 533M/1.85G [00:09&lt;00:25, 51.2MB/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 538M/1.85G [00:09&lt;00:30, 42.5MB/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 544M/1.85G [00:09&lt;00:28, 45.5MB/s]</pre> <pre>\r 30%|\u2588\u2588\u2589       | 551M/1.85G [00:09&lt;00:26, 49.4MB/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 557M/1.85G [00:09&lt;00:24, 53.8MB/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 564M/1.85G [00:09&lt;00:22, 57.5MB/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 571M/1.85G [00:09&lt;00:21, 60.3MB/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 578M/1.85G [00:09&lt;00:20, 62.3MB/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 585M/1.85G [00:10&lt;00:21, 58.1MB/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 591M/1.85G [00:10&lt;00:26, 47.2MB/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 598M/1.85G [00:10&lt;00:24, 51.9MB/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 603M/1.85G [00:10&lt;00:40, 30.6MB/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 610M/1.85G [00:10&lt;00:33, 36.8MB/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 617M/1.85G [00:10&lt;00:28, 42.7MB/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258e      | 624M/1.85G [00:11&lt;00:25, 48.1MB/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 631M/1.85G [00:11&lt;00:23, 52.5MB/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 638M/1.85G [00:11&lt;00:21, 56.3MB/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258d      | 644M/1.85G [00:11&lt;00:20, 58.6MB/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258c      | 652M/1.85G [00:11&lt;00:19, 61.9MB/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 659M/1.85G [00:11&lt;00:18, 63.4MB/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 665M/1.85G [00:11&lt;00:18, 64.5MB/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258b      | 672M/1.85G [00:11&lt;00:18, 65.4MB/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 679M/1.85G [00:11&lt;00:21, 53.3MB/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 685M/1.85G [00:12&lt;00:21, 54.7MB/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 692M/1.85G [00:12&lt;00:19, 58.1MB/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 699M/1.85G [00:12&lt;00:19, 60.6MB/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 706M/1.85G [00:12&lt;00:18, 62.3MB/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 713M/1.85G [00:12&lt;00:21, 53.9MB/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u2589      | 718M/1.85G [00:12&lt;00:21, 53.3MB/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u2589      | 725M/1.85G [00:12&lt;00:19, 57.0MB/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2589      | 732M/1.85G [00:12&lt;00:18, 59.6MB/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2589      | 739M/1.85G [00:12&lt;00:17, 62.0MB/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 746M/1.85G [00:13&lt;00:17, 63.5MB/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588      | 752M/1.85G [00:13&lt;00:16, 64.7MB/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588      | 759M/1.85G [00:13&lt;00:16, 65.4MB/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588\u258f     | 766M/1.85G [00:13&lt;00:16, 66.1MB/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 773M/1.85G [00:13&lt;00:18, 58.6MB/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 779M/1.85G [00:13&lt;00:19, 53.9MB/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 786M/1.85G [00:13&lt;00:18, 57.4MB/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 793M/1.85G [00:13&lt;00:17, 60.1MB/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 800M/1.85G [00:13&lt;00:16, 62.2MB/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258e     | 806M/1.85G [00:14&lt;00:16, 63.3MB/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 814M/1.85G [00:14&lt;00:15, 65.0MB/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 821M/1.85G [00:14&lt;00:15, 65.5MB/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258d     | 827M/1.85G [00:14&lt;00:15, 65.7MB/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 835M/1.85G [00:14&lt;00:15, 66.6MB/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 841M/1.85G [00:14&lt;00:15, 66.8MB/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 848M/1.85G [00:14&lt;00:15, 66.8MB/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 856M/1.85G [00:14&lt;00:14, 67.5MB/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 862M/1.85G [00:14&lt;00:17, 56.7MB/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 869M/1.85G [00:15&lt;00:17, 55.0MB/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 875M/1.85G [00:15&lt;00:20, 47.6MB/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 881M/1.85G [00:15&lt;00:18, 52.3MB/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 888M/1.85G [00:15&lt;00:17, 56.2MB/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 895M/1.85G [00:15&lt;00:16, 59.3MB/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u258a     | 902M/1.85G [00:15&lt;00:15, 61.4MB/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 909M/1.85G [00:15&lt;00:15, 60.0MB/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 915M/1.85G [00:15&lt;00:18, 51.7MB/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2589     | 922M/1.85G [00:16&lt;00:16, 55.7MB/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 928M/1.85G [00:16&lt;00:17, 53.9MB/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 934M/1.85G [00:16&lt;00:18, 49.9MB/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588     | 941M/1.85G [00:16&lt;00:16, 53.7MB/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588     | 948M/1.85G [00:16&lt;00:15, 58.8MB/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 954M/1.85G [00:16&lt;00:14, 59.9MB/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 962M/1.85G [00:16&lt;00:14, 61.8MB/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 969M/1.85G [00:16&lt;00:13, 64.6MB/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 976M/1.85G [00:16&lt;00:13, 65.1MB/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 983M/1.85G [00:17&lt;00:13, 65.2MB/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 990M/1.85G [00:17&lt;00:12, 67.4MB/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 997M/1.85G [00:17&lt;00:12, 66.6MB/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 1.00G/1.85G [00:17&lt;00:12, 66.8MB/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 1.01G/1.85G [00:17&lt;00:12, 67.8MB/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 1.02G/1.85G [00:17&lt;00:12, 66.8MB/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 1.03G/1.85G [00:17&lt;00:12, 66.5MB/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 1.03G/1.85G [00:17&lt;00:12, 67.7MB/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 1.04G/1.85G [00:17&lt;00:14, 56.8MB/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 1.05G/1.85G [00:18&lt;00:14, 55.9MB/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 1.05G/1.85G [00:18&lt;00:15, 51.1MB/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 1.06G/1.85G [00:18&lt;00:15, 52.1MB/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 1.07G/1.85G [00:18&lt;00:14, 55.1MB/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 1.07G/1.85G [00:18&lt;00:13, 57.2MB/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 1.08G/1.85G [00:18&lt;00:12, 62.7MB/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u258a    | 1.09G/1.85G [00:18&lt;00:11, 63.8MB/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 1.09G/1.85G [00:18&lt;00:11, 64.6MB/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 1.10G/1.85G [00:18&lt;00:11, 65.5MB/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 1.11G/1.85G [00:19&lt;00:11, 66.2MB/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 1.11G/1.85G [00:19&lt;00:13, 56.0MB/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 1.12G/1.85G [00:19&lt;00:13, 55.4MB/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 1.13G/1.85G [00:19&lt;00:13, 54.1MB/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 1.13G/1.85G [00:19&lt;00:14, 49.4MB/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 1.14G/1.85G [00:19&lt;00:13, 52.8MB/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 1.14G/1.85G [00:19&lt;00:13, 51.9MB/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 1.15G/1.85G [00:19&lt;00:14, 48.7MB/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 1.16G/1.85G [00:20&lt;00:12, 53.5MB/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 1.16G/1.85G [00:20&lt;00:11, 57.3MB/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 1.17G/1.85G [00:20&lt;00:11, 60.2MB/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 1.18G/1.85G [00:20&lt;00:10, 62.3MB/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 1.18G/1.85G [00:20&lt;00:10, 63.7MB/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 1.19G/1.85G [00:20&lt;00:10, 64.9MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 1.20G/1.85G [00:20&lt;00:09, 65.5MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 1.20G/1.85G [00:20&lt;00:09, 66.2MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 1.21G/1.85G [00:20&lt;00:09, 66.7MB/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 1.22G/1.85G [00:20&lt;00:09, 66.7MB/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 1.23G/1.85G [00:21&lt;00:11, 56.9MB/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 1.23G/1.85G [00:21&lt;00:10, 56.9MB/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 1.24G/1.85G [00:21&lt;00:10, 59.3MB/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 1.25G/1.85G [00:21&lt;00:09, 62.0MB/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 1.25G/1.85G [00:21&lt;00:10, 56.0MB/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 1.26G/1.85G [00:21&lt;00:11, 52.9MB/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 1.26G/1.85G [00:21&lt;00:12, 47.5MB/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 1.27G/1.85G [00:21&lt;00:11, 48.6MB/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 1.28G/1.85G [00:22&lt;00:10, 53.4MB/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 1.28G/1.85G [00:22&lt;00:09, 57.3MB/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 1.29G/1.85G [00:22&lt;00:10, 53.6MB/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 1.30G/1.85G [00:22&lt;00:11, 50.4MB/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 1.30G/1.85G [00:22&lt;00:18, 29.1MB/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 1.31G/1.85G [00:22&lt;00:14, 36.4MB/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 1.31G/1.85G [00:23&lt;00:12, 42.6MB/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1.32G/1.85G [00:23&lt;00:11, 48.0MB/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1.33G/1.85G [00:23&lt;00:11, 45.3MB/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1.33G/1.85G [00:23&lt;00:10, 47.2MB/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1.34G/1.85G [00:23&lt;00:11, 44.3MB/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 1.34G/1.85G [00:23&lt;00:12, 40.3MB/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 1.35G/1.85G [00:23&lt;00:11, 43.9MB/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 1.36G/1.85G [00:23&lt;00:09, 49.6MB/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 1.36G/1.85G [00:24&lt;00:08, 54.3MB/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 1.37G/1.85G [00:24&lt;00:08, 57.8MB/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 1.38G/1.85G [00:24&lt;00:08, 53.2MB/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 1.38G/1.85G [00:24&lt;00:09, 50.6MB/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 1.39G/1.85G [00:24&lt;00:08, 55.0MB/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 1.40G/1.85G [00:24&lt;00:07, 58.3MB/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 1.40G/1.85G [00:24&lt;00:07, 61.0MB/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 1.41G/1.85G [00:24&lt;00:07, 62.8MB/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 1.42G/1.85G [00:24&lt;00:06, 65.2MB/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 1.42G/1.85G [00:25&lt;00:07, 57.6MB/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 1.43G/1.85G [00:25&lt;00:07, 54.9MB/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 1.44G/1.85G [00:25&lt;00:07, 56.7MB/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 1.44G/1.85G [00:25&lt;00:06, 60.6MB/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 1.45G/1.85G [00:25&lt;00:06, 62.1MB/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 1.46G/1.85G [00:25&lt;00:06, 64.7MB/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 1.47G/1.85G [00:25&lt;00:05, 65.8MB/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 1.47G/1.85G [00:25&lt;00:05, 66.3MB/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 1.48G/1.85G [00:25&lt;00:05, 67.1MB/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 1.49G/1.85G [00:26&lt;00:06, 56.1MB/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 1.49G/1.85G [00:26&lt;00:06, 56.6MB/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 1.50G/1.85G [00:26&lt;00:05, 59.6MB/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 1.51G/1.85G [00:26&lt;00:05, 58.0MB/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 1.51G/1.85G [00:26&lt;00:06, 52.7MB/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 1.52G/1.85G [00:26&lt;00:06, 48.0MB/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 1.53G/1.85G [00:26&lt;00:06, 49.9MB/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 1.53G/1.85G [00:26&lt;00:06, 53.0MB/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 1.54G/1.85G [00:27&lt;00:05, 56.7MB/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 1.55G/1.85G [00:27&lt;00:05, 60.4MB/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 1.55G/1.85G [00:27&lt;00:05, 52.8MB/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 1.56G/1.85G [00:27&lt;00:05, 56.3MB/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 1.57G/1.85G [00:27&lt;00:05, 48.5MB/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 1.57G/1.85G [00:27&lt;00:05, 52.7MB/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 1.58G/1.85G [00:27&lt;00:04, 56.9MB/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 1.59G/1.85G [00:27&lt;00:04, 60.0MB/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 1.60G/1.85G [00:28&lt;00:04, 62.5MB/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 1.60G/1.85G [00:28&lt;00:03, 64.0MB/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 1.61G/1.85G [00:28&lt;00:03, 65.3MB/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 1.62G/1.85G [00:28&lt;00:03, 66.1MB/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 1.62G/1.85G [00:28&lt;00:04, 56.8MB/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 1.63G/1.85G [00:28&lt;00:03, 57.7MB/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 1.64G/1.85G [00:28&lt;00:04, 51.6MB/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 1.64G/1.85G [00:28&lt;00:03, 52.7MB/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 1.65G/1.85G [00:28&lt;00:03, 56.2MB/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 1.66G/1.85G [00:29&lt;00:03, 58.7MB/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 1.66G/1.85G [00:29&lt;00:02, 63.5MB/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 1.67G/1.85G [00:29&lt;00:02, 64.0MB/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 1.68G/1.85G [00:29&lt;00:02, 64.3MB/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 1.69G/1.85G [00:29&lt;00:02, 67.4MB/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 1.69G/1.85G [00:29&lt;00:02, 66.8MB/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 1.70G/1.85G [00:29&lt;00:02, 61.5MB/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 1.70G/1.85G [00:29&lt;00:02, 48.9MB/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 1.71G/1.85G [00:30&lt;00:02, 53.7MB/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 1.72G/1.85G [00:30&lt;00:02, 57.0MB/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 1.73G/1.85G [00:30&lt;00:02, 55.4MB/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 1.73G/1.85G [00:30&lt;00:02, 52.1MB/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 1.74G/1.85G [00:30&lt;00:02, 56.1MB/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 1.75G/1.85G [00:30&lt;00:01, 59.2MB/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 1.75G/1.85G [00:30&lt;00:01, 53.0MB/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 1.76G/1.85G [00:30&lt;00:01, 53.7MB/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 1.76G/1.85G [00:30&lt;00:01, 57.5MB/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 1.77G/1.85G [00:31&lt;00:01, 60.7MB/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 1.78G/1.85G [00:31&lt;00:01, 62.9MB/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 1.79G/1.85G [00:31&lt;00:01, 58.0MB/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 1.79G/1.85G [00:31&lt;00:01, 53.0MB/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 1.80G/1.85G [00:31&lt;00:00, 56.8MB/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 1.81G/1.85G [00:31&lt;00:00, 56.7MB/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 1.81G/1.85G [00:31&lt;00:00, 63.4MB/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 1.82G/1.85G [00:31&lt;00:00, 54.7MB/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 1.83G/1.85G [00:32&lt;00:00, 54.2MB/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1.83G/1.85G [00:32&lt;00:00, 57.7MB/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1.84G/1.85G [00:32&lt;00:00, 59.4MB/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1.85G/1.85G [00:32&lt;00:00, 63.1MB/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.85G/1.85G [00:32&lt;00:00, 57.0MB/s]</pre> <pre>\n</pre> Out[4]: <pre>'/home/runner/work/HyperCoast/HyperCoast/docs/examples/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc'</pre> <p>Load the dataset as a <code>xarray.Dataset</code> object.</p> In\u00a0[5]: Copied! <pre>dataset = hypercoast.read_emit(filepath)\n</pre> dataset = hypercoast.read_emit(filepath) <p>Visualize the data interactively with HyperCoast.</p> In\u00a0[6]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"SATELLITE\")\nm.add_emit(dataset, wavelengths=[500, 600, 1000], indexes=[3, 2, 1], layer_name=\"EMIT\")\nm.add(\"spectral\")\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"SATELLITE\") m.add_emit(dataset, wavelengths=[500, 600, 1000], indexes=[3, 2, 1], layer_name=\"EMIT\") m.add(\"spectral\") m Out[6]: <p></p>"},{"location":"examples/emit/#visualizing-emit-data-interactively-with-hypercoast","title":"Visualizing EMIT data interactively with HyperCoast\u00b6","text":"<p>This notebook demonstrates how to visualize Earth Surface Mineral Dust Source Investigation (EMIT) data interactively with HyperCoast. This notebook is inspired by the EMIT data visualization tutorial - Exploring_EMIT_L2A_Reflectance.ipynb. We have made it much easier to visualize the data interactively with HyperCoast.</p>"},{"location":"examples/pace/","title":"Pace","text":"In\u00a0[1]: Copied! <pre># %pip install \"hypercoast[extra]\"\n</pre> # %pip install \"hypercoast[extra]\" In\u00a0[2]: Copied! <pre>import hypercoast\n</pre> import hypercoast <p>Download a sample PACE data file from here.</p> In\u00a0[3]: Copied! <pre>url = \"https://github.com/opengeos/datasets/releases/download/netcdf/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\"\n</pre> url = \"https://github.com/opengeos/datasets/releases/download/netcdf/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\" In\u00a0[4]: Copied! <pre>filepath = \"PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\"\nhypercoast.download_file(url)\n</pre> filepath = \"PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\" hypercoast.download_file(url) <pre>Downloading...\nFrom: https://github.com/opengeos/datasets/releases/download/netcdf/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\nTo: /home/runner/work/HyperCoast/HyperCoast/docs/examples/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\n</pre> <pre>\r  0%|          | 0.00/192M [00:00&lt;?, ?B/s]</pre> <pre>\r  4%|\u258d         | 8.39M/192M [00:00&lt;00:02, 79.9MB/s]</pre> <pre>\r  9%|\u258a         | 16.8M/192M [00:00&lt;00:02, 78.0MB/s]</pre> <pre>\r 13%|\u2588\u258e        | 24.6M/192M [00:00&lt;00:02, 77.0MB/s]</pre> <pre>\r 17%|\u2588\u258b        | 32.5M/192M [00:00&lt;00:02, 76.7MB/s]</pre> <pre>\r 21%|\u2588\u2588        | 40.4M/192M [00:00&lt;00:01, 76.5MB/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 48.2M/192M [00:00&lt;00:01, 76.2MB/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 56.1M/192M [00:00&lt;00:01, 76.3MB/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 64.0M/192M [00:00&lt;00:01, 76.1MB/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 71.8M/192M [00:00&lt;00:01, 76.5MB/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588\u258f     | 79.7M/192M [00:01&lt;00:01, 76.4MB/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 87.6M/192M [00:01&lt;00:01, 76.0MB/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2589     | 95.4M/192M [00:01&lt;00:01, 75.8MB/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258e    | 103M/192M [00:01&lt;00:01, 75.9MB/s] </pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 111M/192M [00:01&lt;00:01, 76.0MB/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 119M/192M [00:01&lt;00:00, 76.0MB/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 127M/192M [00:01&lt;00:00, 75.6MB/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 135M/192M [00:01&lt;00:00, 76.3MB/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 143M/192M [00:01&lt;00:00, 76.5MB/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 150M/192M [00:01&lt;00:00, 76.2MB/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 158M/192M [00:02&lt;00:00, 75.9MB/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 166M/192M [00:02&lt;00:00, 76.3MB/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 174M/192M [00:02&lt;00:00, 76.1MB/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 182M/192M [00:02&lt;00:00, 76.5MB/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 190M/192M [00:02&lt;00:00, 76.0MB/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 192M/192M [00:02&lt;00:00, 76.1MB/s]</pre> <pre>\n</pre> Out[4]: <pre>'/home/runner/work/HyperCoast/HyperCoast/docs/examples/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc'</pre> <p>Load the dataset as a <code>xarray.Dataset</code> object.</p> In\u00a0[5]: Copied! <pre>dataset = hypercoast.read_pace(filepath)\n</pre> dataset = hypercoast.read_pace(filepath) In\u00a0[6]: Copied! <pre>hypercoast.viz_pace(dataset, wavelengths=[500, 510, 520, 530], ncols=2)\n</pre> hypercoast.viz_pace(dataset, wavelengths=[500, 510, 520, 530], ncols=2) <p>Add projection.</p> In\u00a0[7]: Copied! <pre>hypercoast.viz_pace(dataset, wavelengths=[500, 510, 520, 530], ncols=2, crs=\"default\")\n</pre> hypercoast.viz_pace(dataset, wavelengths=[500, 510, 520, 530], ncols=2, crs=\"default\") <p>Plot a spectral signature.</p> In\u00a0[8]: Copied! <pre>latitude = 25.493961\nlongitude = -91.25617\nhypercoast.filter_pace(dataset, latitude, longitude, return_plot=True)\n</pre> latitude = 25.493961 longitude = -91.25617 hypercoast.filter_pace(dataset, latitude, longitude, return_plot=True) <p>Plot multiple spectral signatures.</p> In\u00a0[9]: Copied! <pre>latitude = (25.49, 25.50)\nlongitude = (-92, -91.055)\nhypercoast.filter_pace(dataset, latitude, longitude, return_plot=True)\n</pre> latitude = (25.49, 25.50) longitude = (-92, -91.055) hypercoast.filter_pace(dataset, latitude, longitude, return_plot=True) <p>Single-band visualization.</p> In\u00a0[10]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"Hybrid\")\nwavelengths = [450]\nm.add_pace(dataset, wavelengths, colormap=\"jet\", vmin=0, vmax=0.02, layer_name=\"PACE\")\nm.add_colormap(cmap=\"jet\", vmin=0, vmax=0.02, label=\"Reflectance\")\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"Hybrid\") wavelengths = [450] m.add_pace(dataset, wavelengths, colormap=\"jet\", vmin=0, vmax=0.02, layer_name=\"PACE\") m.add_colormap(cmap=\"jet\", vmin=0, vmax=0.02, label=\"Reflectance\") m Out[10]: <p></p> <p>Multiple-band visualization.</p> In\u00a0[11]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"Hybrid\")\nwavelengths = [450, 550, 650]\nm.add_pace(\n    dataset, wavelengths, indexes=[3, 2, 1], vmin=0, vmax=0.02, layer_name=\"PACE\"\n)\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"Hybrid\") wavelengths = [450, 550, 650] m.add_pace(     dataset, wavelengths, indexes=[3, 2, 1], vmin=0, vmax=0.02, layer_name=\"PACE\" ) m Out[11]: <p></p>"},{"location":"examples/pace/#visualizing-pace-data-interactively-with-hypercoast","title":"Visualizing PACE data interactively with HyperCoast\u00b6","text":"<p>This notebook demonstrates how to visualize Plankton, Aerosol, Cloud, ocean Ecosystem (PACE) data interactively with HyperCoast.</p>"}]}