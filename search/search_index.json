{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to hypercoast","text":"<p>A Python package for visualizing and analyzing hyperspectral data in coastal regions</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://hypercoast.org</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Interactive visualization and analysis of hyperspectral data, such as EMIT, PACE, DESIS, NEON AOP</li> <li>Interactive visualization of NASA ECOSTRESS data</li> <li>Interactive extraction and visualization of spectral signatures</li> <li>Saving spectral signatures as CSV files</li> </ul>"},{"location":"#demos","title":"Demos","text":"<ul> <li>Visualizing NASA EMIT hyperspectral data interactively</li> </ul> <ul> <li>Visualizing NASA PACE hyperspectral data interactively</li> </ul> <ul> <li>Visualizing DESIS hyperspectral data interactively</li> </ul> <ul> <li>Visualizing NEON AOP hyperspectral data interactively</li> </ul>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>This projects draws inspiration and adapts source code from the nasa/EMIT-Data-Resources repository. Credit goes to the original authors.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"common/","title":"common module","text":"<p>The common module contains common functions and classes used by the other modules.</p>"},{"location":"common/#hypercoast.common.convert_coords","title":"<code>convert_coords(coords, from_epsg, to_epsg)</code>","text":"<p>Convert a list of coordinates from one EPSG to another.</p> <p>Parameters:</p> Name Type Description Default <code>coords</code> <code>List[Tuple[float, float]]</code> <p>List of tuples containing coordinates in the format (latitude, longitude).</p> required <code>from_epsg</code> <code>str</code> <p>Source EPSG code (default is \"epsg:4326\").</p> required <code>to_epsg</code> <code>str</code> <p>Target EPSG code (default is \"epsg:32615\").</p> required <p>Returns:</p> Type Description <code>List[Tuple[float, float]]</code> <p>List of tuples containing converted coordinates in the format (x, y).</p> Source code in <code>hypercoast/common.py</code> <pre><code>def convert_coords(\n    coords: List[Tuple[float, float]], from_epsg: str, to_epsg: str\n) -&gt; List[Tuple[float, float]]:\n    \"\"\"\n    Convert a list of coordinates from one EPSG to another.\n\n    Args:\n        coords: List of tuples containing coordinates in the format (latitude, longitude).\n        from_epsg: Source EPSG code (default is \"epsg:4326\").\n        to_epsg: Target EPSG code (default is \"epsg:32615\").\n\n    Returns:\n        List of tuples containing converted coordinates in the format (x, y).\n    \"\"\"\n    import pyproj\n\n    # Define the coordinate transformation\n    transformer = pyproj.Transformer.from_crs(from_epsg, to_epsg, always_xy=True)\n\n    # Convert each coordinate\n    converted_coords = [transformer.transform(lon, lat) for lat, lon in coords]\n\n    return converted_coords\n</code></pre>"},{"location":"common/#hypercoast.common.download_ecostress","title":"<code>download_ecostress(granules, out_dir=None, threads=8)</code>","text":"<p>Downloads NASA ECOSTRESS granules.</p> <p>Parameters:</p> Name Type Description Default <code>granules</code> <code>List[dict]</code> <p>The granules to download.</p> required <code>out_dir</code> <code>str</code> <p>The output directory where the granules will be downloaded. Defaults to None (current directory).</p> <code>None</code> <code>threads</code> <code>int</code> <p>The number of threads to use for downloading. Defaults to 8.</p> <code>8</code> Source code in <code>hypercoast/common.py</code> <pre><code>def download_ecostress(\n    granules: List[dict],\n    out_dir: Optional[str] = None,\n    threads: int = 8,\n) -&gt; None:\n    \"\"\"Downloads NASA ECOSTRESS granules.\n\n    Args:\n        granules (List[dict]): The granules to download.\n        out_dir (str, optional): The output directory where the granules will be\n            downloaded. Defaults to None (current directory).\n        threads (int, optional): The number of threads to use for downloading.\n            Defaults to 8.\n    \"\"\"\n\n    download_nasa_data(granules=granules, out_dir=out_dir, threads=threads)\n</code></pre>"},{"location":"common/#hypercoast.common.download_emit","title":"<code>download_emit(granules, out_dir=None, threads=8)</code>","text":"<p>Downloads NASA EMIT granules.</p> <p>Parameters:</p> Name Type Description Default <code>granules</code> <code>List[dict]</code> <p>The granules to download.</p> required <code>out_dir</code> <code>str</code> <p>The output directory where the granules will be downloaded. Defaults to None (current directory).</p> <code>None</code> <code>threads</code> <code>int</code> <p>The number of threads to use for downloading. Defaults to 8.</p> <code>8</code> Source code in <code>hypercoast/common.py</code> <pre><code>def download_emit(\n    granules: List[dict],\n    out_dir: Optional[str] = None,\n    threads: int = 8,\n) -&gt; None:\n    \"\"\"Downloads NASA EMIT granules.\n\n    Args:\n        granules (List[dict]): The granules to download.\n        out_dir (str, optional): The output directory where the granules will be\n            downloaded. Defaults to None (current directory).\n        threads (int, optional): The number of threads to use for downloading.\n            Defaults to 8.\n    \"\"\"\n\n    download_nasa_data(granules=granules, out_dir=out_dir, threads=threads)\n</code></pre>"},{"location":"common/#hypercoast.common.download_file","title":"<code>download_file(url=None, output=None, quiet=False, proxy=None, speed=None, use_cookies=True, verify=True, id=None, fuzzy=False, resume=False, unzip=True, overwrite=False, subfolder=False)</code>","text":"<p>Download a file from URL, including Google Drive shared URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Google Drive URL is also supported. Defaults to None.</p> <code>None</code> <code>output</code> <code>str</code> <p>Output filename. Default is basename of URL.</p> <code>None</code> <code>quiet</code> <code>bool</code> <p>Suppress terminal output. Default is False.</p> <code>False</code> <code>proxy</code> <code>str</code> <p>Proxy. Defaults to None.</p> <code>None</code> <code>speed</code> <code>float</code> <p>Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.</p> <code>None</code> <code>use_cookies</code> <code>bool</code> <p>Flag to use cookies. Defaults to True.</p> <code>True</code> <code>verify</code> <code>bool | str</code> <p>Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string, in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.</p> <code>True</code> <code>id</code> <code>str</code> <p>Google Drive's file ID. Defaults to None.</p> <code>None</code> <code>fuzzy</code> <code>bool</code> <p>Fuzzy extraction of Google Drive's file Id. Defaults to False.</p> <code>False</code> <code>resume</code> <code>bool</code> <p>Resume the download from existing tmp file if possible. Defaults to False.</p> <code>False</code> <code>unzip</code> <code>bool</code> <p>Unzip the file. Defaults to True.</p> <code>True</code> <code>overwrite</code> <code>bool</code> <p>Overwrite the file if it already exists. Defaults to False.</p> <code>False</code> <code>subfolder</code> <code>bool</code> <p>Create a subfolder with the same name as the file. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The output file path.</p> Source code in <code>hypercoast/common.py</code> <pre><code>def download_file(\n    url=None,\n    output=None,\n    quiet=False,\n    proxy=None,\n    speed=None,\n    use_cookies=True,\n    verify=True,\n    id=None,\n    fuzzy=False,\n    resume=False,\n    unzip=True,\n    overwrite=False,\n    subfolder=False,\n):\n    \"\"\"Download a file from URL, including Google Drive shared URL.\n\n    Args:\n        url (str, optional): Google Drive URL is also supported. Defaults to None.\n        output (str, optional): Output filename. Default is basename of URL.\n        quiet (bool, optional): Suppress terminal output. Default is False.\n        proxy (str, optional): Proxy. Defaults to None.\n        speed (float, optional): Download byte size per second (e.g., 256KB/s = 256 * 1024). Defaults to None.\n        use_cookies (bool, optional): Flag to use cookies. Defaults to True.\n        verify (bool | str, optional): Either a bool, in which case it controls whether the server's TLS certificate is verified, or a string,\n            in which case it must be a path to a CA bundle to use. Default is True.. Defaults to True.\n        id (str, optional): Google Drive's file ID. Defaults to None.\n        fuzzy (bool, optional): Fuzzy extraction of Google Drive's file Id. Defaults to False.\n        resume (bool, optional): Resume the download from existing tmp file if possible. Defaults to False.\n        unzip (bool, optional): Unzip the file. Defaults to True.\n        overwrite (bool, optional): Overwrite the file if it already exists. Defaults to False.\n        subfolder (bool, optional): Create a subfolder with the same name as the file. Defaults to False.\n\n    Returns:\n        str: The output file path.\n    \"\"\"\n    import zipfile\n    import tarfile\n    import gdown\n\n    if output is None:\n        if isinstance(url, str) and url.startswith(\"http\"):\n            output = os.path.basename(url)\n\n    out_dir = os.path.abspath(os.path.dirname(output))\n    if not os.path.exists(out_dir):\n        os.makedirs(out_dir)\n\n    if isinstance(url, str):\n        if os.path.exists(os.path.abspath(output)) and (not overwrite):\n            print(\n                f\"{output} already exists. Skip downloading. Set overwrite=True to overwrite.\"\n            )\n            return os.path.abspath(output)\n        else:\n            url = github_raw_url(url)\n\n    if \"https://drive.google.com/file/d/\" in url:\n        fuzzy = True\n\n    output = gdown.download(\n        url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume\n    )\n\n    if unzip:\n        if output.endswith(\".zip\"):\n            with zipfile.ZipFile(output, \"r\") as zip_ref:\n                if not quiet:\n                    print(\"Extracting files...\")\n                if subfolder:\n                    basename = os.path.splitext(os.path.basename(output))[0]\n\n                    output = os.path.join(out_dir, basename)\n                    if not os.path.exists(output):\n                        os.makedirs(output)\n                    zip_ref.extractall(output)\n                else:\n                    zip_ref.extractall(os.path.dirname(output))\n        elif output.endswith(\".tar.gz\") or output.endswith(\".tar\"):\n            if output.endswith(\".tar.gz\"):\n                mode = \"r:gz\"\n            else:\n                mode = \"r\"\n\n            with tarfile.open(output, mode) as tar_ref:\n                if not quiet:\n                    print(\"Extracting files...\")\n                if subfolder:\n                    basename = os.path.splitext(os.path.basename(output))[0]\n                    output = os.path.join(out_dir, basename)\n                    if not os.path.exists(output):\n                        os.makedirs(output)\n                    tar_ref.extractall(output)\n                else:\n                    tar_ref.extractall(os.path.dirname(output))\n\n    return os.path.abspath(output)\n</code></pre>"},{"location":"common/#hypercoast.common.download_nasa_data","title":"<code>download_nasa_data(granules, out_dir=None, provider=None, threads=8)</code>","text":"<p>Downloads NASA Earthdata granules.</p> <p>Parameters:</p> Name Type Description Default <code>granules</code> <code>List[dict]</code> <p>The granules to download.</p> required <code>out_dir</code> <code>str</code> <p>The output directory where the granules will be downloaded. Defaults to None (current directory).</p> <code>None</code> <code>provider</code> <code>str</code> <p>The provider of the granules.</p> <code>None</code> <code>threads</code> <code>int</code> <p>The number of threads to use for downloading. Defaults to 8.</p> <code>8</code> Source code in <code>hypercoast/common.py</code> <pre><code>def download_nasa_data(\n    granules: List[dict],\n    out_dir: Optional[str] = None,\n    provider: Optional[str] = None,\n    threads: int = 8,\n) -&gt; None:\n    \"\"\"Downloads NASA Earthdata granules.\n\n    Args:\n        granules (List[dict]): The granules to download.\n        out_dir (str, optional): The output directory where the granules will be downloaded. Defaults to None (current directory).\n        provider (str, optional): The provider of the granules.\n        threads (int, optional): The number of threads to use for downloading. Defaults to 8.\n    \"\"\"\n\n    leafmap.nasa_data_download(\n        granules=granules, out_dir=out_dir, provider=provider, threads=threads\n    )\n</code></pre>"},{"location":"common/#hypercoast.common.download_pace","title":"<code>download_pace(granules, out_dir=None, threads=8)</code>","text":"<p>Downloads NASA PACE granules.</p> <p>Parameters:</p> Name Type Description Default <code>granules</code> <code>List[dict]</code> <p>The granules to download.</p> required <code>out_dir</code> <code>str</code> <p>The output directory where the granules will be downloaded. Defaults to None (current directory).</p> <code>None</code> <code>threads</code> <code>int</code> <p>The number of threads to use for downloading. Defaults to 8.</p> <code>8</code> Source code in <code>hypercoast/common.py</code> <pre><code>def download_pace(\n    granules: List[dict],\n    out_dir: Optional[str] = None,\n    threads: int = 8,\n) -&gt; None:\n    \"\"\"Downloads NASA PACE granules.\n\n    Args:\n        granules (List[dict]): The granules to download.\n        out_dir (str, optional): The output directory where the granules will be\n            downloaded. Defaults to None (current directory).\n        threads (int, optional): The number of threads to use for downloading.\n            Defaults to 8.\n    \"\"\"\n\n    download_nasa_data(granules=granules, out_dir=out_dir, threads=threads)\n</code></pre>"},{"location":"common/#hypercoast.common.github_raw_url","title":"<code>github_raw_url(url)</code>","text":"<p>Get the raw URL for a GitHub file.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The GitHub URL.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The raw URL.</p> Source code in <code>hypercoast/common.py</code> <pre><code>def github_raw_url(url):\n    \"\"\"Get the raw URL for a GitHub file.\n\n    Args:\n        url (str): The GitHub URL.\n    Returns:\n        str: The raw URL.\n    \"\"\"\n    if isinstance(url, str) and url.startswith(\"https://github.com/\") and \"blob\" in url:\n        url = url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\n            \"blob/\", \"\"\n        )\n    return url\n</code></pre>"},{"location":"common/#hypercoast.common.nasa_earth_login","title":"<code>nasa_earth_login(strategy='all', persist=True, **kwargs)</code>","text":"<p>Logs in to NASA Earthdata.</p> <p>Parameters:</p> Name Type Description Default <code>strategy</code> <code>str</code> <p>The login strategy. Defaults to \"all\".</p> <code>'all'</code> <code>persist</code> <code>bool</code> <p>Whether to persist the login. Defaults to True.</p> <code>True</code> Source code in <code>hypercoast/common.py</code> <pre><code>def nasa_earth_login(strategy: str = \"all\", persist: bool = True, **kwargs) -&gt; None:\n    \"\"\"Logs in to NASA Earthdata.\n\n    Args:\n        strategy (str, optional): The login strategy. Defaults to \"all\".\n        persist (bool, optional): Whether to persist the login. Defaults to True.\n    \"\"\"\n\n    leafmap.nasa_data_login(strategy=strategy, persist=persist, **kwargs)\n</code></pre>"},{"location":"common/#hypercoast.common.netcdf_groups","title":"<code>netcdf_groups(filepath)</code>","text":"<p>Get the list of groups in a NetCDF file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The path to the NetCDF file.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of group names in the NetCDF file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; netcdf_groups('path/to/netcdf/file')\n['group1', 'group2', 'group3']\n</code></pre> Source code in <code>hypercoast/common.py</code> <pre><code>def netcdf_groups(filepath: str) -&gt; List[str]:\n    \"\"\"\n    Get the list of groups in a NetCDF file.\n\n    Args:\n        filepath (str): The path to the NetCDF file.\n\n    Returns:\n        list: A list of group names in the NetCDF file.\n\n    Example:\n        &gt;&gt;&gt; netcdf_groups('path/to/netcdf/file')\n        ['group1', 'group2', 'group3']\n    \"\"\"\n    import h5netcdf\n\n    with h5netcdf.File(filepath) as file:\n        groups = list(file)\n    return groups\n</code></pre>"},{"location":"common/#hypercoast.common.search_ecostress","title":"<code>search_ecostress(bbox=None, temporal=None, count=-1, short_name='ECO_L2T_LSTE', output=None, crs='EPSG:4326', return_gdf=False, **kwargs)</code>","text":"<p>Searches for NASA ECOSTRESS granules.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>List[float]</code> <p>The bounding box coordinates [xmin, ymin, xmax, ymax].</p> <code>None</code> <code>temporal</code> <code>str</code> <p>The temporal extent of the data.</p> <code>None</code> <code>count</code> <code>int</code> <p>The number of granules to retrieve. Defaults to -1 (retrieve all).</p> <code>-1</code> <code>short_name</code> <code>str</code> <p>The short name of the dataset. Defaults to \"ECO_L2T_LSTE\".</p> <code>'ECO_L2T_LSTE'</code> <code>output</code> <code>str</code> <p>The output file path to save the GeoDataFrame as a file.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system (CRS) of the GeoDataFrame. Defaults to \"EPSG:4326\".</p> <code>'EPSG:4326'</code> <code>return_gdf</code> <code>bool</code> <p>Whether to return the GeoDataFrame in addition to the granules. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for the earthaccess.search_data() function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[List[dict], tuple]</code> <p>The retrieved granules. If return_gdf is True, also returns the resulting GeoDataFrame.</p> Source code in <code>hypercoast/common.py</code> <pre><code>def search_ecostress(\n    bbox: Optional[List[float]] = None,\n    temporal: Optional[str] = None,\n    count: int = -1,\n    short_name: Optional[str] = \"ECO_L2T_LSTE\",\n    output: Optional[str] = None,\n    crs: str = \"EPSG:4326\",\n    return_gdf: bool = False,\n    **kwargs,\n) -&gt; Union[List[dict], tuple]:\n    \"\"\"Searches for NASA ECOSTRESS granules.\n\n    Args:\n        bbox (List[float], optional): The bounding box coordinates [xmin, ymin, xmax, ymax].\n        temporal (str, optional): The temporal extent of the data.\n        count (int, optional): The number of granules to retrieve. Defaults to -1 (retrieve all).\n        short_name (str, optional): The short name of the dataset. Defaults to \"ECO_L2T_LSTE\".\n        output (str, optional): The output file path to save the GeoDataFrame as a file.\n        crs (str, optional): The coordinate reference system (CRS) of the GeoDataFrame. Defaults to \"EPSG:4326\".\n        return_gdf (bool, optional): Whether to return the GeoDataFrame in addition to the granules. Defaults to False.\n        **kwargs: Additional keyword arguments for the earthaccess.search_data() function.\n\n    Returns:\n        Union[List[dict], tuple]: The retrieved granules. If return_gdf is True, also returns the resulting GeoDataFrame.\n    \"\"\"\n\n    return search_nasa_data(\n        count=count,\n        short_name=short_name,\n        bbox=bbox,\n        temporal=temporal,\n        output=output,\n        crs=crs,\n        return_gdf=return_gdf,\n        **kwargs,\n    )\n</code></pre>"},{"location":"common/#hypercoast.common.search_emit","title":"<code>search_emit(bbox=None, temporal=None, count=-1, short_name='EMITL2ARFL', output=None, crs='EPSG:4326', return_gdf=False, **kwargs)</code>","text":"<p>Searches for NASA EMIT granules.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>List[float]</code> <p>The bounding box coordinates [xmin, ymin, xmax, ymax].</p> <code>None</code> <code>temporal</code> <code>str</code> <p>The temporal extent of the data.</p> <code>None</code> <code>count</code> <code>int</code> <p>The number of granules to retrieve. Defaults to -1 (retrieve all).</p> <code>-1</code> <code>short_name</code> <code>str</code> <p>The short name of the dataset. Defaults to \"EMITL2ARFL\".</p> <code>'EMITL2ARFL'</code> <code>output</code> <code>str</code> <p>The output file path to save the GeoDataFrame as a file.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system (CRS) of the GeoDataFrame. Defaults to \"EPSG:4326\".</p> <code>'EPSG:4326'</code> <code>return_gdf</code> <code>bool</code> <p>Whether to return the GeoDataFrame in addition to the granules. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for the earthaccess.search_data() function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[List[dict], tuple]</code> <p>The retrieved granules. If return_gdf is True, also returns the resulting GeoDataFrame.</p> Source code in <code>hypercoast/common.py</code> <pre><code>def search_emit(\n    bbox: Optional[List[float]] = None,\n    temporal: Optional[str] = None,\n    count: int = -1,\n    short_name: Optional[str] = \"EMITL2ARFL\",\n    output: Optional[str] = None,\n    crs: str = \"EPSG:4326\",\n    return_gdf: bool = False,\n    **kwargs,\n) -&gt; Union[List[dict], tuple]:\n    \"\"\"Searches for NASA EMIT granules.\n\n    Args:\n        bbox (List[float], optional): The bounding box coordinates [xmin, ymin, xmax, ymax].\n        temporal (str, optional): The temporal extent of the data.\n        count (int, optional): The number of granules to retrieve. Defaults to -1 (retrieve all).\n        short_name (str, optional): The short name of the dataset. Defaults to \"EMITL2ARFL\".\n        output (str, optional): The output file path to save the GeoDataFrame as a file.\n        crs (str, optional): The coordinate reference system (CRS) of the GeoDataFrame. Defaults to \"EPSG:4326\".\n        return_gdf (bool, optional): Whether to return the GeoDataFrame in addition to the granules. Defaults to False.\n        **kwargs: Additional keyword arguments for the earthaccess.search_data() function.\n\n    Returns:\n        Union[List[dict], tuple]: The retrieved granules. If return_gdf is True, also returns the resulting GeoDataFrame.\n    \"\"\"\n\n    return search_nasa_data(\n        count=count,\n        short_name=short_name,\n        bbox=bbox,\n        temporal=temporal,\n        output=output,\n        crs=crs,\n        return_gdf=return_gdf,\n        **kwargs,\n    )\n</code></pre>"},{"location":"common/#hypercoast.common.search_nasa_data","title":"<code>search_nasa_data(count=-1, short_name=None, bbox=None, temporal=None, version=None, doi=None, daac=None, provider=None, output=None, crs='EPSG:4326', return_gdf=False, **kwargs)</code>","text":"<p>Searches for NASA Earthdata granules.</p> <p>Parameters:</p> Name Type Description Default <code>count</code> <code>int</code> <p>The number of granules to retrieve. Defaults to -1 (retrieve all).</p> <code>-1</code> <code>short_name</code> <code>str</code> <p>The short name of the dataset.</p> <code>None</code> <code>bbox</code> <code>List[float]</code> <p>The bounding box coordinates [xmin, ymin, xmax, ymax].</p> <code>None</code> <code>temporal</code> <code>str</code> <p>The temporal extent of the data.</p> <code>None</code> <code>version</code> <code>str</code> <p>The version of the dataset.</p> <code>None</code> <code>doi</code> <code>str</code> <p>The Digital Object Identifier (DOI) of the dataset.</p> <code>None</code> <code>daac</code> <code>str</code> <p>The Distributed Active Archive Center (DAAC) of the dataset.</p> <code>None</code> <code>provider</code> <code>str</code> <p>The provider of the dataset.</p> <code>None</code> <code>output</code> <code>str</code> <p>The output file path to save the GeoDataFrame as a file.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system (CRS) of the GeoDataFrame. Defaults to \"EPSG:4326\".</p> <code>'EPSG:4326'</code> <code>return_gdf</code> <code>bool</code> <p>Whether to return the GeoDataFrame in addition to the granules. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for the earthaccess.search_data() function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[List[dict], tuple]</code> <p>The retrieved granules. If return_gdf is True, also returns the resulting GeoDataFrame.</p> Source code in <code>hypercoast/common.py</code> <pre><code>def search_nasa_data(\n    count: int = -1,\n    short_name: Optional[str] = None,\n    bbox: Optional[List[float]] = None,\n    temporal: Optional[str] = None,\n    version: Optional[str] = None,\n    doi: Optional[str] = None,\n    daac: Optional[str] = None,\n    provider: Optional[str] = None,\n    output: Optional[str] = None,\n    crs: str = \"EPSG:4326\",\n    return_gdf: bool = False,\n    **kwargs,\n) -&gt; Union[List[dict], tuple]:\n    \"\"\"Searches for NASA Earthdata granules.\n\n    Args:\n        count (int, optional): The number of granules to retrieve. Defaults to -1 (retrieve all).\n        short_name (str, optional): The short name of the dataset.\n        bbox (List[float], optional): The bounding box coordinates [xmin, ymin, xmax, ymax].\n        temporal (str, optional): The temporal extent of the data.\n        version (str, optional): The version of the dataset.\n        doi (str, optional): The Digital Object Identifier (DOI) of the dataset.\n        daac (str, optional): The Distributed Active Archive Center (DAAC) of the dataset.\n        provider (str, optional): The provider of the dataset.\n        output (str, optional): The output file path to save the GeoDataFrame as a file.\n        crs (str, optional): The coordinate reference system (CRS) of the GeoDataFrame. Defaults to \"EPSG:4326\".\n        return_gdf (bool, optional): Whether to return the GeoDataFrame in addition to the granules. Defaults to False.\n        **kwargs: Additional keyword arguments for the earthaccess.search_data() function.\n\n    Returns:\n        Union[List[dict], tuple]: The retrieved granules. If return_gdf is True, also returns the resulting GeoDataFrame.\n    \"\"\"\n\n    return leafmap.nasa_data_search(\n        count=count,\n        short_name=short_name,\n        bbox=bbox,\n        temporal=temporal,\n        version=version,\n        doi=doi,\n        daac=daac,\n        provider=provider,\n        output=output,\n        crs=crs,\n        return_gdf=return_gdf,\n        **kwargs,\n    )\n</code></pre>"},{"location":"common/#hypercoast.common.search_pace","title":"<code>search_pace(bbox=None, temporal=None, count=-1, short_name='PACE_OCI_L2_AOP_NRT', output=None, crs='EPSG:4326', return_gdf=False, **kwargs)</code>","text":"<p>Searches for NASA PACE granules.</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>List[float]</code> <p>The bounding box coordinates [xmin, ymin, xmax, ymax].</p> <code>None</code> <code>temporal</code> <code>str</code> <p>The temporal extent of the data.</p> <code>None</code> <code>count</code> <code>int</code> <p>The number of granules to retrieve. Defaults to -1 (retrieve all).</p> <code>-1</code> <code>short_name</code> <code>str</code> <p>The short name of the dataset. Defaults to \"PACE_OCI_L2_AOP_NRT\".</p> <code>'PACE_OCI_L2_AOP_NRT'</code> <code>output</code> <code>str</code> <p>The output file path to save the GeoDataFrame as a file.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system (CRS) of the GeoDataFrame. Defaults to \"EPSG:4326\".</p> <code>'EPSG:4326'</code> <code>return_gdf</code> <code>bool</code> <p>Whether to return the GeoDataFrame in addition to the granules. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for the earthaccess.search_data() function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[List[dict], tuple]</code> <p>The retrieved granules. If return_gdf is True, also returns the resulting GeoDataFrame.</p> Source code in <code>hypercoast/common.py</code> <pre><code>def search_pace(\n    bbox: Optional[List[float]] = None,\n    temporal: Optional[str] = None,\n    count: int = -1,\n    short_name: Optional[str] = \"PACE_OCI_L2_AOP_NRT\",\n    output: Optional[str] = None,\n    crs: str = \"EPSG:4326\",\n    return_gdf: bool = False,\n    **kwargs,\n) -&gt; Union[List[dict], tuple]:\n    \"\"\"Searches for NASA PACE granules.\n\n    Args:\n        bbox (List[float], optional): The bounding box coordinates [xmin, ymin, xmax, ymax].\n        temporal (str, optional): The temporal extent of the data.\n        count (int, optional): The number of granules to retrieve. Defaults to -1 (retrieve all).\n        short_name (str, optional): The short name of the dataset. Defaults to \"PACE_OCI_L2_AOP_NRT\".\n        output (str, optional): The output file path to save the GeoDataFrame as a file.\n        crs (str, optional): The coordinate reference system (CRS) of the GeoDataFrame. Defaults to \"EPSG:4326\".\n        return_gdf (bool, optional): Whether to return the GeoDataFrame in addition to the granules. Defaults to False.\n        **kwargs: Additional keyword arguments for the earthaccess.search_data() function.\n\n    Returns:\n        Union[List[dict], tuple]: The retrieved granules. If return_gdf is True, also returns the resulting GeoDataFrame.\n    \"\"\"\n\n    return search_nasa_data(\n        count=count,\n        short_name=short_name,\n        bbox=bbox,\n        temporal=temporal,\n        output=output,\n        crs=crs,\n        return_gdf=return_gdf,\n        **kwargs,\n    )\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/opengeos/HyperCoast/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>HyperCoast could always use more documentation, whether as part of the official HyperCoast docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/opengeos/HyperCoast/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up HyperCoast for local development.</p> <ol> <li> <p>Fork the HyperCoast repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/HyperCoast.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv HyperCoast\n$ cd HyperCoast/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 HyperCoast tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/opengeos/HyperCoast/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"desis/","title":"desis module","text":"<p>This Module has the functions related to working with a DESIS dataset.</p>"},{"location":"desis/#hypercoast.desis.desis_to_image","title":"<code>desis_to_image(dataset, bands=None, method='nearest', output=None, **kwargs)</code>","text":"<p>Converts an DESIS dataset to an image.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xarray.Dataset or str</code> <p>The dataset containing the DESIS data or the file path to the dataset.</p> required <code>bands</code> <code>array-like</code> <p>The specific bands to select. If None, all bands are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data interpolation. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>output</code> <code>str</code> <p>The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>leafmap.array_to_image</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>rasterio.Dataset or None</code> <p>The image converted from the dataset. If     <code>output</code> is provided, the image will be saved to the specified file     and the function will return None.</p> Source code in <code>hypercoast/desis.py</code> <pre><code>def desis_to_image(dataset, bands=None, method=\"nearest\", output=None, **kwargs):\n    \"\"\"\n    Converts an DESIS dataset to an image.\n\n    Args:\n        dataset (xarray.Dataset or str): The dataset containing the DESIS data\n            or the file path to the dataset.\n        bands (array-like, optional): The specific bands to select. If None, all\n            bands are selected. Defaults to None.\n        method (str, optional): The method to use for data interpolation.\n            Defaults to \"nearest\".\n        output (str, optional): The file path where the image will be saved. If\n            None, the image will be returned as a PIL Image object. Defaults to None.\n        **kwargs: Additional keyword arguments to be passed to\n            `leafmap.array_to_image`.\n\n    Returns:\n        rasterio.Dataset or None: The image converted from the dataset. If\n            `output` is provided, the image will be saved to the specified file\n            and the function will return None.\n    \"\"\"\n    from leafmap import array_to_image\n\n    if isinstance(dataset, str):\n        dataset = read_desis(dataset, method=method)\n\n    if bands is not None:\n        dataset = dataset.sel(band=bands, method=method)\n\n    return array_to_image(dataset[\"reflectance\"], output=output, **kwargs)\n</code></pre>"},{"location":"desis/#hypercoast.desis.extract_desis","title":"<code>extract_desis(ds, lat, lon)</code>","text":"<p>Extracts DESIS data from a given xarray Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset</code> <p>The dataset containing the DESIS data.</p> required <code>lat</code> <code>float</code> <p>The latitude of the point to extract.</p> required <code>lon</code> <code>float</code> <p>The longitude of the point to extract.</p> required <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>The extracted data.</p> Source code in <code>hypercoast/desis.py</code> <pre><code>def extract_desis(ds, lat, lon):\n    \"\"\"\n    Extracts DESIS data from a given xarray Dataset.\n\n    Args:\n        ds (xarray.Dataset): The dataset containing the DESIS data.\n        lat (float): The latitude of the point to extract.\n        lon (float): The longitude of the point to extract.\n\n    Returns:\n        xarray.DataArray: The extracted data.\n    \"\"\"\n\n    crs = ds.attrs[\"crs\"]\n\n    x, y = convert_coords([[lat, lon]], \"epsg:4326\", crs)[0]\n\n    values = ds.sel(x=x, y=y, method=\"nearest\")[\"reflectance\"].values / 10000\n\n    da = xr.DataArray(\n        values, dims=[\"wavelength\"], coords={\"wavelength\": ds.attrs[\"wavelengths\"]}\n    )\n\n    return da\n</code></pre>"},{"location":"desis/#hypercoast.desis.filter_desis","title":"<code>filter_desis(dataset, lat, lon, return_plot=False, **kwargs)</code>","text":"<p>Filters a DESIS dataset based on latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xr.Dataset</code> <p>The DESIS dataset to filter.</p> required <code>lat</code> <code>float or tuple</code> <p>The latitude to filter by. If a tuple or list, it represents a range.</p> required <code>lon</code> <code>float or tuple</code> <p>The longitude to filter by. If a tuple or list, it represents a range.</p> required <p>Returns:</p> Type Description <code>xr.DataArray</code> <p>The filtered DESIS data.</p> Source code in <code>hypercoast/desis.py</code> <pre><code>def filter_desis(dataset, lat, lon, return_plot=False, **kwargs):\n    \"\"\"\n    Filters a DESIS dataset based on latitude and longitude.\n\n    Args:\n        dataset (xr.Dataset): The DESIS dataset to filter.\n        lat (float or tuple): The latitude to filter by. If a tuple or list,\n            it represents a range.\n        lon (float or tuple): The longitude to filter by. If a tuple or\n            list, it represents a range.\n\n    Returns:\n        xr.DataArray: The filtered DESIS data.\n    \"\"\"\n\n    if isinstance(lat, list) or isinstance(lat, tuple):\n        min_lat = min(lat)\n        max_lat = max(lat)\n    else:\n        min_lat = lat\n        max_lat = lat\n\n    if isinstance(lon, list) or isinstance(lon, tuple):\n        min_lon = min(lon)\n        max_lon = max(lon)\n    else:\n        min_lon = lon\n        max_lon = lon\n\n    if min_lat == max_lat and min_lon == max_lon:\n        coords = [[min_lat, min_lon]]\n    else:\n        coords = [[min_lat, min_lon], [max_lat, max_lon]]\n    coords = convert_coords(coords, \"epsg:4326\", dataset.rio.crs.to_string())\n\n    if len(coords) == 1:\n        x, y = coords[0]\n        da = dataset.sel(x=x, y=y, method=\"nearest\")[\"reflectance\"]\n    else:\n        x_min, y_min = coords[0]\n        x_max, y_max = coords[1]\n        print(x_min, y_min, x_max, y_max)\n        da = dataset.sel(x=slice(x_min, x_max), y=slice(y_min, y_max))[\"reflectance\"]\n\n    wavelengths = dataset.attrs[\"wavelengths\"]\n\n    if return_plot:\n        rrs_stack = da.stack(\n            {\"pixel\": [\"latitude\", \"longitude\"]},\n            create_index=False,\n        )\n        rrs_stack.plot.line(hue=\"pixel\", **kwargs)\n    else:\n        return da\n</code></pre>"},{"location":"desis/#hypercoast.desis.read_desis","title":"<code>read_desis(filepath, bands=None, method='nearest', **kwargs)</code>","text":"<p>Reads DESIS data from a given file and returns an xarray Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the file to read.</p> required <code>bands</code> <code>array-like</code> <p>Specific bands to select. If None, all bands are selected.</p> <code>None</code> <code>method</code> <code>str</code> <p>Method to use for selection when bands is not None. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the <code>sel</code> method when bands is not None.</p> <code>{}</code> <p>Returns:</p> Type Description <code>xr.Dataset</code> <p>An xarray Dataset containing the DESIS data.</p> Source code in <code>hypercoast/desis.py</code> <pre><code>def read_desis(filepath, bands=None, method=\"nearest\", **kwargs):\n    \"\"\"\n    Reads DESIS data from a given file and returns an xarray Dataset.\n\n    Args:\n        filepath (str): Path to the file to read.\n        bands (array-like, optional): Specific bands to select. If None, all\n            bands are selected.\n        method (str, optional): Method to use for selection when bands is not\n            None. Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to pass to the `sel` method when\n            bands is not None.\n\n    Returns:\n        xr.Dataset: An xarray Dataset containing the DESIS data.\n    \"\"\"\n\n    dataset = xr.open_dataset(filepath)\n\n    if bands is not None:\n        dataset = dataset.sel(band=bands, method=method, **kwargs)\n\n    dataset = dataset.rename({\"band_data\": \"reflectance\"})\n    url = \"https://github.com/opengeos/datasets/releases/download/hypercoast/desis_wavelengths.csv\"\n    df = pd.read_csv(url)\n    wavelengths = df[\"wavelength\"].tolist()\n    dataset.attrs[\"wavelengths\"] = wavelengths\n    dataset.attrs[\"crs\"] = dataset.rio.crs.to_string()\n\n    return dataset\n</code></pre>"},{"location":"emit/","title":"emit module","text":"<p>This Module has the functions related to working with an EMIT dataset. This includes doing things like opening and flattening the data to work in xarray, orthorectification, and visualization.</p> <p>Some source code is adapted from https://github.com/nasa/EMIT-Data-Resources. Credits to the original authors, including Erik Bolch, Alex Leigh, and others.</p>"},{"location":"emit/#hypercoast.emit.apply_glt","title":"<code>apply_glt(ds_array, glt_array, fill_value=-9999, GLT_NODATA_VALUE=0)</code>","text":"<p>Applies the GLT array to a numpy array of either 2 or 3 dimensions to orthorectify the data.</p> <p>Parameters:</p> Name Type Description Default <code>ds_array</code> <code>numpy.ndarray</code> <p>A numpy array of the desired variable.</p> required <code>glt_array</code> <code>numpy.ndarray</code> <p>A GLT array constructed from EMIT GLT data.</p> required <code>fill_value</code> <code>int</code> <p>The value to fill in the output array where the GLT array has no data. Defaults to -9999.</p> <code>-9999</code> <code>GLT_NODATA_VALUE</code> <code>int</code> <p>The value in the GLT array that indicates no data. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>A numpy array of orthorectified data.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def apply_glt(ds_array, glt_array, fill_value=-9999, GLT_NODATA_VALUE=0):\n    \"\"\"\n    Applies the GLT array to a numpy array of either 2 or 3 dimensions to orthorectify the data.\n\n    Args:\n        ds_array (numpy.ndarray): A numpy array of the desired variable.\n        glt_array (numpy.ndarray): A GLT array constructed from EMIT GLT data.\n        fill_value (int, optional): The value to fill in the output array where the GLT array has no data. Defaults to -9999.\n        GLT_NODATA_VALUE (int, optional): The value in the GLT array that indicates no data. Defaults to 0.\n\n    Returns:\n        numpy.ndarray: A numpy array of orthorectified data.\n    \"\"\"\n\n    # Build Output Dataset\n    if ds_array.ndim == 2:\n        ds_array = ds_array[:, :, np.newaxis]\n    out_ds = np.full(\n        (glt_array.shape[0], glt_array.shape[1], ds_array.shape[-1]),\n        fill_value,\n        dtype=np.float32,\n    )\n    valid_glt = np.all(glt_array != GLT_NODATA_VALUE, axis=-1)\n\n    # Adjust for One based Index - make a copy to prevent decrementing multiple times inside ortho_xr when applying the glt to elev\n    glt_array_copy = glt_array.copy()\n    glt_array_copy[valid_glt] -= 1\n    out_ds[valid_glt, :] = ds_array[\n        glt_array_copy[valid_glt, 1], glt_array_copy[valid_glt, 0], :\n    ]\n    return out_ds\n</code></pre>"},{"location":"emit/#hypercoast.emit.band_mask","title":"<code>band_mask(filepath)</code>","text":"<p>Unpacks the packed band mask to apply to the dataset. Can be used manually or as an input in the emit_xarray() function.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>An EMIT L2A Mask netCDF file.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>A numpy array that can be used with the emit_xarray function to apply a band mask.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def band_mask(filepath):\n    \"\"\"\n    Unpacks the packed band mask to apply to the dataset. Can be used manually or as an input in the emit_xarray() function.\n\n    Args:\n        filepath (str): An EMIT L2A Mask netCDF file.\n\n    Returns:\n        numpy.ndarray: A numpy array that can be used with the emit_xarray function to apply a band mask.\n    \"\"\"\n    # Open Dataset\n    mask_ds = xr.open_dataset(filepath, engine=\"h5netcdf\")\n    # Open band_mask and convert to uint8\n    bmask = mask_ds.band_mask.data.astype(\"uint8\")\n    # Print Flags used\n    unpacked_bmask = np.unpackbits(bmask, axis=-1)\n    # Remove bands &gt; 285\n    unpacked_bmask = unpacked_bmask[:, :, 0:285]\n    # Check for data bands and build mask\n    return unpacked_bmask\n</code></pre>"},{"location":"emit/#hypercoast.emit.coord_vects","title":"<code>coord_vects(ds)</code>","text":"<p>This function calculates the Lat and Lon Coordinate Vectors using the GLT and Metadata from an EMIT dataset read into xarray.</p> <p>lon, lat (numpy.array): longitute and latitude array grid for the dataset</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def coord_vects(ds):\n    \"\"\"\n    This function calculates the Lat and Lon Coordinate Vectors using the GLT and Metadata from an EMIT dataset read into xarray.\n\n    Parameters:\n    ds: an xarray.Dataset containing the root variable and metadata of an EMIT dataset\n    loc: an xarray.Dataset containing the 'location' group of an EMIT dataset\n\n    Returns:\n    lon, lat (numpy.array): longitute and latitude array grid for the dataset\n\n    \"\"\"\n    # Retrieve Geotransform from Metadata\n    GT = ds.geotransform\n    # Create Array for Lat and Lon and fill\n    dim_x = ds.glt_x.shape[1]\n    dim_y = ds.glt_x.shape[0]\n    lon = np.zeros(dim_x)\n    lat = np.zeros(dim_y)\n    # Note: no rotation for EMIT Data\n    for x in np.arange(dim_x):\n        x_geo = (GT[0] + 0.5 * GT[1]) + x * GT[1]  # Adjust coordinates to pixel-center\n        lon[x] = x_geo\n    for y in np.arange(dim_y):\n        y_geo = (GT[3] + 0.5 * GT[5]) + y * GT[5]\n        lat[y] = y_geo\n    return lon, lat\n</code></pre>"},{"location":"emit/#hypercoast.emit.emit_to_image","title":"<code>emit_to_image(data, wavelengths=None, method='nearest', output=None, **kwargs)</code>","text":"<p>Converts an EMIT dataset to an image.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>xarray.Dataset or str</code> <p>The dataset containing the EMIT data or the file path to the dataset.</p> required <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>output</code> <code>str</code> <p>The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>leafmap.array_to_image</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>rasterio.Dataset or None</code> <p>The image converted from the dataset. If <code>output</code> is provided, the image will be saved to the specified file and the function will return None.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def emit_to_image(data, wavelengths=None, method=\"nearest\", output=None, **kwargs):\n    \"\"\"\n    Converts an EMIT dataset to an image.\n\n    Args:\n        data (xarray.Dataset or str): The dataset containing the EMIT data or the file path to the dataset.\n        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n        output (str, optional): The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.\n        **kwargs: Additional keyword arguments to be passed to `leafmap.array_to_image`.\n\n    Returns:\n        rasterio.Dataset or None: The image converted from the dataset. If `output` is provided, the image will be saved to the specified file and the function will return None.\n    \"\"\"\n    from leafmap import array_to_image\n\n    if isinstance(data, str):\n        data = read_emit(data, ortho=True)\n\n    ds = data[\"reflectance\"]\n\n    if wavelengths is not None:\n        ds = ds.sel(wavelengths=wavelengths, method=method)\n    return array_to_image(ds, transpose=False, output=output, **kwargs)\n</code></pre>"},{"location":"emit/#hypercoast.emit.emit_to_netcdf","title":"<code>emit_to_netcdf(data, output, **kwargs)</code>","text":"<p>Transposes an EMIT dataset and saves it as a NetCDF file.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>xarray.Dataset or str</code> <p>The dataset containing the EMIT data or the file path to the dataset.</p> required <code>output</code> <code>str</code> <p>The file path where the NetCDF file will be saved.</p> required <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>xarray.Dataset.to_netcdf</code>.</p> <code>{}</code> Source code in <code>hypercoast/emit.py</code> <pre><code>def emit_to_netcdf(data, output, **kwargs):\n    \"\"\"\n    Transposes an EMIT dataset and saves it as a NetCDF file.\n\n    Args:\n        data (xarray.Dataset or str): The dataset containing the EMIT data or the file path to the dataset.\n        output (str): The file path where the NetCDF file will be saved.\n        **kwargs: Additional keyword arguments to be passed to `xarray.Dataset.to_netcdf`.\n\n    \"\"\"\n    if isinstance(data, str):\n        data = read_emit(data, ortho=True)\n\n    ds_geo = data.transpose(\"wavelengths\", \"latitude\", \"longitude\")\n    ds_geo.to_netcdf(output, **kwargs)\n</code></pre>"},{"location":"emit/#hypercoast.emit.emit_xarray","title":"<code>emit_xarray(filepath, ortho=False, qmask=None, unpacked_bmask=None, wavelengths=None, method='nearest')</code>","text":"<p>Streamlines opening an EMIT dataset as an xarray.Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>A filepath to an EMIT netCDF file.</p> required <code>ortho</code> <code>bool</code> <p>Whether to orthorectify the dataset or leave in crosstrack/downtrack coordinates. Defaults to False.</p> <code>False</code> <code>qmask</code> <code>numpy.ndarray</code> <p>A numpy array output from the quality_mask function used to mask pixels based on quality flags selected in that function. Any non-orthorectified array with the proper crosstrack and downtrack dimensions can also be used. Defaults to None.</p> <code>None</code> <code>unpacked_bmask</code> <code>numpy.ndarray</code> <p>A numpy array from the band_mask function that can be used to mask band-specific pixels that have been interpolated. Defaults to None.</p> <code>None</code> <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>An xarray.Dataset constructed based on the parameters provided.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def emit_xarray(\n    filepath,\n    ortho=False,\n    qmask=None,\n    unpacked_bmask=None,\n    wavelengths=None,\n    method=\"nearest\",\n):\n    \"\"\"\n    Streamlines opening an EMIT dataset as an xarray.Dataset.\n\n    Args:\n        filepath (str): A filepath to an EMIT netCDF file.\n        ortho (bool, optional): Whether to orthorectify the dataset or leave in crosstrack/downtrack coordinates. Defaults to False.\n        qmask (numpy.ndarray, optional): A numpy array output from the quality_mask function used to mask pixels based on quality flags selected in that function. Any non-orthorectified array with the proper crosstrack and downtrack dimensions can also be used. Defaults to None.\n        unpacked_bmask (numpy.ndarray, optional): A numpy array from the band_mask function that can be used to mask band-specific pixels that have been interpolated. Defaults to None.\n        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n\n    Returns:\n        xarray.Dataset: An xarray.Dataset constructed based on the parameters provided.\n    \"\"\"\n    # Grab granule filename to check product\n    import s3fs\n    from fsspec.implementations.http import HTTPFile\n\n    if type(filepath) == s3fs.core.S3File:\n        granule_id = filepath.info()[\"name\"].split(\"/\", -1)[-1].split(\".\", -1)[0]\n    elif type(filepath) == HTTPFile:\n        granule_id = filepath.path.split(\"/\", -1)[-1].split(\".\", -1)[0]\n    else:\n        granule_id = os.path.splitext(os.path.basename(filepath))[0]\n\n    # Read in Data as Xarray Datasets\n    engine, wvl_group = \"h5netcdf\", None\n\n    ds = xr.open_dataset(filepath, engine=engine)\n    loc = xr.open_dataset(filepath, engine=engine, group=\"location\")\n\n    # Check if mineral dataset and read in groups (only ds/loc for minunc)\n\n    if \"L2B_MIN_\" in granule_id:\n        wvl_group = \"mineral_metadata\"\n    elif \"L2B_MINUNC\" not in granule_id:\n        wvl_group = \"sensor_band_parameters\"\n\n    wvl = None\n\n    if wvl_group:\n        wvl = xr.open_dataset(filepath, engine=engine, group=wvl_group)\n\n    # Building Flat Dataset from Components\n    data_vars = {**ds.variables}\n\n    # Format xarray coordinates based upon emit product (no wvl for mineral uncertainty)\n    coords = {\n        \"downtrack\": ([\"downtrack\"], ds.downtrack.data),\n        \"crosstrack\": ([\"crosstrack\"], ds.crosstrack.data),\n        **loc.variables,\n    }\n\n    product_band_map = {\n        \"L2B_MIN_\": \"name\",\n        \"L2A_MASK_\": \"mask_bands\",\n        \"L1B_OBS_\": \"observation_bands\",\n        \"L2A_RFL_\": \"wavelengths\",\n        \"L1B_RAD_\": \"wavelengths\",\n        \"L2A_RFLUNCERT_\": \"wavelengths\",\n    }\n\n    # if band := product_band_map.get(next((k for k in product_band_map.keys() if k in granule_id), 'unknown'), None):\n    # coords['bands'] = wvl[band].data\n\n    if wvl:\n        coords = {**coords, **wvl.variables}\n\n    out_xr = xr.Dataset(data_vars=data_vars, coords=coords, attrs=ds.attrs)\n    out_xr.attrs[\"granule_id\"] = granule_id\n\n    if band := product_band_map.get(\n        next((k for k in product_band_map.keys() if k in granule_id), \"unknown\"), None\n    ):\n        if \"minerals\" in list(out_xr.dims):\n            out_xr = out_xr.swap_dims({\"minerals\": band})\n            out_xr = out_xr.rename({band: \"mineral_name\"})\n        else:\n            out_xr = out_xr.swap_dims({\"bands\": band})\n\n    # Apply Quality and Band Masks, set fill values to NaN\n    for var in list(ds.data_vars):\n        if qmask is not None:\n            out_xr[var].data[qmask == 1] = np.nan\n        if unpacked_bmask is not None:\n            out_xr[var].data[unpacked_bmask == 1] = np.nan\n        out_xr[var].data[out_xr[var].data == -9999] = np.nan\n\n    if ortho is True:\n        out_xr = ortho_xr(out_xr)\n        out_xr.attrs[\"Orthorectified\"] = \"True\"\n\n    if wavelengths is not None:\n        out_xr = out_xr.sel(wavelengths=wavelengths, method=method)\n    return out_xr\n</code></pre>"},{"location":"emit/#hypercoast.emit.envi_header","title":"<code>envi_header(inputpath)</code>","text":"<p>Convert a ENVI binary/header path to a header, handling extensions.</p> <p>Parameters:</p> Name Type Description Default <code>inputpath</code> <code>str</code> <p>Path to ENVI binary file.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The header file associated with the input reference. If the header file does not exist, it returns the expected header file path.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def envi_header(inputpath):\n    \"\"\"\n    Convert a ENVI binary/header path to a header, handling extensions.\n\n    Args:\n        inputpath (str): Path to ENVI binary file.\n\n    Returns:\n        str: The header file associated with the input reference. If the header file does not exist, it returns the expected header file path.\n    \"\"\"\n    if (\n        os.path.splitext(inputpath)[-1] == \".img\"\n        or os.path.splitext(inputpath)[-1] == \".dat\"\n        or os.path.splitext(inputpath)[-1] == \".raw\"\n    ):\n        # headers could be at either filename.img.hdr or filename.hdr.  Check both, return the one that exists if it\n        # does, if not return the latter (new file creation presumed).\n        hdrfile = os.path.splitext(inputpath)[0] + \".hdr\"\n        if os.path.isfile(hdrfile):\n            return hdrfile\n        elif os.path.isfile(inputpath + \".hdr\"):\n            return inputpath + \".hdr\"\n        return hdrfile\n    elif os.path.splitext(inputpath)[-1] == \".hdr\":\n        return inputpath\n    else:\n        return inputpath + \".hdr\"\n</code></pre>"},{"location":"emit/#hypercoast.emit.is_adjacent","title":"<code>is_adjacent(scene, same_orbit)</code>","text":"<p>Checks if the scene numbers from the same orbit are adjacent/sequential.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>str</code> <p>The scene number to check.</p> required <code>same_orbit</code> <code>list</code> <p>A list of scene numbers from the same orbit.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the scene numbers are adjacent/sequential, False otherwise.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def is_adjacent(scene: str, same_orbit: list):\n    \"\"\"\n    Checks if the scene numbers from the same orbit are adjacent/sequential.\n\n    Args:\n        scene (str): The scene number to check.\n        same_orbit (list): A list of scene numbers from the same orbit.\n\n    Returns:\n        bool: True if the scene numbers are adjacent/sequential, False otherwise.\n    \"\"\"\n    scene_nums = [int(scene.split(\".\")[-2].split(\"_\")[-1]) for scene in same_orbit]\n    return all(b - a == 1 for a, b in zip(scene_nums[:-1], scene_nums[1:]))\n</code></pre>"},{"location":"emit/#hypercoast.emit.merge_emit","title":"<code>merge_emit(datasets, gdf)</code>","text":"<p>Merges xarray datasets formatted using emit_xarray. Note: GDF may only work with a single geometry.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>dict</code> <p>A dictionary of xarray datasets formatted using emit_xarray.</p> required <code>gdf</code> <code>gpd.GeoDataFrame</code> <p>A GeoDataFrame containing the geometry to be used for merging.</p> required <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>A merged xarray dataset.</p> <p>Exceptions:</p> Type Description <code>Exception</code> <p>If there are inconsistencies in the 1D variables across datasets.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def merge_emit(datasets: dict, gdf: gpd.GeoDataFrame):\n    \"\"\"\n    Merges xarray datasets formatted using emit_xarray. Note: GDF may only work with a single geometry.\n\n    Args:\n        datasets (dict): A dictionary of xarray datasets formatted using emit_xarray.\n        gdf (gpd.GeoDataFrame): A GeoDataFrame containing the geometry to be used for merging.\n\n    Returns:\n        xarray.Dataset: A merged xarray dataset.\n\n    Raises:\n        Exception: If there are inconsistencies in the 1D variables across datasets.\n    \"\"\"\n    from rioxarray.merge import merge_arrays\n\n    nested_data_arrays = {}\n    # loop over datasets\n    for dataset in datasets:\n        # create dictionary of arrays for each dataset\n\n        # create dictionary of 1D variables, which should be consistent across datasets\n        one_d_arrays = {}\n\n        # Dictionary of variables to merge\n        data_arrays = {}\n        # Loop over variables in dataset including elevation\n        for var in list(datasets[dataset].data_vars) + [\"elev\"]:\n            # Get 1D for this variable and add to dictionary\n            if not one_d_arrays:\n                # These should be an array describing the others (wavelengths, mask_bands, etc.)\n                one_dim = [\n                    item\n                    for item in list(datasets[dataset].coords)\n                    if item not in [\"latitude\", \"longitude\", \"spatial_ref\"]\n                    and len(datasets[dataset][item].dims) == 1\n                ]\n                # print(one_dim)\n                for od in one_dim:\n                    one_d_arrays[od] = datasets[dataset].coords[od].data\n\n                # Update format for merging - This could probably be improved\n            da = datasets[dataset][var].reset_coords(\"elev\", drop=False)\n            da = da.rename({\"latitude\": \"y\", \"longitude\": \"x\"})\n            if len(da.dims) == 3:\n                if any(item in list(da.coords) for item in one_dim):\n                    da = da.drop_vars(one_dim)\n                da = da.drop_vars(\"elev\")\n                da = da.to_array(name=var).squeeze(\"variable\", drop=True)\n                da = da.transpose(da.dims[-1], da.dims[0], da.dims[1])\n                # print(da.dims)\n            if var == \"elev\":\n                da = da.to_array(name=var).squeeze(\"variable\", drop=True)\n            data_arrays[var] = da\n            nested_data_arrays[dataset] = data_arrays\n\n            # Transpose the nested arrays dict. This is horrible to read, but works to pair up variables (ie mask) from the different granules\n    transposed_dict = {\n        inner_key: {\n            outer_key: inner_dict[inner_key]\n            for outer_key, inner_dict in nested_data_arrays.items()\n        }\n        for inner_key in nested_data_arrays[next(iter(nested_data_arrays))]\n    }\n\n    # remove some unused data\n    del nested_data_arrays, data_arrays, da\n\n    # Merge the arrays using rioxarray.merge_arrays()\n    merged = {}\n    for _var in transposed_dict:\n        merged[_var] = merge_arrays(\n            list(transposed_dict[_var].values()),\n            bounds=gdf.unary_union.bounds,\n            nodata=np.nan,\n        )\n\n    # Create a new xarray dataset from the merged arrays\n    # Create Merged Dataset\n    merged_ds = xr.Dataset(data_vars=merged, coords=one_d_arrays)\n    # Rename x and y to longitude and latitude\n    merged_ds = merged_ds.rename({\"y\": \"latitude\", \"x\": \"longitude\"})\n    del transposed_dict, merged\n    return merged_ds\n</code></pre>"},{"location":"emit/#hypercoast.emit.ortho_browse","title":"<code>ortho_browse(url, glt, spatial_ref, geotransform, white_background=True)</code>","text":"<p>Use an EMIT GLT, geotransform, and spatial ref to orthorectify a browse image. (browse images are in native resolution)</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of the browse image.</p> required <code>glt</code> <code>numpy.ndarray</code> <p>A GLT array constructed from EMIT GLT data.</p> required <code>spatial_ref</code> <code>str</code> <p>Spatial reference system.</p> required <code>geotransform</code> <code>list</code> <p>A list of six numbers that define the affine transform between pixel coordinates and map coordinates.</p> required <code>white_background</code> <code>bool</code> <p>If True, the fill value for the orthorectified image is white (255). If False, the fill value is black (0). Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>An orthorectified browse image in the form of an xarray DataArray.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def ortho_browse(url, glt, spatial_ref, geotransform, white_background=True):\n    \"\"\"\n    Use an EMIT GLT, geotransform, and spatial ref to orthorectify a browse image. (browse images are in native resolution)\n\n    Args:\n        url (str): URL of the browse image.\n        glt (numpy.ndarray): A GLT array constructed from EMIT GLT data.\n        spatial_ref (str): Spatial reference system.\n        geotransform (list): A list of six numbers that define the affine transform between pixel coordinates and map coordinates.\n        white_background (bool, optional): If True, the fill value for the orthorectified image is white (255). If False, the fill value is black (0). Defaults to True.\n\n    Returns:\n        xarray.DataArray: An orthorectified browse image in the form of an xarray DataArray.\n    \"\"\"\n    from skimage import io\n\n    # Read Data\n    data = io.imread(url)\n    # Orthorectify using GLT and transpose so band is first dimension\n    if white_background == True:\n        fill = 255\n    else:\n        fill = 0\n    ortho_data = apply_glt(data, glt, fill_value=fill).transpose(2, 0, 1)\n    coords = {\n        \"y\": (\n            [\"y\"],\n            (geotransform[3] + 0.5 * geotransform[5])\n            + np.arange(glt.shape[0]) * geotransform[5],\n        ),\n        \"x\": (\n            [\"x\"],\n            (geotransform[0] + 0.5 * geotransform[1])\n            + np.arange(glt.shape[1]) * geotransform[1],\n        ),\n    }\n    ortho_data = ortho_data.astype(int)\n    ortho_data[ortho_data == -1] = 0\n    # Place in xarray.datarray\n    da = xr.DataArray(ortho_data, dims=[\"band\", \"y\", \"x\"], coords=coords)\n    da.rio.write_crs(spatial_ref, inplace=True)\n    return da\n</code></pre>"},{"location":"emit/#hypercoast.emit.ortho_xr","title":"<code>ortho_xr(ds, GLT_NODATA_VALUE=0, fill_value=-9999)</code>","text":"<p>Uses <code>apply_glt</code> to create an orthorectified xarray dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset</code> <p>An xarray dataset produced by emit_xarray.</p> required <code>GLT_NODATA_VALUE</code> <code>int</code> <p>No data value for the GLT tables. Defaults to 0.</p> <code>0</code> <code>fill_value</code> <code>int</code> <p>The fill value for EMIT datasets. Defaults to -9999.</p> <code>-9999</code> <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>An orthocorrected xarray dataset.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def ortho_xr(ds, GLT_NODATA_VALUE=0, fill_value=-9999):\n    \"\"\"\n    Uses `apply_glt` to create an orthorectified xarray dataset.\n\n    Args:\n        ds (xarray.Dataset): An xarray dataset produced by emit_xarray.\n        GLT_NODATA_VALUE (int, optional): No data value for the GLT tables. Defaults to 0.\n        fill_value (int, optional): The fill value for EMIT datasets. Defaults to -9999.\n\n    Returns:\n        xarray.Dataset: An orthocorrected xarray dataset.\n    \"\"\"\n    # Build glt_ds\n\n    glt_ds = np.nan_to_num(\n        np.stack([ds[\"glt_x\"].data, ds[\"glt_y\"].data], axis=-1), nan=GLT_NODATA_VALUE\n    ).astype(int)\n\n    # List Variables\n    var_list = list(ds.data_vars)\n\n    # Remove flat field from data vars - the flat field is only useful with additional information before orthorectification\n    if \"flat_field_update\" in var_list:\n        var_list.remove(\"flat_field_update\")\n\n    # Create empty dictionary for orthocorrected data vars\n    data_vars = {}\n\n    # Extract Rawspace Dataset Variable Values (Typically Reflectance)\n    for var in var_list:\n        raw_ds = ds[var].data\n        var_dims = ds[var].dims\n        # Apply GLT to dataset\n        out_ds = apply_glt(raw_ds, glt_ds, GLT_NODATA_VALUE=GLT_NODATA_VALUE)\n\n        # Mask fill values\n        out_ds[out_ds == fill_value] = np.nan\n\n        # Update variables - Only works for 2 or 3 dimensional arays\n        if raw_ds.ndim == 2:\n            out_ds = out_ds.squeeze()\n            data_vars[var] = ([\"latitude\", \"longitude\"], out_ds)\n        else:\n            data_vars[var] = ([\"latitude\", \"longitude\", var_dims[-1]], out_ds)\n\n        del raw_ds\n\n    # Calculate Lat and Lon Vectors\n    lon, lat = coord_vects(\n        ds\n    )  # Reorder this function to make sense in case of multiple variables\n\n    # Apply GLT to elevation\n    elev_ds = apply_glt(ds[\"elev\"].data, glt_ds)\n    elev_ds[elev_ds == fill_value] = np.nan\n\n    # Delete glt_ds - no longer needed\n    del glt_ds\n\n    # Create Coordinate Dictionary\n    coords = {\n        \"latitude\": ([\"latitude\"], lat),\n        \"longitude\": ([\"longitude\"], lon),\n        **ds.coords,\n    }  # unpack to add appropriate coordinates\n\n    # Remove Unnecessary Coords\n    for key in [\"downtrack\", \"crosstrack\", \"lat\", \"lon\", \"glt_x\", \"glt_y\", \"elev\"]:\n        del coords[key]\n\n    # Add Orthocorrected Elevation\n    coords[\"elev\"] = ([\"latitude\", \"longitude\"], np.squeeze(elev_ds))\n\n    # Build Output xarray Dataset and assign data_vars array attributes\n    out_xr = xr.Dataset(data_vars=data_vars, coords=coords, attrs=ds.attrs)\n\n    del out_ds\n    # Assign Attributes from Original Datasets\n    for var in var_list:\n        out_xr[var].attrs = ds[var].attrs\n    out_xr.coords[\"latitude\"].attrs = ds[\"lat\"].attrs\n    out_xr.coords[\"longitude\"].attrs = ds[\"lon\"].attrs\n    out_xr.coords[\"elev\"].attrs = ds[\"elev\"].attrs\n\n    # Add Spatial Reference in recognizable format\n    out_xr.rio.write_crs(ds.spatial_ref, inplace=True)\n\n    return out_xr\n</code></pre>"},{"location":"emit/#hypercoast.emit.plot_emit","title":"<code>plot_emit(ds, longitude=None, latitude=None, downtrack=None, crosstrack=None, remove_nans=True, x='wavelengths', y='reflectance', color='black', frame_height=400, frame_width=600, title=None, method='nearest', ortho=True, options={}, **kwargs)</code>","text":"<p>Plots a line graph of the reflectance data from a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset or str</code> <p>The dataset containing the reflectance data or the file path to the dataset.</p> required <code>longitude</code> <code>float</code> <p>The longitude coordinate to select for orthorectified data. Defaults to None.</p> <code>None</code> <code>latitude</code> <code>float</code> <p>The latitude coordinate to select for orthorectified data. Defaults to None.</p> <code>None</code> <code>downtrack</code> <code>int</code> <p>The downtrack coordinate to select for non-orthorectified data. Defaults to None.</p> <code>None</code> <code>crosstrack</code> <code>int</code> <p>The crosstrack coordinate to select for non-orthorectified data. Defaults to None.</p> <code>None</code> <code>remove_nans</code> <code>bool</code> <p>If True, replace non-good wavelengths with NaN. Defaults to True.</p> <code>True</code> <code>x</code> <code>str</code> <p>The x-axis label. Defaults to \"wavelengths\".</p> <code>'wavelengths'</code> <code>y</code> <code>str</code> <p>The y-axis label. Defaults to \"reflectance\".</p> <code>'reflectance'</code> <code>color</code> <code>str</code> <p>The color of the line. Defaults to \"black\".</p> <code>'black'</code> <code>frame_height</code> <code>int</code> <p>The height of the frame. Defaults to 400.</p> <code>400</code> <code>frame_width</code> <code>int</code> <p>The width of the frame. Defaults to 600.</p> <code>600</code> <code>title</code> <code>str</code> <p>The title of the plot. If None, a default title will be generated. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>ortho</code> <code>bool</code> <p>If True, the function will use longitude and latitude for data selection. Defaults to True.</p> <code>True</code> <code>options</code> <code>dict</code> <p>Additional options to be passed to <code>hvplot.line</code>. Defaults to {}.</p> <code>{}</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>hvplot.line</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>hvplot.Plot</code> <p>The line plot of the reflectance data.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def plot_emit(\n    ds,\n    longitude=None,\n    latitude=None,\n    downtrack=None,\n    crosstrack=None,\n    remove_nans=True,\n    x=\"wavelengths\",\n    y=\"reflectance\",\n    color=\"black\",\n    frame_height=400,\n    frame_width=600,\n    title=None,\n    method=\"nearest\",\n    ortho=True,\n    options={},\n    **kwargs,\n):\n    \"\"\"\n    Plots a line graph of the reflectance data from a given dataset.\n\n    Args:\n        ds (xarray.Dataset or str): The dataset containing the reflectance data or the file path to the dataset.\n        longitude (float, optional): The longitude coordinate to select for orthorectified data. Defaults to None.\n        latitude (float, optional): The latitude coordinate to select for orthorectified data. Defaults to None.\n        downtrack (int, optional): The downtrack coordinate to select for non-orthorectified data. Defaults to None.\n        crosstrack (int, optional): The crosstrack coordinate to select for non-orthorectified data. Defaults to None.\n        remove_nans (bool, optional): If True, replace non-good wavelengths with NaN. Defaults to True.\n        x (str, optional): The x-axis label. Defaults to \"wavelengths\".\n        y (str, optional): The y-axis label. Defaults to \"reflectance\".\n        color (str, optional): The color of the line. Defaults to \"black\".\n        frame_height (int, optional): The height of the frame. Defaults to 400.\n        frame_width (int, optional): The width of the frame. Defaults to 600.\n        title (str, optional): The title of the plot. If None, a default title will be generated. Defaults to None.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n        ortho (bool, optional): If True, the function will use longitude and latitude for data selection. Defaults to True.\n        options (dict, optional): Additional options to be passed to `hvplot.line`. Defaults to {}.\n        **kwargs: Additional keyword arguments to be passed to `hvplot.line`.\n\n    Returns:\n        hvplot.Plot: The line plot of the reflectance data.\n    \"\"\"\n\n    import hvplot.xarray\n\n    if ortho == True:\n        if longitude is None or latitude is None:\n            raise ValueError(\n                \"Longitude and Latitude must be provided for orthorectified data.\"\n            )\n    else:\n        if downtrack is None or crosstrack is None:\n            raise ValueError(\n                \"Downtrack and Crosstrack must be provided for non-orthorectified data.\"\n            )\n\n    if longitude is not None and latitude is not None:\n        ortho = True\n\n    if downtrack is not None and crosstrack is not None:\n        ortho = False\n\n    if isinstance(ds, str):\n        ds = read_emit(ds, ortho=ortho)\n\n    if remove_nans:\n        ds[\"reflectance\"].data[:, :, ds[\"good_wavelengths\"].data == 0] = np.nan\n\n    if ortho:\n        example = ds[\"reflectance\"].sel(\n            longitude=longitude, latitude=latitude, method=method\n        )\n        if title is None:\n            title = f\"Reflectance at longitude={longitude:.3f}, latitude={latitude:.3f}\"\n\n    else:\n        example = ds[\"reflectance\"].sel(\n            downtrack=downtrack, crosstrack=crosstrack, method=method\n        )\n        if title is None:\n            title = f\"Reflectance at downtrack={downtrack}, crosstrack={crosstrack}\"\n\n    line = example.hvplot.line(\n        y=y,\n        x=x,\n        color=color,\n        frame_height=frame_height,\n        frame_width=frame_width,\n        **kwargs,\n    ).opts(title=title, **options)\n    return line\n</code></pre>"},{"location":"emit/#hypercoast.emit.quality_mask","title":"<code>quality_mask(filepath, quality_bands)</code>","text":"<p>Builds a single layer mask to apply based on the bands selected from an EMIT L2A Mask file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>An EMIT L2A Mask netCDF file.</p> required <code>quality_bands</code> <code>list</code> <p>A list of bands (quality flags only) from the mask file that should be used in creation of mask.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>A numpy array that can be used with the emit_xarray function to apply a quality mask.</p> <p>Exceptions:</p> Type Description <code>AttributeError</code> <p>If the selected flags include a data band (5 or 6) not just flag bands.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def quality_mask(filepath, quality_bands):\n    \"\"\"\n    Builds a single layer mask to apply based on the bands selected from an EMIT L2A Mask file.\n\n    Args:\n        filepath (str): An EMIT L2A Mask netCDF file.\n        quality_bands (list): A list of bands (quality flags only) from the mask file that should be used in creation of mask.\n\n    Returns:\n        numpy.ndarray: A numpy array that can be used with the emit_xarray function to apply a quality mask.\n\n    Raises:\n        AttributeError: If the selected flags include a data band (5 or 6) not just flag bands.\n    \"\"\"\n    # Open Dataset\n    mask_ds = xr.open_dataset(filepath, engine=\"h5netcdf\")\n    # Open Sensor band Group\n    mask_parameters_ds = xr.open_dataset(\n        filepath, engine=\"h5netcdf\", group=\"sensor_band_parameters\"\n    )\n    # Print Flags used\n    flags_used = mask_parameters_ds[\"mask_bands\"].data[quality_bands]\n    print(f\"Flags used: {flags_used}\")\n    # Check for data bands and build mask\n    if any(x in quality_bands for x in [5, 6]):\n        err_str = f\"Selected flags include a data band (5 or 6) not just flag bands\"\n        raise AttributeError(err_str)\n    else:\n        qmask = np.sum(mask_ds[\"mask\"][:, :, quality_bands].values, axis=-1)\n        qmask[qmask &gt; 1] = 1\n    return qmask\n</code></pre>"},{"location":"emit/#hypercoast.emit.raw_spatial_crop","title":"<code>raw_spatial_crop(ds, shape)</code>","text":"<p>Use a polygon to clip the file GLT, then a bounding box to crop the spatially raw data. Regions clipped in the GLT are set to 0 so a mask will be applied when used to orthorectify the data at a later point in a workflow.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset</code> <p>Raw spatial EMIT data (non-orthorectified) opened with the <code>emit_xarray</code> function.</p> required <code>shape</code> <code>geopandas.GeoDataFrame</code> <p>A polygon opened with geopandas.</p> required <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>A clipped GLT and raw spatial data clipped to a bounding box.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def raw_spatial_crop(ds, shape):\n    \"\"\"\n    Use a polygon to clip the file GLT, then a bounding box to crop the spatially raw data. Regions clipped in the GLT are set to 0 so a mask will be applied when\n    used to orthorectify the data at a later point in a workflow.\n\n    Args:\n        ds (xarray.Dataset): Raw spatial EMIT data (non-orthorectified) opened with the `emit_xarray` function.\n        shape (geopandas.GeoDataFrame): A polygon opened with geopandas.\n\n    Returns:\n        xarray.Dataset: A clipped GLT and raw spatial data clipped to a bounding box.\n    \"\"\"\n    # Reformat the GLT\n    lon, lat = coord_vects(ds)\n    data_vars = {\n        \"glt_x\": ([\"latitude\", \"longitude\"], ds.glt_x.data),\n        \"glt_y\": ([\"latitude\", \"longitude\"], ds.glt_y.data),\n    }\n    coords = {\n        \"latitude\": ([\"latitude\"], lat),\n        \"longitude\": ([\"longitude\"], lon),\n        \"ortho_y\": ([\"latitude\"], ds.ortho_y.data),\n        \"ortho_x\": ([\"longitude\"], ds.ortho_x.data),\n    }\n    glt_ds = xr.Dataset(data_vars=data_vars, coords=coords, attrs=ds.attrs)\n    glt_ds.rio.write_crs(glt_ds.spatial_ref, inplace=True)\n\n    # Clip the emit glt\n    clipped = glt_ds.rio.clip(shape.geometry.values, shape.crs, all_touched=True)\n\n    # Pull new geotransform from clipped glt\n    clipped_gt = np.array(\n        [float(i) for i in clipped[\"spatial_ref\"].GeoTransform.split(\" \")]\n    )  # THIS GEOTRANSFORM IS OFF BY HALF A PIXEL\n\n    # Create Crosstrack and Downtrack masks for spatially raw dataset -1 is to account for 1 based index. May be a more robust way to do this exists\n    crosstrack_mask = (ds.crosstrack &gt;= np.nanmin(clipped.glt_x.data) - 1) &amp; (\n        ds.crosstrack &lt;= np.nanmax(clipped.glt_x.data) - 1\n    )\n    downtrack_mask = (ds.downtrack &gt;= np.nanmin(clipped.glt_y.data) - 1) &amp; (\n        ds.downtrack &lt;= np.nanmax(clipped.glt_y.data) - 1\n    )\n\n    # Mask Areas outside of crosstrack and downtrack covered by the shape\n    clipped_ds = ds.where((crosstrack_mask &amp; downtrack_mask), drop=True)\n    # Replace Full dataset geotransform with clipped geotransform\n    clipped_ds.attrs[\"geotransform\"] = clipped_gt\n\n    # Drop unnecessary vars from dataset\n    clipped_ds = clipped_ds.drop_vars([\"glt_x\", \"glt_y\", \"downtrack\", \"crosstrack\"])\n\n    # Re-index the GLT to the new array\n    glt_x_data = clipped.glt_x.data - np.nanmin(clipped.glt_x)\n    glt_y_data = clipped.glt_y.data - np.nanmin(clipped.glt_y)\n    clipped_ds = clipped_ds.assign_coords(\n        {\n            \"glt_x\": ([\"ortho_y\", \"ortho_x\"], np.nan_to_num(glt_x_data)),\n            \"glt_y\": ([\"ortho_y\", \"ortho_x\"], np.nan_to_num(glt_y_data)),\n        }\n    )\n    clipped_ds = clipped_ds.assign_coords(\n        {\n            \"downtrack\": (\n                [\"downtrack\"],\n                np.arange(0, clipped_ds[list(ds.data_vars.keys())[0]].shape[0]),\n            ),\n            \"crosstrack\": (\n                [\"crosstrack\"],\n                np.arange(0, clipped_ds[list(ds.data_vars.keys())[0]].shape[1]),\n            ),\n        }\n    )\n\n    return clipped_ds\n</code></pre>"},{"location":"emit/#hypercoast.emit.read_emit","title":"<code>read_emit(filepath, ortho=True, wavelengths=None, method='nearest', **kwargs)</code>","text":"<p>Opens an EMIT dataset from a file path and assigns new coordinates to it.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The file path to the EMIT dataset.</p> required <code>ortho</code> <code>bool</code> <p>If True, the function will return an orthorectified dataset. Defaults to True.</p> <code>True</code> <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>xr.open_dataset</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>The dataset with new coordinates assigned.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def read_emit(filepath, ortho=True, wavelengths=None, method=\"nearest\", **kwargs):\n    \"\"\"\n    Opens an EMIT dataset from a file path and assigns new coordinates to it.\n\n    Args:\n        filepath (str): The file path to the EMIT dataset.\n        ortho (bool, optional): If True, the function will return an orthorectified dataset. Defaults to True.\n        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to be passed to `xr.open_dataset`.\n\n    Returns:\n        xarray.Dataset: The dataset with new coordinates assigned.\n\n    \"\"\"\n\n    if ortho == True:\n        return emit_xarray(\n            filepath, ortho=True, wavelengths=wavelengths, method=method, **kwargs\n        )\n    else:\n        ds = xr.open_dataset(filepath, **kwargs)\n        wvl = xr.open_dataset(filepath, group=\"sensor_band_parameters\")\n        loc = xr.open_dataset(filepath, group=\"location\")\n        ds = ds.assign_coords(\n            {\n                \"downtrack\": ([\"downtrack\"], ds.downtrack.data),\n                \"crosstrack\": ([\"crosstrack\"], ds.crosstrack.data),\n                **wvl.variables,\n                **loc.variables,\n            }\n        )\n        ds = ds.swap_dims({\"bands\": \"wavelengths\"})\n        del wvl\n        del loc\n\n        if wavelengths is not None:\n            ds = ds.sel(wavelengths=wavelengths, method=method)\n\n        return ds\n</code></pre>"},{"location":"emit/#hypercoast.emit.viz_emit","title":"<code>viz_emit(ds, wavelengths, cmap='viridis', frame_width=720, method='nearest', ortho=True, aspect='equal', tiles='ESRI', alpha=0.8, title=None, options={}, **kwargs)</code>","text":"<p>Visualizes the reflectance data from a given dataset at specific wavelengths.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset or str</code> <p>The dataset containing the reflectance data or the file path to the dataset.</p> required <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to visualize.</p> required <code>cmap</code> <code>str</code> <p>The colormap to use. Defaults to \"viridis\".</p> <code>'viridis'</code> <code>frame_width</code> <code>int</code> <p>The width of the frame. Defaults to 720.</p> <code>720</code> <code>method</code> <code>str</code> <p>The method to use for data selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>ortho</code> <code>bool</code> <p>If True, the function will return an orthorectified image. Defaults to True.</p> <code>True</code> <code>aspect</code> <code>str</code> <p>The aspect ratio of the plot. Defaults to \"equal\".</p> <code>'equal'</code> <code>tiles</code> <code>str</code> <p>The tile source to use for the background map. Defaults to \"ESRI\".</p> <code>'ESRI'</code> <code>alpha</code> <code>float</code> <p>The alpha value for the image. Defaults to 0.8.</p> <code>0.8</code> <code>title</code> <code>str</code> <p>The title of the plot. If None, a default title will be generated. Defaults to None.</p> <code>None</code> <code>options</code> <code>dict</code> <p>Additional options to be passed to <code>hvplot.image</code>. Defaults to {}.</p> <code>{}</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>hvplot.image</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>hvplot.Plot</code> <p>The image plot of the reflectance data at the specified wavelengths.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def viz_emit(\n    ds,\n    wavelengths,\n    cmap=\"viridis\",\n    frame_width=720,\n    method=\"nearest\",\n    ortho=True,\n    aspect=\"equal\",\n    tiles=\"ESRI\",\n    alpha=0.8,\n    title=None,\n    options={},\n    **kwargs,\n):\n    \"\"\"\n    Visualizes the reflectance data from a given dataset at specific wavelengths.\n\n    Args:\n        ds (xarray.Dataset or str): The dataset containing the reflectance data or the file path to the dataset.\n        wavelengths (array-like): The specific wavelengths to visualize.\n        cmap (str, optional): The colormap to use. Defaults to \"viridis\".\n        frame_width (int, optional): The width of the frame. Defaults to 720.\n        method (str, optional): The method to use for data selection. Defaults to \"nearest\".\n        ortho (bool, optional): If True, the function will return an orthorectified image. Defaults to True.\n        aspect (str, optional): The aspect ratio of the plot. Defaults to \"equal\".\n        tiles (str, optional): The tile source to use for the background map. Defaults to \"ESRI\".\n        alpha (float, optional): The alpha value for the image. Defaults to 0.8.\n        title (str, optional): The title of the plot. If None, a default title will be generated. Defaults to None.\n        options (dict, optional): Additional options to be passed to `hvplot.image`. Defaults to {}.\n        **kwargs: Additional keyword arguments to be passed to `hvplot.image`.\n\n    Returns:\n        hvplot.Plot: The image plot of the reflectance data at the specified wavelengths.\n    \"\"\"\n    import hvplot.xarray\n\n    if isinstance(ds, str):\n        ds = read_emit(ds, ortho=ortho)\n    example = ds.sel(wavelengths=wavelengths, method=method)\n\n    if title is None:\n        title = f\"Reflectance at {example.wavelengths.values:.3f} {example.wavelengths.units}\"\n\n    if ortho:\n        image = example.hvplot.image(\n            cmap=cmap,\n            geo=ortho,\n            tiles=tiles,\n            alpha=alpha,\n            frame_width=frame_width,\n            **kwargs,\n        ).opts(title=title, **options)\n    else:\n        image = example.hvplot.image(\n            cmap=cmap, aspect=aspect, alpha=alpha, frame_width=frame_width, **kwargs\n        ).opts(title=title, **options)\n\n    return image\n</code></pre>"},{"location":"emit/#hypercoast.emit.write_envi","title":"<code>write_envi(xr_ds, output_dir, overwrite=False, extension='.img', interleave='BIL', glt_file=False)</code>","text":"<p>Takes an EMIT dataset read into an xarray dataset using the emit_xarray function and writes an ENVI file and header.</p> <p>Parameters:</p> Name Type Description Default <code>xr_ds</code> <code>xarray.Dataset</code> <p>An EMIT dataset read into xarray using the emit_xarray function.</p> required <code>output_dir</code> <code>str</code> <p>Output directory.</p> required <code>overwrite</code> <code>bool</code> <p>Overwrite existing file if True. Defaults to False.</p> <code>False</code> <code>extension</code> <code>str</code> <p>The file extension for the envi formatted file, .img by default. Defaults to \".img\".</p> <code>'.img'</code> <code>interleave</code> <code>str</code> <p>The interleave option for the ENVI file. Defaults to \"BIL\".</p> <code>'BIL'</code> <code>glt_file</code> <code>bool</code> <p>Also create a GLT ENVI file for later use to reproject. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing:     - envi_ds (spectral.io.envi.Image): ENVI file in the output directory.     - glt_ds (spectral.io.envi.Image): GLT file in the output directory.</p> <p>Exceptions:</p> Type Description <code>Exception</code> <p>If the data is already orthorectified but a GLT file is still requested.</p> Source code in <code>hypercoast/emit.py</code> <pre><code>def write_envi(\n    xr_ds,\n    output_dir,\n    overwrite=False,\n    extension=\".img\",\n    interleave=\"BIL\",\n    glt_file=False,\n):\n    \"\"\"\n    Takes an EMIT dataset read into an xarray dataset using the emit_xarray function and writes an ENVI file and header.\n\n    Args:\n        xr_ds (xarray.Dataset): An EMIT dataset read into xarray using the emit_xarray function.\n        output_dir (str): Output directory.\n        overwrite (bool, optional): Overwrite existing file if True. Defaults to False.\n        extension (str, optional): The file extension for the envi formatted file, .img by default. Defaults to \".img\".\n        interleave (str, optional): The interleave option for the ENVI file. Defaults to \"BIL\".\n        glt_file (bool, optional): Also create a GLT ENVI file for later use to reproject. Defaults to False.\n\n    Returns:\n        tuple: A tuple containing:\n            - envi_ds (spectral.io.envi.Image): ENVI file in the output directory.\n            - glt_ds (spectral.io.envi.Image): GLT file in the output directory.\n\n    Raises:\n        Exception: If the data is already orthorectified but a GLT file is still requested.\n    \"\"\"\n    from spectral.io import envi\n\n    # Check if xr_ds has been orthorectified, raise exception if it has been but GLT is still requested\n    if (\n        \"Orthorectified\" in xr_ds.attrs.keys()\n        and xr_ds.attrs[\"Orthorectified\"] == \"True\"\n        and glt_file == True\n    ):\n        raise Exception(\"Data is already orthorectified.\")\n\n    # Typemap dictionary for ENVI files\n    envi_typemap = {\n        \"uint8\": 1,\n        \"int16\": 2,\n        \"int32\": 3,\n        \"float32\": 4,\n        \"float64\": 5,\n        \"complex64\": 6,\n        \"complex128\": 9,\n        \"uint16\": 12,\n        \"uint32\": 13,\n        \"int64\": 14,\n        \"uint64\": 15,\n    }\n\n    # Get CRS/geotransform for creation of Orthorectified ENVI file or optional GLT file\n    gt = xr_ds.attrs[\"geotransform\"]\n    mapinfo = (\n        \"{Geographic Lat/Lon, 1, 1, \"\n        + str(gt[0])\n        + \", \"\n        + str(gt[3])\n        + \", \"\n        + str(gt[1])\n        + \", \"\n        + str(gt[5] * -1)\n        + \", WGS-84, units=Degrees}\"\n    )\n\n    # This creates the coordinate system string\n    # hard-coded replacement of wkt crs could probably be improved, though should be the same for all EMIT datasets\n    csstring = '{ GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]] }'\n    # List data variables (typically reflectance/radiance)\n    var_names = list(xr_ds.data_vars)\n\n    # Loop through variable names\n    for var in var_names:\n        # Define output filename\n        output_name = os.path.join(output_dir, xr_ds.attrs[\"granule_id\"] + \"_\" + var)\n\n        nbands = 1\n        if len(xr_ds[var].data.shape) &gt; 2:\n            nbands = xr_ds[var].data.shape[2]\n\n        # Start building metadata\n        metadata = {\n            \"lines\": xr_ds[var].data.shape[0],\n            \"samples\": xr_ds[var].data.shape[1],\n            \"bands\": nbands,\n            \"interleave\": interleave,\n            \"header offset\": 0,\n            \"file type\": \"ENVI Standard\",\n            \"data type\": envi_typemap[str(xr_ds[var].data.dtype)],\n            \"byte order\": 0,\n        }\n\n        for key in list(xr_ds.attrs.keys()):\n            if key == \"summary\":\n                metadata[\"description\"] = xr_ds.attrs[key]\n            elif key not in [\"geotransform\", \"spatial_ref\"]:\n                metadata[key] = f\"{{ {xr_ds.attrs[key]} }}\"\n\n        # List all variables in dataset (including coordinate variables)\n        meta_vars = list(xr_ds.variables)\n\n        # Add band parameter information to metadata (ie wavelengths/obs etc.)\n        for m in meta_vars:\n            if m == \"wavelengths\" or m == \"radiance_wl\":\n                metadata[\"wavelength\"] = np.array(xr_ds[m].data).astype(str).tolist()\n            elif m == \"fwhm\" or m == \"radiance_fwhm\":\n                metadata[\"fwhm\"] = np.array(xr_ds[m].data).astype(str).tolist()\n            elif m == \"good_wavelengths\":\n                metadata[\"good_wavelengths\"] = (\n                    np.array(xr_ds[m].data).astype(int).tolist()\n                )\n            elif m == \"observation_bands\":\n                metadata[\"band names\"] = np.array(xr_ds[m].data).astype(str).tolist()\n            elif m == \"mask_bands\":\n                if var == \"band_mask\":\n                    metadata[\"band names\"] = [\n                        \"packed_bands_\" + bn\n                        for bn in np.arange(285 / 8).astype(str).tolist()\n                    ]\n                else:\n                    metadata[\"band names\"] = (\n                        np.array(xr_ds[m].data).astype(str).tolist()\n                    )\n            if \"wavelength\" in list(metadata.keys()) and \"band names\" not in list(\n                metadata.keys()\n            ):\n                metadata[\"band names\"] = metadata[\"wavelength\"]\n\n        # Add CRS/mapinfo if xarray dataset has been orthorectified\n        if (\n            \"Orthorectified\" in xr_ds.attrs.keys()\n            and xr_ds.attrs[\"Orthorectified\"] == \"True\"\n        ):\n            metadata[\"coordinate system string\"] = csstring\n            metadata[\"map info\"] = mapinfo\n\n        # Replace NaN values in each layer with fill_value\n        # np.nan_to_num(xr_ds[var].data, copy=False, nan=-9999)\n\n        # Write Variables as ENVI Output\n        envi_ds = envi.create_image(\n            envi_header(output_name), metadata, ext=extension, force=overwrite\n        )\n        mm = envi_ds.open_memmap(interleave=\"bip\", writable=True)\n\n        dat = xr_ds[var].data\n\n        if len(dat.shape) == 2:\n            dat = dat.reshape((dat.shape[0], dat.shape[1], 1))\n\n        mm[...] = dat\n\n    # Create GLT Metadata/File\n    if glt_file == True:\n        # Output Name\n        glt_output_name = os.path.join(\n            output_dir, xr_ds.attrs[\"granule_id\"] + \"_\" + \"glt\"\n        )\n\n        # Write GLT Metadata\n        glt_metadata = metadata\n\n        # Remove Unwanted Metadata\n        glt_metadata.pop(\"wavelength\", None)\n        glt_metadata.pop(\"fwhm\", None)\n\n        # Replace Metadata\n        glt_metadata[\"lines\"] = xr_ds[\"glt_x\"].data.shape[0]\n        glt_metadata[\"samples\"] = xr_ds[\"glt_x\"].data.shape[1]\n        glt_metadata[\"bands\"] = 2\n        glt_metadata[\"data type\"] = envi_typemap[\"int32\"]\n        glt_metadata[\"band names\"] = [\"glt_x\", \"glt_y\"]\n        glt_metadata[\"coordinate system string\"] = csstring\n        glt_metadata[\"map info\"] = mapinfo\n\n        # Write GLT Outputs as ENVI File\n        glt_ds = envi.create_image(\n            envi_header(glt_output_name), glt_metadata, ext=extension, force=overwrite\n        )\n        mmglt = glt_ds.open_memmap(interleave=\"bip\", writable=True)\n        mmglt[...] = np.stack(\n            (xr_ds[\"glt_x\"].values, xr_ds[\"glt_y\"].values), axis=-1\n        ).astype(\"int32\")\n</code></pre>"},{"location":"faq/","title":"FAQ","text":""},{"location":"hypercoast/","title":"hypercoast module","text":"<p>Main module.</p>"},{"location":"hypercoast/#hypercoast.hypercoast.Map","title":"<code> Map            (Map)         </code>","text":"<p>A class that extends leafmap.Map to provide additional functionality for     hypercoast.</p> <p>Methods</p> <p>Any methods inherited from leafmap.Map.</p> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>class Map(leafmap.Map):\n    \"\"\"\n    A class that extends leafmap.Map to provide additional functionality for\n        hypercoast.\n\n    Attributes:\n        Any attributes inherited from leafmap.Map.\n\n    Methods:\n        Any methods inherited from leafmap.Map.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes a new instance of the Map class.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments that are passed to the parent\n                class's constructor.\n        \"\"\"\n        super().__init__(**kwargs)\n\n    def add(self, obj, position=\"topright\", **kwargs):\n        \"\"\"Add a layer to the map.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments that are passed to the parent\n                class's add_layer method.\n        \"\"\"\n\n        if isinstance(obj, str):\n            if obj == \"spectral\":\n\n                SpectralWidget(self, position=position, **kwargs)\n                self.set_plot_options(add_marker_cluster=True)\n            else:\n                super().add(obj, **kwargs)\n\n        else:\n            super().add(obj, **kwargs)\n\n    def search_emit(self, default_dataset=\"EMITL2ARFL\"):\n        \"\"\"\n        Adds a NASA Earth Data search tool to the map with a default dataset for\n            EMIT.\n\n        Args:\n            default_dataset (str, optional): The default dataset to search for.\n                Defaults to \"EMITL2ARFL\".\n        \"\"\"\n        self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n\n    def search_pace(self, default_dataset=\"PACE_OCI_L2_AOP_NRT\"):\n        \"\"\"\n        Adds a NASA Earth Data search tool to the map with a default dataset for\n            PACE.\n\n        Args:\n            default_dataset (str, optional): The default dataset to search for.\n                Defaults to \"PACE_OCI_L2_AOP_NRT\".\n        \"\"\"\n        self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n\n    def search_ecostress(self, default_dataset=\"ECO_L2T_LSTE\"):\n        \"\"\"\n        Adds a NASA Earth Data search tool to the map with a default dataset for\n            ECOSTRESS.\n\n        Args:\n            default_dataset (str, optional): The default dataset to search for.\n                Defaults to \"ECO_L2T_LSTE\".\n        \"\"\"\n        self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n\n    def add_raster(\n        self,\n        source,\n        indexes=None,\n        colormap=None,\n        vmin=None,\n        vmax=None,\n        nodata=None,\n        attribution=None,\n        layer_name=\"Raster\",\n        zoom_to_layer=True,\n        visible=True,\n        array_args={},\n        **kwargs,\n    ):\n        \"\"\"Add a local raster dataset to the map.\n            If you are using this function in JupyterHub on a remote server\n                (e.g., Binder, Microsoft Planetary Computer) and\n            if the raster does not render properly, try installing\n                jupyter-server-proxy using `pip install jupyter-server-proxy`,\n            then running the following code before calling this function. For\n                more info, see https://bit.ly/3JbmF93.\n\n            import os\n            os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n        Args:\n            source (str): The path to the GeoTIFF file or the URL of the Cloud\n                Optimized GeoTIFF.\n            indexes (int, optional): The band(s) to use. Band indexing starts\n                at 1. Defaults to None.\n            colormap (str, optional): The name of the colormap from `matplotlib`\n                to use when plotting a single band. See\n                https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n                Default is greyscale.\n            vmin (float, optional): The minimum value to use when colormapping\n                the palette when plotting a single band. Defaults to None.\n            vmax (float, optional): The maximum value to use when colormapping\n                the palette when plotting a single band. Defaults to None.\n            nodata (float, optional): The value from the band to use to interpret\n                as not valid data. Defaults to None.\n            attribution (str, optional): Attribution for the source raster. This\n                defaults to a message about it being a local file.. Defaults to None.\n            layer_name (str, optional): The layer name to use. Defaults to 'Raster'.\n            zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n                layer. Defaults to True.\n            visible (bool, optional): Whether the layer is visible. Defaults to\n                True.\n            array_args (dict, optional): Additional arguments to pass to\n                `array_to_memory_file` when reading the raster. Defaults to {}.\n        \"\"\"\n\n        import numpy as np\n\n        if nodata is None:\n            nodata = np.nan\n        super().add_raster(\n            source,\n            indexes=indexes,\n            colormap=colormap,\n            vmin=vmin,\n            vmax=vmax,\n            nodata=nodata,\n            attribution=attribution,\n            layer_name=layer_name,\n            zoom_to_layer=zoom_to_layer,\n            visible=visible,\n            array_args=array_args,\n            **kwargs,\n        )\n\n    def add_emit(\n        self,\n        source,\n        wavelengths=None,\n        indexes=None,\n        colormap=None,\n        vmin=None,\n        vmax=None,\n        nodata=np.nan,\n        attribution=None,\n        layer_name=\"EMIT\",\n        zoom_to_layer=True,\n        visible=True,\n        array_args={},\n        **kwargs,\n    ):\n        \"\"\"Add an EMIT dataset to the map.\n            If you are using this function in JupyterHub on a remote server\n                (e.g., Binder, Microsoft Planetary Computer) and\n            if the raster does not render properly, try installing\n                jupyter-server-proxy using `pip install jupyter-server-proxy`,\n            then running the following code before calling this function. For\n                more info, see https://bit.ly/3JbmF93.\n\n            import os\n            os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n        Args:\n            source (str): The path to the GeoTIFF file or the URL of the Cloud\n                Optimized GeoTIFF.\n            indexes (int, optional): The band(s) to use. Band indexing starts\n                at 1. Defaults to None.\n            colormap (str, optional): The name of the colormap from `matplotlib`\n                to use when plotting a single band.\n                    See https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n                    Default is greyscale.\n            vmin (float, optional): The minimum value to use when colormapping\n                the palette when plotting a single band. Defaults to None.\n            vmax (float, optional): The maximum value to use when colormapping\n                the palette when plotting a single band. Defaults to None.\n            nodata (float, optional): The value from the band to use to\n                interpret as not valid data. Defaults to None.\n            attribution (str, optional): Attribution for the source raster. This\n                defaults to a message about it being a local file.. Defaults to None.\n            layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n            zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n                layer. Defaults to True.\n            visible (bool, optional): Whether the layer is visible. Defaults to\n                True.\n            array_args (dict, optional): Additional arguments to pass to\n                `array_to_memory_file` when reading the raster. Defaults to {}.\n        \"\"\"\n\n        xds = None\n        if isinstance(source, str):\n\n            xds = read_emit(source)\n            source = emit_to_image(xds, wavelengths=wavelengths)\n        elif isinstance(source, xr.Dataset):\n            xds = source\n            source = emit_to_image(xds, wavelengths=wavelengths)\n\n        self.add_raster(\n            source,\n            indexes=indexes,\n            colormap=colormap,\n            vmin=vmin,\n            vmax=vmax,\n            nodata=nodata,\n            attribution=attribution,\n            layer_name=layer_name,\n            zoom_to_layer=zoom_to_layer,\n            visible=visible,\n            array_args=array_args,\n            **kwargs,\n        )\n\n        self.cog_layer_dict[layer_name][\"xds\"] = xds\n        self.cog_layer_dict[layer_name][\"hyper\"] = \"EMIT\"\n\n    def add_pace(\n        self,\n        source,\n        wavelengths=None,\n        indexes=None,\n        colormap=\"jet\",\n        vmin=None,\n        vmax=None,\n        nodata=np.nan,\n        attribution=None,\n        layer_name=\"PACE\",\n        zoom_to_layer=True,\n        visible=True,\n        method=\"nearest\",\n        gridded=False,\n        array_args={},\n        **kwargs,\n    ):\n        \"\"\"Add a PACE dataset to the map.\n            If you are using this function in JupyterHub on a remote server\n                (e.g., Binder, Microsoft Planetary Computer) and\n            if the raster does not render properly, try installing\n                jupyter-server-proxy using `pip install jupyter-server-proxy`,\n            then running the following code before calling this function. For\n                more info, see https://bit.ly/3JbmF93.\n\n            import os\n            os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n        Args:\n            source (str): The path to the GeoTIFF file or the URL of the Cloud\n                Optimized GeoTIFF.\n            indexes (int, optional): The band(s) to use. Band indexing starts\n                at 1. Defaults to None.\n            colormap (str, optional): The name of the colormap from `matplotlib`\n                to use when plotting a single band. See\n                    https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n                    Default is greyscale.\n            vmin (float, optional): The minimum value to use when colormapping\n                the palette when plotting a single band. Defaults to None.\n            vmax (float, optional): The maximum value to use when colormapping\n                the palette when plotting a single band. Defaults to None.\n            nodata (float, optional): The value from the band to use to interpret\n                as not valid data. Defaults to None.\n            attribution (str, optional): Attribution for the source raster. This\n                defaults to a message about it being a local file.. Defaults to None.\n            layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n            zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n                layer. Defaults to True.\n            visible (bool, optional): Whether the layer is visible. Defaults to True.\n            array_args (dict, optional): Additional arguments to pass to\n                `array_to_memory_file` when reading the raster. Defaults to {}.\n        \"\"\"\n\n        if isinstance(source, str):\n\n            source = read_pace(source)\n\n        image = pace_to_image(\n            source, wavelengths=wavelengths, method=method, gridded=gridded\n        )\n\n        if isinstance(wavelengths, list) and len(wavelengths) &gt; 1:\n            colormap = None\n\n        self.add_raster(\n            image,\n            indexes=indexes,\n            colormap=colormap,\n            vmin=vmin,\n            vmax=vmax,\n            nodata=nodata,\n            attribution=attribution,\n            layer_name=layer_name,\n            zoom_to_layer=zoom_to_layer,\n            visible=visible,\n            array_args=array_args,\n            **kwargs,\n        )\n\n        self.cog_layer_dict[layer_name][\"xds\"] = source\n        self.cog_layer_dict[layer_name][\"hyper\"] = \"PACE\"\n\n    def add_desis(\n        self,\n        source,\n        bands=[50, 100, 200],\n        indexes=None,\n        colormap=\"jet\",\n        vmin=None,\n        vmax=None,\n        nodata=np.nan,\n        attribution=None,\n        layer_name=\"DESIS\",\n        zoom_to_layer=True,\n        visible=True,\n        method=\"nearest\",\n        array_args={},\n        **kwargs,\n    ):\n        \"\"\"Add a DESIS dataset to the map.\n            If you are using this function in JupyterHub on a remote server\n                (e.g., Binder, Microsoft Planetary Computer) and\n            if the raster does not render properly, try installing\n                jupyter-server-proxy using `pip install jupyter-server-proxy`,\n            then running the following code before calling this function. For\n                more info, see https://bit.ly/3JbmF93.\n\n            import os\n            os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n        Args:\n            source (str): The path to the GeoTIFF file or the URL of the Cloud\n                Optimized GeoTIFF.\n            indexes (int, optional): The band(s) to use. Band indexing starts\n                at 1. Defaults to None.\n            colormap (str, optional): The name of the colormap from `matplotlib`\n                to use when plotting a single band. See\n                https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n                Default is 'jet'.\n            vmin (float, optional): The minimum value to use when colormapping\n                the palette when plotting a single band. Defaults to None.\n            vmax (float, optional): The maximum value to use when colormapping\n                the palette when plotting a single band. Defaults to None.\n            nodata (float, optional): The value from the band to use to interpret\n                as not valid data. Defaults to None.\n            attribution (str, optional): Attribution for the source raster. This\n                defaults to a message about it being a local file.. Defaults to None.\n            layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n            zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n                layer. Defaults to True.\n            visible (bool, optional): Whether the layer is visible. Defaults to True.\n            array_args (dict, optional): Additional arguments to pass to\n                `array_to_memory_file` when reading the raster. Defaults to {}.\n        \"\"\"\n\n        if isinstance(source, str):\n\n            source = read_desis(source)\n\n        image = desis_to_image(source, bands=bands, method=method)\n\n        if isinstance(bands, list) and len(bands) &gt; 1:\n            colormap = None\n\n        if isinstance(bands, int):\n            bands = [bands]\n\n        if indexes is None:\n            if isinstance(bands, list) and len(bands) == 1:\n                indexes = [1]\n            else:\n                indexes = [3, 2, 1]\n\n        self.add_raster(\n            image,\n            indexes=indexes,\n            colormap=colormap,\n            vmin=vmin,\n            vmax=vmax,\n            nodata=nodata,\n            attribution=attribution,\n            layer_name=layer_name,\n            zoom_to_layer=zoom_to_layer,\n            visible=visible,\n            array_args=array_args,\n            **kwargs,\n        )\n\n        self.cog_layer_dict[layer_name][\"xds\"] = source\n        self.cog_layer_dict[layer_name][\"hyper\"] = \"DESIS\"\n\n    def add_neon(\n        self,\n        source,\n        wavelengths=None,\n        indexes=None,\n        colormap=None,\n        vmin=0,\n        vmax=0.5,\n        nodata=np.nan,\n        attribution=None,\n        layer_name=\"NEON\",\n        zoom_to_layer=True,\n        visible=True,\n        array_args={},\n        method=\"nearest\",\n        **kwargs,\n    ):\n        \"\"\"Add an NEON AOP dataset to the map.\n            If you are using this function in JupyterHub on a remote server\n                (e.g., Binder, Microsoft Planetary Computer) and\n            if the raster does not render properly, try installing\n                jupyter-server-proxy using `pip install jupyter-server-proxy`,\n            then running the following code before calling this function. For\n                more info, see https://bit.ly/3JbmF93.\n\n            import os\n            os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n        Args:\n            source (str): The path to the NEON AOP HDF5 file.\n            indexes (int, optional): The band(s) to use. Band indexing starts\n                at 1. Defaults to None.\n            colormap (str, optional): The name of the colormap from `matplotlib`\n                to use when plotting a single band. See\n                    https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n                    Default is greyscale.\n            vmin (float, optional): The minimum value to use when colormapping\n                the palette when plotting a single band. Defaults to 0.\n            vmax (float, optional): The maximum value to use when colormapping\n                the palette when plotting a single band. Defaults to 0.5.\n            nodata (float, optional): The value from the band to use to\n                interpret as not valid data. Defaults to np.nan.\n            attribution (str, optional): Attribution for the source raster. This\n                defaults to a message about it being a local file.. Defaults to None.\n            layer_name (str, optional): The layer name to use. Defaults to 'NEON'.\n            zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n                layer. Defaults to True.\n            visible (bool, optional): Whether the layer is visible. Defaults\n                to True.\n            array_args (dict, optional): Additional arguments to pass to\n                `array_to_memory_file` when reading the raster. Defaults to {}.\n            method (str, optional): The method to use for data interpolation.\n                Defaults to \"nearest\".\n        \"\"\"\n\n        xds = None\n        if isinstance(source, str):\n\n            xds = read_neon(source)\n            source = neon_to_image(xds, wavelengths=wavelengths, method=method)\n        elif isinstance(source, xr.Dataset):\n            xds = source\n            source = neon_to_image(xds, wavelengths=wavelengths, method=method)\n\n        self.add_raster(\n            source,\n            indexes=indexes,\n            colormap=colormap,\n            vmin=vmin,\n            vmax=vmax,\n            nodata=nodata,\n            attribution=attribution,\n            layer_name=layer_name,\n            zoom_to_layer=zoom_to_layer,\n            visible=visible,\n            array_args=array_args,\n            **kwargs,\n        )\n\n        self.cog_layer_dict[layer_name][\"xds\"] = xds\n        self.cog_layer_dict[layer_name][\"hyper\"] = \"NEON\"\n\n    def set_plot_options(\n        self,\n        add_marker_cluster=False,\n        plot_type=None,\n        overlay=False,\n        position=\"bottomright\",\n        min_width=None,\n        max_width=None,\n        min_height=None,\n        max_height=None,\n        **kwargs,\n    ):\n        \"\"\"Sets plotting options.\n\n        Args:\n            add_marker_cluster (bool, optional): Whether to add a marker cluster.\n                Defaults to False.\n            sample_scale (float, optional):  A nominal scale in meters of the\n                projection to sample in . Defaults to None.\n            plot_type (str, optional): The plot type can be one of \"None\", \"bar\",\n                \"scatter\" or \"hist\". Defaults to None.\n            overlay (bool, optional): Whether to overlay plotted lines on the\n                figure. Defaults to False.\n            position (str, optional): Position of the control, can be\n                \u2018bottomleft\u2019, \u2018bottomright\u2019, \u2018topleft\u2019, or \u2018topright\u2019. Defaults\n                to 'bottomright'.\n            min_width (int, optional): Min width of the widget (in pixels), if\n                None it will respect the content size. Defaults to None.\n            max_width (int, optional): Max width of the widget (in pixels), if\n                None it will respect the content size. Defaults to None.\n            min_height (int, optional): Min height of the widget (in pixels), if\n                None it will respect the content size. Defaults to None.\n            max_height (int, optional): Max height of the widget (in pixels), if\n                None it will respect the content size. Defaults to None.\n\n        \"\"\"\n        plot_options_dict = {}\n        plot_options_dict[\"add_marker_cluster\"] = add_marker_cluster\n        plot_options_dict[\"plot_type\"] = plot_type\n        plot_options_dict[\"overlay\"] = overlay\n        plot_options_dict[\"position\"] = position\n        plot_options_dict[\"min_width\"] = min_width\n        plot_options_dict[\"max_width\"] = max_width\n        plot_options_dict[\"min_height\"] = min_height\n        plot_options_dict[\"max_height\"] = max_height\n\n        for key in kwargs:\n            plot_options_dict[key] = kwargs[key]\n\n        self._plot_options = plot_options_dict\n\n        if not hasattr(self, \"_plot_marker_cluster\"):\n            self._plot_marker_cluster = ipyleaflet.MarkerCluster(name=\"Marker Cluster\")\n\n        if add_marker_cluster and (self._plot_marker_cluster not in self.layers):\n            self.add(self._plot_marker_cluster)\n\n    def spectral_to_df(self, **kwargs):\n        \"\"\"Converts the spectral data to a pandas DataFrame.\n\n        Returns:\n            pd.DataFrame: The spectral data as a pandas DataFrame.\n        \"\"\"\n        import pandas as pd\n\n        df = pd.DataFrame(self._spectral_data, **kwargs)\n        return df\n\n    def spectral_to_csv(self, filename, index=True, **kwargs):\n        \"\"\"Saves the spectral data to a CSV file.\n\n        Args:\n            filename (str): The output CSV file.\n            index (bool, optional): Whether to write the index. Defaults to True.\n        \"\"\"\n        df = self.spectral_to_df()\n        df = df.rename_axis(\"band\")\n        df.to_csv(filename, index=index, **kwargs)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.__init__","title":"<code>__init__(self, **kwargs)</code>  <code>special</code>","text":"<p>Initializes a new instance of the Map class.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments that are passed to the parent class's constructor.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes a new instance of the Map class.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments that are passed to the parent\n            class's constructor.\n    \"\"\"\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add","title":"<code>add(self, obj, position='topright', **kwargs)</code>","text":"<p>Add a layer to the map.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments that are passed to the parent class's add_layer method.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add(self, obj, position=\"topright\", **kwargs):\n    \"\"\"Add a layer to the map.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments that are passed to the parent\n            class's add_layer method.\n    \"\"\"\n\n    if isinstance(obj, str):\n        if obj == \"spectral\":\n\n            SpectralWidget(self, position=position, **kwargs)\n            self.set_plot_options(add_marker_cluster=True)\n        else:\n            super().add(obj, **kwargs)\n\n    else:\n        super().add(obj, **kwargs)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add_desis","title":"<code>add_desis(self, source, bands=[50, 100, 200], indexes=None, colormap='jet', vmin=None, vmax=None, nodata=nan, attribution=None, layer_name='DESIS', zoom_to_layer=True, visible=True, method='nearest', array_args={}, **kwargs)</code>","text":"<p>Add a DESIS dataset to the map.     If you are using this function in JupyterHub on a remote server         (e.g., Binder, Microsoft Planetary Computer) and     if the raster does not render properly, try installing         jupyter-server-proxy using <code>pip install jupyter-server-proxy</code>,     then running the following code before calling this function. For         more info, see https://bit.ly/3JbmF93.</p> <pre><code>import os\nos.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.</p> required <code>indexes</code> <code>int</code> <p>The band(s) to use. Band indexing starts at 1. Defaults to None.</p> <code>None</code> <code>colormap</code> <code>str</code> <p>The name of the colormap from <code>matplotlib</code> to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is 'jet'.</p> <code>'jet'</code> <code>vmin</code> <code>float</code> <p>The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>nodata</code> <code>float</code> <p>The value from the band to use to interpret as not valid data. Defaults to None.</p> <code>nan</code> <code>attribution</code> <code>str</code> <p>Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.</p> <code>None</code> <code>layer_name</code> <code>str</code> <p>The layer name to use. Defaults to 'EMIT'.</p> <code>'DESIS'</code> <code>zoom_to_layer</code> <code>bool</code> <p>Whether to zoom to the extent of the layer. Defaults to True.</p> <code>True</code> <code>visible</code> <code>bool</code> <p>Whether the layer is visible. Defaults to True.</p> <code>True</code> <code>array_args</code> <code>dict</code> <p>Additional arguments to pass to <code>array_to_memory_file</code> when reading the raster. Defaults to {}.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add_desis(\n    self,\n    source,\n    bands=[50, 100, 200],\n    indexes=None,\n    colormap=\"jet\",\n    vmin=None,\n    vmax=None,\n    nodata=np.nan,\n    attribution=None,\n    layer_name=\"DESIS\",\n    zoom_to_layer=True,\n    visible=True,\n    method=\"nearest\",\n    array_args={},\n    **kwargs,\n):\n    \"\"\"Add a DESIS dataset to the map.\n        If you are using this function in JupyterHub on a remote server\n            (e.g., Binder, Microsoft Planetary Computer) and\n        if the raster does not render properly, try installing\n            jupyter-server-proxy using `pip install jupyter-server-proxy`,\n        then running the following code before calling this function. For\n            more info, see https://bit.ly/3JbmF93.\n\n        import os\n        os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n    Args:\n        source (str): The path to the GeoTIFF file or the URL of the Cloud\n            Optimized GeoTIFF.\n        indexes (int, optional): The band(s) to use. Band indexing starts\n            at 1. Defaults to None.\n        colormap (str, optional): The name of the colormap from `matplotlib`\n            to use when plotting a single band. See\n            https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n            Default is 'jet'.\n        vmin (float, optional): The minimum value to use when colormapping\n            the palette when plotting a single band. Defaults to None.\n        vmax (float, optional): The maximum value to use when colormapping\n            the palette when plotting a single band. Defaults to None.\n        nodata (float, optional): The value from the band to use to interpret\n            as not valid data. Defaults to None.\n        attribution (str, optional): Attribution for the source raster. This\n            defaults to a message about it being a local file.. Defaults to None.\n        layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n        zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n            layer. Defaults to True.\n        visible (bool, optional): Whether the layer is visible. Defaults to True.\n        array_args (dict, optional): Additional arguments to pass to\n            `array_to_memory_file` when reading the raster. Defaults to {}.\n    \"\"\"\n\n    if isinstance(source, str):\n\n        source = read_desis(source)\n\n    image = desis_to_image(source, bands=bands, method=method)\n\n    if isinstance(bands, list) and len(bands) &gt; 1:\n        colormap = None\n\n    if isinstance(bands, int):\n        bands = [bands]\n\n    if indexes is None:\n        if isinstance(bands, list) and len(bands) == 1:\n            indexes = [1]\n        else:\n            indexes = [3, 2, 1]\n\n    self.add_raster(\n        image,\n        indexes=indexes,\n        colormap=colormap,\n        vmin=vmin,\n        vmax=vmax,\n        nodata=nodata,\n        attribution=attribution,\n        layer_name=layer_name,\n        zoom_to_layer=zoom_to_layer,\n        visible=visible,\n        array_args=array_args,\n        **kwargs,\n    )\n\n    self.cog_layer_dict[layer_name][\"xds\"] = source\n    self.cog_layer_dict[layer_name][\"hyper\"] = \"DESIS\"\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add_emit","title":"<code>add_emit(self, source, wavelengths=None, indexes=None, colormap=None, vmin=None, vmax=None, nodata=nan, attribution=None, layer_name='EMIT', zoom_to_layer=True, visible=True, array_args={}, **kwargs)</code>","text":"<p>Add an EMIT dataset to the map.     If you are using this function in JupyterHub on a remote server         (e.g., Binder, Microsoft Planetary Computer) and     if the raster does not render properly, try installing         jupyter-server-proxy using <code>pip install jupyter-server-proxy</code>,     then running the following code before calling this function. For         more info, see https://bit.ly/3JbmF93.</p> <pre><code>import os\nos.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.</p> required <code>indexes</code> <code>int</code> <p>The band(s) to use. Band indexing starts at 1. Defaults to None.</p> <code>None</code> <code>colormap</code> <code>str</code> <p>The name of the colormap from <code>matplotlib</code> to use when plotting a single band.     See https://matplotlib.org/stable/gallery/color/colormap_reference.html.     Default is greyscale.</p> <code>None</code> <code>vmin</code> <code>float</code> <p>The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>nodata</code> <code>float</code> <p>The value from the band to use to interpret as not valid data. Defaults to None.</p> <code>nan</code> <code>attribution</code> <code>str</code> <p>Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.</p> <code>None</code> <code>layer_name</code> <code>str</code> <p>The layer name to use. Defaults to 'EMIT'.</p> <code>'EMIT'</code> <code>zoom_to_layer</code> <code>bool</code> <p>Whether to zoom to the extent of the layer. Defaults to True.</p> <code>True</code> <code>visible</code> <code>bool</code> <p>Whether the layer is visible. Defaults to True.</p> <code>True</code> <code>array_args</code> <code>dict</code> <p>Additional arguments to pass to <code>array_to_memory_file</code> when reading the raster. Defaults to {}.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add_emit(\n    self,\n    source,\n    wavelengths=None,\n    indexes=None,\n    colormap=None,\n    vmin=None,\n    vmax=None,\n    nodata=np.nan,\n    attribution=None,\n    layer_name=\"EMIT\",\n    zoom_to_layer=True,\n    visible=True,\n    array_args={},\n    **kwargs,\n):\n    \"\"\"Add an EMIT dataset to the map.\n        If you are using this function in JupyterHub on a remote server\n            (e.g., Binder, Microsoft Planetary Computer) and\n        if the raster does not render properly, try installing\n            jupyter-server-proxy using `pip install jupyter-server-proxy`,\n        then running the following code before calling this function. For\n            more info, see https://bit.ly/3JbmF93.\n\n        import os\n        os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n    Args:\n        source (str): The path to the GeoTIFF file or the URL of the Cloud\n            Optimized GeoTIFF.\n        indexes (int, optional): The band(s) to use. Band indexing starts\n            at 1. Defaults to None.\n        colormap (str, optional): The name of the colormap from `matplotlib`\n            to use when plotting a single band.\n                See https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n                Default is greyscale.\n        vmin (float, optional): The minimum value to use when colormapping\n            the palette when plotting a single band. Defaults to None.\n        vmax (float, optional): The maximum value to use when colormapping\n            the palette when plotting a single band. Defaults to None.\n        nodata (float, optional): The value from the band to use to\n            interpret as not valid data. Defaults to None.\n        attribution (str, optional): Attribution for the source raster. This\n            defaults to a message about it being a local file.. Defaults to None.\n        layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n        zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n            layer. Defaults to True.\n        visible (bool, optional): Whether the layer is visible. Defaults to\n            True.\n        array_args (dict, optional): Additional arguments to pass to\n            `array_to_memory_file` when reading the raster. Defaults to {}.\n    \"\"\"\n\n    xds = None\n    if isinstance(source, str):\n\n        xds = read_emit(source)\n        source = emit_to_image(xds, wavelengths=wavelengths)\n    elif isinstance(source, xr.Dataset):\n        xds = source\n        source = emit_to_image(xds, wavelengths=wavelengths)\n\n    self.add_raster(\n        source,\n        indexes=indexes,\n        colormap=colormap,\n        vmin=vmin,\n        vmax=vmax,\n        nodata=nodata,\n        attribution=attribution,\n        layer_name=layer_name,\n        zoom_to_layer=zoom_to_layer,\n        visible=visible,\n        array_args=array_args,\n        **kwargs,\n    )\n\n    self.cog_layer_dict[layer_name][\"xds\"] = xds\n    self.cog_layer_dict[layer_name][\"hyper\"] = \"EMIT\"\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add_neon","title":"<code>add_neon(self, source, wavelengths=None, indexes=None, colormap=None, vmin=0, vmax=0.5, nodata=nan, attribution=None, layer_name='NEON', zoom_to_layer=True, visible=True, array_args={}, method='nearest', **kwargs)</code>","text":"<p>Add an NEON AOP dataset to the map.     If you are using this function in JupyterHub on a remote server         (e.g., Binder, Microsoft Planetary Computer) and     if the raster does not render properly, try installing         jupyter-server-proxy using <code>pip install jupyter-server-proxy</code>,     then running the following code before calling this function. For         more info, see https://bit.ly/3JbmF93.</p> <pre><code>import os\nos.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the NEON AOP HDF5 file.</p> required <code>indexes</code> <code>int</code> <p>The band(s) to use. Band indexing starts at 1. Defaults to None.</p> <code>None</code> <code>colormap</code> <code>str</code> <p>The name of the colormap from <code>matplotlib</code> to use when plotting a single band. See     https://matplotlib.org/stable/gallery/color/colormap_reference.html.     Default is greyscale.</p> <code>None</code> <code>vmin</code> <code>float</code> <p>The minimum value to use when colormapping the palette when plotting a single band. Defaults to 0.</p> <code>0</code> <code>vmax</code> <code>float</code> <p>The maximum value to use when colormapping the palette when plotting a single band. Defaults to 0.5.</p> <code>0.5</code> <code>nodata</code> <code>float</code> <p>The value from the band to use to interpret as not valid data. Defaults to np.nan.</p> <code>nan</code> <code>attribution</code> <code>str</code> <p>Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.</p> <code>None</code> <code>layer_name</code> <code>str</code> <p>The layer name to use. Defaults to 'NEON'.</p> <code>'NEON'</code> <code>zoom_to_layer</code> <code>bool</code> <p>Whether to zoom to the extent of the layer. Defaults to True.</p> <code>True</code> <code>visible</code> <code>bool</code> <p>Whether the layer is visible. Defaults to True.</p> <code>True</code> <code>array_args</code> <code>dict</code> <p>Additional arguments to pass to <code>array_to_memory_file</code> when reading the raster. Defaults to {}.</p> <code>{}</code> <code>method</code> <code>str</code> <p>The method to use for data interpolation. Defaults to \"nearest\".</p> <code>'nearest'</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add_neon(\n    self,\n    source,\n    wavelengths=None,\n    indexes=None,\n    colormap=None,\n    vmin=0,\n    vmax=0.5,\n    nodata=np.nan,\n    attribution=None,\n    layer_name=\"NEON\",\n    zoom_to_layer=True,\n    visible=True,\n    array_args={},\n    method=\"nearest\",\n    **kwargs,\n):\n    \"\"\"Add an NEON AOP dataset to the map.\n        If you are using this function in JupyterHub on a remote server\n            (e.g., Binder, Microsoft Planetary Computer) and\n        if the raster does not render properly, try installing\n            jupyter-server-proxy using `pip install jupyter-server-proxy`,\n        then running the following code before calling this function. For\n            more info, see https://bit.ly/3JbmF93.\n\n        import os\n        os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n    Args:\n        source (str): The path to the NEON AOP HDF5 file.\n        indexes (int, optional): The band(s) to use. Band indexing starts\n            at 1. Defaults to None.\n        colormap (str, optional): The name of the colormap from `matplotlib`\n            to use when plotting a single band. See\n                https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n                Default is greyscale.\n        vmin (float, optional): The minimum value to use when colormapping\n            the palette when plotting a single band. Defaults to 0.\n        vmax (float, optional): The maximum value to use when colormapping\n            the palette when plotting a single band. Defaults to 0.5.\n        nodata (float, optional): The value from the band to use to\n            interpret as not valid data. Defaults to np.nan.\n        attribution (str, optional): Attribution for the source raster. This\n            defaults to a message about it being a local file.. Defaults to None.\n        layer_name (str, optional): The layer name to use. Defaults to 'NEON'.\n        zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n            layer. Defaults to True.\n        visible (bool, optional): Whether the layer is visible. Defaults\n            to True.\n        array_args (dict, optional): Additional arguments to pass to\n            `array_to_memory_file` when reading the raster. Defaults to {}.\n        method (str, optional): The method to use for data interpolation.\n            Defaults to \"nearest\".\n    \"\"\"\n\n    xds = None\n    if isinstance(source, str):\n\n        xds = read_neon(source)\n        source = neon_to_image(xds, wavelengths=wavelengths, method=method)\n    elif isinstance(source, xr.Dataset):\n        xds = source\n        source = neon_to_image(xds, wavelengths=wavelengths, method=method)\n\n    self.add_raster(\n        source,\n        indexes=indexes,\n        colormap=colormap,\n        vmin=vmin,\n        vmax=vmax,\n        nodata=nodata,\n        attribution=attribution,\n        layer_name=layer_name,\n        zoom_to_layer=zoom_to_layer,\n        visible=visible,\n        array_args=array_args,\n        **kwargs,\n    )\n\n    self.cog_layer_dict[layer_name][\"xds\"] = xds\n    self.cog_layer_dict[layer_name][\"hyper\"] = \"NEON\"\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add_pace","title":"<code>add_pace(self, source, wavelengths=None, indexes=None, colormap='jet', vmin=None, vmax=None, nodata=nan, attribution=None, layer_name='PACE', zoom_to_layer=True, visible=True, method='nearest', gridded=False, array_args={}, **kwargs)</code>","text":"<p>Add a PACE dataset to the map.     If you are using this function in JupyterHub on a remote server         (e.g., Binder, Microsoft Planetary Computer) and     if the raster does not render properly, try installing         jupyter-server-proxy using <code>pip install jupyter-server-proxy</code>,     then running the following code before calling this function. For         more info, see https://bit.ly/3JbmF93.</p> <pre><code>import os\nos.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.</p> required <code>indexes</code> <code>int</code> <p>The band(s) to use. Band indexing starts at 1. Defaults to None.</p> <code>None</code> <code>colormap</code> <code>str</code> <p>The name of the colormap from <code>matplotlib</code> to use when plotting a single band. See     https://matplotlib.org/stable/gallery/color/colormap_reference.html.     Default is greyscale.</p> <code>'jet'</code> <code>vmin</code> <code>float</code> <p>The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>nodata</code> <code>float</code> <p>The value from the band to use to interpret as not valid data. Defaults to None.</p> <code>nan</code> <code>attribution</code> <code>str</code> <p>Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.</p> <code>None</code> <code>layer_name</code> <code>str</code> <p>The layer name to use. Defaults to 'EMIT'.</p> <code>'PACE'</code> <code>zoom_to_layer</code> <code>bool</code> <p>Whether to zoom to the extent of the layer. Defaults to True.</p> <code>True</code> <code>visible</code> <code>bool</code> <p>Whether the layer is visible. Defaults to True.</p> <code>True</code> <code>array_args</code> <code>dict</code> <p>Additional arguments to pass to <code>array_to_memory_file</code> when reading the raster. Defaults to {}.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add_pace(\n    self,\n    source,\n    wavelengths=None,\n    indexes=None,\n    colormap=\"jet\",\n    vmin=None,\n    vmax=None,\n    nodata=np.nan,\n    attribution=None,\n    layer_name=\"PACE\",\n    zoom_to_layer=True,\n    visible=True,\n    method=\"nearest\",\n    gridded=False,\n    array_args={},\n    **kwargs,\n):\n    \"\"\"Add a PACE dataset to the map.\n        If you are using this function in JupyterHub on a remote server\n            (e.g., Binder, Microsoft Planetary Computer) and\n        if the raster does not render properly, try installing\n            jupyter-server-proxy using `pip install jupyter-server-proxy`,\n        then running the following code before calling this function. For\n            more info, see https://bit.ly/3JbmF93.\n\n        import os\n        os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n    Args:\n        source (str): The path to the GeoTIFF file or the URL of the Cloud\n            Optimized GeoTIFF.\n        indexes (int, optional): The band(s) to use. Band indexing starts\n            at 1. Defaults to None.\n        colormap (str, optional): The name of the colormap from `matplotlib`\n            to use when plotting a single band. See\n                https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n                Default is greyscale.\n        vmin (float, optional): The minimum value to use when colormapping\n            the palette when plotting a single band. Defaults to None.\n        vmax (float, optional): The maximum value to use when colormapping\n            the palette when plotting a single band. Defaults to None.\n        nodata (float, optional): The value from the band to use to interpret\n            as not valid data. Defaults to None.\n        attribution (str, optional): Attribution for the source raster. This\n            defaults to a message about it being a local file.. Defaults to None.\n        layer_name (str, optional): The layer name to use. Defaults to 'EMIT'.\n        zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n            layer. Defaults to True.\n        visible (bool, optional): Whether the layer is visible. Defaults to True.\n        array_args (dict, optional): Additional arguments to pass to\n            `array_to_memory_file` when reading the raster. Defaults to {}.\n    \"\"\"\n\n    if isinstance(source, str):\n\n        source = read_pace(source)\n\n    image = pace_to_image(\n        source, wavelengths=wavelengths, method=method, gridded=gridded\n    )\n\n    if isinstance(wavelengths, list) and len(wavelengths) &gt; 1:\n        colormap = None\n\n    self.add_raster(\n        image,\n        indexes=indexes,\n        colormap=colormap,\n        vmin=vmin,\n        vmax=vmax,\n        nodata=nodata,\n        attribution=attribution,\n        layer_name=layer_name,\n        zoom_to_layer=zoom_to_layer,\n        visible=visible,\n        array_args=array_args,\n        **kwargs,\n    )\n\n    self.cog_layer_dict[layer_name][\"xds\"] = source\n    self.cog_layer_dict[layer_name][\"hyper\"] = \"PACE\"\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.add_raster","title":"<code>add_raster(self, source, indexes=None, colormap=None, vmin=None, vmax=None, nodata=None, attribution=None, layer_name='Raster', zoom_to_layer=True, visible=True, array_args={}, **kwargs)</code>","text":"<p>Add a local raster dataset to the map.     If you are using this function in JupyterHub on a remote server         (e.g., Binder, Microsoft Planetary Computer) and     if the raster does not render properly, try installing         jupyter-server-proxy using <code>pip install jupyter-server-proxy</code>,     then running the following code before calling this function. For         more info, see https://bit.ly/3JbmF93.</p> <pre><code>import os\nos.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>The path to the GeoTIFF file or the URL of the Cloud Optimized GeoTIFF.</p> required <code>indexes</code> <code>int</code> <p>The band(s) to use. Band indexing starts at 1. Defaults to None.</p> <code>None</code> <code>colormap</code> <code>str</code> <p>The name of the colormap from <code>matplotlib</code> to use when plotting a single band. See https://matplotlib.org/stable/gallery/color/colormap_reference.html. Default is greyscale.</p> <code>None</code> <code>vmin</code> <code>float</code> <p>The minimum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>The maximum value to use when colormapping the palette when plotting a single band. Defaults to None.</p> <code>None</code> <code>nodata</code> <code>float</code> <p>The value from the band to use to interpret as not valid data. Defaults to None.</p> <code>None</code> <code>attribution</code> <code>str</code> <p>Attribution for the source raster. This defaults to a message about it being a local file.. Defaults to None.</p> <code>None</code> <code>layer_name</code> <code>str</code> <p>The layer name to use. Defaults to 'Raster'.</p> <code>'Raster'</code> <code>zoom_to_layer</code> <code>bool</code> <p>Whether to zoom to the extent of the layer. Defaults to True.</p> <code>True</code> <code>visible</code> <code>bool</code> <p>Whether the layer is visible. Defaults to True.</p> <code>True</code> <code>array_args</code> <code>dict</code> <p>Additional arguments to pass to <code>array_to_memory_file</code> when reading the raster. Defaults to {}.</p> <code>{}</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def add_raster(\n    self,\n    source,\n    indexes=None,\n    colormap=None,\n    vmin=None,\n    vmax=None,\n    nodata=None,\n    attribution=None,\n    layer_name=\"Raster\",\n    zoom_to_layer=True,\n    visible=True,\n    array_args={},\n    **kwargs,\n):\n    \"\"\"Add a local raster dataset to the map.\n        If you are using this function in JupyterHub on a remote server\n            (e.g., Binder, Microsoft Planetary Computer) and\n        if the raster does not render properly, try installing\n            jupyter-server-proxy using `pip install jupyter-server-proxy`,\n        then running the following code before calling this function. For\n            more info, see https://bit.ly/3JbmF93.\n\n        import os\n        os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n\n    Args:\n        source (str): The path to the GeoTIFF file or the URL of the Cloud\n            Optimized GeoTIFF.\n        indexes (int, optional): The band(s) to use. Band indexing starts\n            at 1. Defaults to None.\n        colormap (str, optional): The name of the colormap from `matplotlib`\n            to use when plotting a single band. See\n            https://matplotlib.org/stable/gallery/color/colormap_reference.html.\n            Default is greyscale.\n        vmin (float, optional): The minimum value to use when colormapping\n            the palette when plotting a single band. Defaults to None.\n        vmax (float, optional): The maximum value to use when colormapping\n            the palette when plotting a single band. Defaults to None.\n        nodata (float, optional): The value from the band to use to interpret\n            as not valid data. Defaults to None.\n        attribution (str, optional): Attribution for the source raster. This\n            defaults to a message about it being a local file.. Defaults to None.\n        layer_name (str, optional): The layer name to use. Defaults to 'Raster'.\n        zoom_to_layer (bool, optional): Whether to zoom to the extent of the\n            layer. Defaults to True.\n        visible (bool, optional): Whether the layer is visible. Defaults to\n            True.\n        array_args (dict, optional): Additional arguments to pass to\n            `array_to_memory_file` when reading the raster. Defaults to {}.\n    \"\"\"\n\n    import numpy as np\n\n    if nodata is None:\n        nodata = np.nan\n    super().add_raster(\n        source,\n        indexes=indexes,\n        colormap=colormap,\n        vmin=vmin,\n        vmax=vmax,\n        nodata=nodata,\n        attribution=attribution,\n        layer_name=layer_name,\n        zoom_to_layer=zoom_to_layer,\n        visible=visible,\n        array_args=array_args,\n        **kwargs,\n    )\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.search_ecostress","title":"<code>search_ecostress(self, default_dataset='ECO_L2T_LSTE')</code>","text":"<p>Adds a NASA Earth Data search tool to the map with a default dataset for     ECOSTRESS.</p> <p>Parameters:</p> Name Type Description Default <code>default_dataset</code> <code>str</code> <p>The default dataset to search for. Defaults to \"ECO_L2T_LSTE\".</p> <code>'ECO_L2T_LSTE'</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def search_ecostress(self, default_dataset=\"ECO_L2T_LSTE\"):\n    \"\"\"\n    Adds a NASA Earth Data search tool to the map with a default dataset for\n        ECOSTRESS.\n\n    Args:\n        default_dataset (str, optional): The default dataset to search for.\n            Defaults to \"ECO_L2T_LSTE\".\n    \"\"\"\n    self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.search_emit","title":"<code>search_emit(self, default_dataset='EMITL2ARFL')</code>","text":"<p>Adds a NASA Earth Data search tool to the map with a default dataset for     EMIT.</p> <p>Parameters:</p> Name Type Description Default <code>default_dataset</code> <code>str</code> <p>The default dataset to search for. Defaults to \"EMITL2ARFL\".</p> <code>'EMITL2ARFL'</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def search_emit(self, default_dataset=\"EMITL2ARFL\"):\n    \"\"\"\n    Adds a NASA Earth Data search tool to the map with a default dataset for\n        EMIT.\n\n    Args:\n        default_dataset (str, optional): The default dataset to search for.\n            Defaults to \"EMITL2ARFL\".\n    \"\"\"\n    self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.search_pace","title":"<code>search_pace(self, default_dataset='PACE_OCI_L2_AOP_NRT')</code>","text":"<p>Adds a NASA Earth Data search tool to the map with a default dataset for     PACE.</p> <p>Parameters:</p> Name Type Description Default <code>default_dataset</code> <code>str</code> <p>The default dataset to search for. Defaults to \"PACE_OCI_L2_AOP_NRT\".</p> <code>'PACE_OCI_L2_AOP_NRT'</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def search_pace(self, default_dataset=\"PACE_OCI_L2_AOP_NRT\"):\n    \"\"\"\n    Adds a NASA Earth Data search tool to the map with a default dataset for\n        PACE.\n\n    Args:\n        default_dataset (str, optional): The default dataset to search for.\n            Defaults to \"PACE_OCI_L2_AOP_NRT\".\n    \"\"\"\n    self.add(\"nasa_earth_data\", default_dataset=default_dataset)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.set_plot_options","title":"<code>set_plot_options(self, add_marker_cluster=False, plot_type=None, overlay=False, position='bottomright', min_width=None, max_width=None, min_height=None, max_height=None, **kwargs)</code>","text":"<p>Sets plotting options.</p> <p>Parameters:</p> Name Type Description Default <code>add_marker_cluster</code> <code>bool</code> <p>Whether to add a marker cluster. Defaults to False.</p> <code>False</code> <code>sample_scale</code> <code>float</code> <p>A nominal scale in meters of the projection to sample in . Defaults to None.</p> required <code>plot_type</code> <code>str</code> <p>The plot type can be one of \"None\", \"bar\", \"scatter\" or \"hist\". Defaults to None.</p> <code>None</code> <code>overlay</code> <code>bool</code> <p>Whether to overlay plotted lines on the figure. Defaults to False.</p> <code>False</code> <code>position</code> <code>str</code> <p>Position of the control, can be \u2018bottomleft\u2019, \u2018bottomright\u2019, \u2018topleft\u2019, or \u2018topright\u2019. Defaults to 'bottomright'.</p> <code>'bottomright'</code> <code>min_width</code> <code>int</code> <p>Min width of the widget (in pixels), if None it will respect the content size. Defaults to None.</p> <code>None</code> <code>max_width</code> <code>int</code> <p>Max width of the widget (in pixels), if None it will respect the content size. Defaults to None.</p> <code>None</code> <code>min_height</code> <code>int</code> <p>Min height of the widget (in pixels), if None it will respect the content size. Defaults to None.</p> <code>None</code> <code>max_height</code> <code>int</code> <p>Max height of the widget (in pixels), if None it will respect the content size. Defaults to None.</p> <code>None</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def set_plot_options(\n    self,\n    add_marker_cluster=False,\n    plot_type=None,\n    overlay=False,\n    position=\"bottomright\",\n    min_width=None,\n    max_width=None,\n    min_height=None,\n    max_height=None,\n    **kwargs,\n):\n    \"\"\"Sets plotting options.\n\n    Args:\n        add_marker_cluster (bool, optional): Whether to add a marker cluster.\n            Defaults to False.\n        sample_scale (float, optional):  A nominal scale in meters of the\n            projection to sample in . Defaults to None.\n        plot_type (str, optional): The plot type can be one of \"None\", \"bar\",\n            \"scatter\" or \"hist\". Defaults to None.\n        overlay (bool, optional): Whether to overlay plotted lines on the\n            figure. Defaults to False.\n        position (str, optional): Position of the control, can be\n            \u2018bottomleft\u2019, \u2018bottomright\u2019, \u2018topleft\u2019, or \u2018topright\u2019. Defaults\n            to 'bottomright'.\n        min_width (int, optional): Min width of the widget (in pixels), if\n            None it will respect the content size. Defaults to None.\n        max_width (int, optional): Max width of the widget (in pixels), if\n            None it will respect the content size. Defaults to None.\n        min_height (int, optional): Min height of the widget (in pixels), if\n            None it will respect the content size. Defaults to None.\n        max_height (int, optional): Max height of the widget (in pixels), if\n            None it will respect the content size. Defaults to None.\n\n    \"\"\"\n    plot_options_dict = {}\n    plot_options_dict[\"add_marker_cluster\"] = add_marker_cluster\n    plot_options_dict[\"plot_type\"] = plot_type\n    plot_options_dict[\"overlay\"] = overlay\n    plot_options_dict[\"position\"] = position\n    plot_options_dict[\"min_width\"] = min_width\n    plot_options_dict[\"max_width\"] = max_width\n    plot_options_dict[\"min_height\"] = min_height\n    plot_options_dict[\"max_height\"] = max_height\n\n    for key in kwargs:\n        plot_options_dict[key] = kwargs[key]\n\n    self._plot_options = plot_options_dict\n\n    if not hasattr(self, \"_plot_marker_cluster\"):\n        self._plot_marker_cluster = ipyleaflet.MarkerCluster(name=\"Marker Cluster\")\n\n    if add_marker_cluster and (self._plot_marker_cluster not in self.layers):\n        self.add(self._plot_marker_cluster)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.spectral_to_csv","title":"<code>spectral_to_csv(self, filename, index=True, **kwargs)</code>","text":"<p>Saves the spectral data to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The output CSV file.</p> required <code>index</code> <code>bool</code> <p>Whether to write the index. Defaults to True.</p> <code>True</code> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def spectral_to_csv(self, filename, index=True, **kwargs):\n    \"\"\"Saves the spectral data to a CSV file.\n\n    Args:\n        filename (str): The output CSV file.\n        index (bool, optional): Whether to write the index. Defaults to True.\n    \"\"\"\n    df = self.spectral_to_df()\n    df = df.rename_axis(\"band\")\n    df.to_csv(filename, index=index, **kwargs)\n</code></pre>"},{"location":"hypercoast/#hypercoast.hypercoast.Map.spectral_to_df","title":"<code>spectral_to_df(self, **kwargs)</code>","text":"<p>Converts the spectral data to a pandas DataFrame.</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>The spectral data as a pandas DataFrame.</p> Source code in <code>hypercoast/hypercoast.py</code> <pre><code>def spectral_to_df(self, **kwargs):\n    \"\"\"Converts the spectral data to a pandas DataFrame.\n\n    Returns:\n        pd.DataFrame: The spectral data as a pandas DataFrame.\n    \"\"\"\n    import pandas as pd\n\n    df = pd.DataFrame(self._spectral_data, **kwargs)\n    return df\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>hypercoast is available on PyPI. To install hypercoast, run this command in your terminal:</p> <pre><code>pip install hypercoast\n</code></pre>"},{"location":"installation/#install-from-conda-forge","title":"Install from conda-forge","text":"<p>hypercoast is also available on conda-forge. If you have Anaconda or Miniconda installed on your computer, you can install hypercoast using the following command:</p> <pre><code>conda install -c conda-forge hypercoast\n</code></pre> <p>Alternatively, you can create a new conda environment and install hypercoast in the new environment. This is a good practice because it avoids potential conflicts with other packages installed in your base environment.</p> <pre><code>conda install -n base mamba -c conda-forge\nconda create -n hyper python=3.11\nconda activate hyper\nmamba install -c conda-forge hypercoast\n</code></pre>"},{"location":"installation/#install-from-github","title":"Install from GitHub","text":"<p>To install the development version from GitHub using Git, run the following command in your terminal:</p> <pre><code>pip install git+https://github.com/opengeos/hypercoast\n</code></pre>"},{"location":"neon/","title":"neon module","text":"<p>This module contains functions to read and process NEON AOP hyperspectral data. More info about the data can be found at https://bit.ly/3Rfszdc. The source code is adapted from https://bit.ly/3KwyZkn. Credit goes to the original authors.</p>"},{"location":"neon/#hypercoast.neon.extract_neon","title":"<code>extract_neon(ds, lat, lon)</code>","text":"<p>Extracts NEON AOP data from a given xarray Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>xarray.Dataset</code> <p>The dataset containing the NEON AOP data.</p> required <code>lat</code> <code>float</code> <p>The latitude of the point to extract.</p> required <code>lon</code> <code>float</code> <p>The longitude of the point to extract.</p> required <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>The extracted data.</p> Source code in <code>hypercoast/neon.py</code> <pre><code>def extract_neon(ds, lat, lon):\n    \"\"\"\n    Extracts NEON AOP data from a given xarray Dataset.\n\n    Args:\n        ds (xarray.Dataset): The dataset containing the NEON AOP data.\n        lat (float): The latitude of the point to extract.\n        lon (float): The longitude of the point to extract.\n\n    Returns:\n        xarray.DataArray: The extracted data.\n    \"\"\"\n\n    crs = ds.attrs[\"crs\"]\n\n    x, y = convert_coords([[lat, lon]], \"epsg:4326\", crs)[0]\n\n    values = ds.sel(x=x, y=y, method=\"nearest\")[\"reflectance\"].values\n\n    da = xr.DataArray(\n        values, dims=[\"wavelength\"], coords={\"wavelength\": ds.coords[\"wavelength\"]}\n    )\n\n    return da\n</code></pre>"},{"location":"neon/#hypercoast.neon.list_neon_datasets","title":"<code>list_neon_datasets(filepath, print_node=False)</code>","text":"<p>Lists all the datasets in an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The path to the HDF5 file.</p> required <code>print_node</code> <code>bool</code> <p>If True, prints the node object of each dataset. If False, prints the name of each dataset. Defaults to False.</p> <code>False</code> Source code in <code>hypercoast/neon.py</code> <pre><code>def list_neon_datasets(filepath: str, print_node: bool = False) -&gt; None:\n    \"\"\"\n    Lists all the datasets in an HDF5 file.\n\n    Args:\n        filepath (str): The path to the HDF5 file.\n        print_node (bool, optional): If True, prints the node object of each dataset.\n            If False, prints the name of each dataset. Defaults to False.\n    \"\"\"\n\n    f = h5py.File(filepath, \"r\")\n\n    if print_node:\n\n        def list_dataset(_, node):\n            if isinstance(node, h5py.Dataset):\n                print(node)\n\n    else:\n\n        def list_dataset(name, node):\n            if isinstance(node, h5py.Dataset):\n                print(name)\n\n    f.visititems(list_dataset)\n</code></pre>"},{"location":"neon/#hypercoast.neon.neon_to_image","title":"<code>neon_to_image(dataset, wavelengths=None, method='nearest', output=None, **kwargs)</code>","text":"<p>Converts an NEON dataset to an image.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[xr.Dataset, str]</code> <p>The dataset containing the NEON data or the file path to the dataset.</p> required <code>wavelengths</code> <code>np.ndarray</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data interpolation. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>output</code> <code>str</code> <p>The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to <code>leafmap.array_to_image</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[rasterio.Dataset]</code> <p>The image converted from the dataset. If     <code>output</code> is provided, the image will be saved to the specified file     and the function will return None.</p> Source code in <code>hypercoast/neon.py</code> <pre><code>def neon_to_image(\n    dataset: Union[xr.Dataset, str],\n    wavelengths: Optional[np.ndarray] = None,\n    method: str = \"nearest\",\n    output: Optional[str] = None,\n    **kwargs: Any,\n):\n    \"\"\"\n    Converts an NEON dataset to an image.\n\n    Args:\n        dataset (Union[xr.Dataset, str]): The dataset containing the NEON data\n            or the file path to the dataset.\n        wavelengths (np.ndarray, optional): The specific wavelengths to select. If None, all\n            wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data interpolation.\n            Defaults to \"nearest\".\n        output (str, optional): The file path where the image will be saved. If\n            None, the image will be returned as a PIL Image object. Defaults to None.\n        **kwargs (Any): Additional keyword arguments to be passed to\n            `leafmap.array_to_image`.\n\n    Returns:\n        Optional[rasterio.Dataset]: The image converted from the dataset. If\n            `output` is provided, the image will be saved to the specified file\n            and the function will return None.\n    \"\"\"\n    from leafmap import array_to_image\n\n    if isinstance(dataset, str):\n        dataset = read_neon(dataset, method=method)\n\n    if wavelengths is not None:\n        dataset = dataset.sel(wavelength=wavelengths, method=method)\n\n    return array_to_image(\n        dataset[\"reflectance\"],\n        output=output,\n        transpose=False,\n        dtype=np.float32,\n        **kwargs,\n    )\n</code></pre>"},{"location":"neon/#hypercoast.neon.read_neon","title":"<code>read_neon(filepath, wavelengths=None, method='nearest', **kwargs)</code>","text":"<p>Reads NEON AOP hyperspectral hdf5 files and returns an xarray dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The path to the hdf5 file.</p> required <code>wavelengths</code> <code>List[float]</code> <p>The wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for selection. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to the selection method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>xr.Dataset</code> <p>The dataset containing the reflectance data.</p> Source code in <code>hypercoast/neon.py</code> <pre><code>def read_neon(\n    filepath: str,\n    wavelengths: Optional[List[float]] = None,\n    method: str = \"nearest\",\n    **kwargs: Any,\n) -&gt; xr.Dataset:\n    \"\"\"\n    Reads NEON AOP hyperspectral hdf5 files and returns an xarray dataset.\n\n    Args:\n        filepath (str): The path to the hdf5 file.\n        wavelengths (List[float], optional): The wavelengths to select. If None,\n            all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for selection. Defaults to\n            \"nearest\".\n        **kwargs (Any): Additional arguments to pass to the selection method.\n\n    Returns:\n        xr.Dataset: The dataset containing the reflectance data.\n    \"\"\"\n    f = h5py.File(filepath, \"r\")\n\n    serc_refl = f[\"SERC\"][\"Reflectance\"]\n    wavelengths = serc_refl[\"Metadata\"][\"Spectral_Data\"][\"Wavelength\"][()].tolist()\n    wavelengths = [round(num, 2) for num in wavelengths]\n\n    epsg_code = serc_refl[\"Metadata\"][\"Coordinate_System\"][\"EPSG Code\"][()]\n    epsg_code_number = int(epsg_code.decode(\"utf-8\"))\n\n    serc_mapInfo = serc_refl[\"Metadata\"][\"Coordinate_System\"][\"Map_Info\"]\n    mapInfo_string = serc_mapInfo[()].decode(\"utf-8\")  # read in as string\n    mapInfo_split = mapInfo_string.split(\",\")\n\n    res = float(mapInfo_split[5]), float(mapInfo_split[6])\n\n    serc_reflArray = serc_refl[\"Reflectance_Data\"]\n    refl_shape = serc_reflArray.shape\n\n    # Extract the upper left-hand corner coordinates from mapInfo\n    xMin = float(mapInfo_split[3])\n    yMax = float(mapInfo_split[4])\n\n    # Calculate the xMax and yMin values from the dimensions\n    xMax = xMin + (\n        refl_shape[1] * res[0]\n    )  # xMax = left edge + (# of columns * x pixel resolution)\n    yMin = yMax - (\n        refl_shape[0] * res[1]\n    )  # yMin = top edge - (# of rows * y pixel resolution)\n\n    # serc_ext = (xMin, xMax, yMin, yMax)\n\n    # View and apply scale factor and data ignore value\n    scaleFactor = serc_reflArray.attrs[\"Scale_Factor\"]\n    noDataValue = serc_reflArray.attrs[\"Data_Ignore_Value\"]\n\n    da = serc_reflArray[:, :, :].astype(float)\n    da[da == int(noDataValue)] = np.nan\n    da[da &lt; 0] = np.nan\n    da[da &gt; 10000] = np.nan\n    da = da / scaleFactor\n\n    coords = {\n        \"y\": np.linspace(yMax, yMin, da.shape[0]),\n        \"x\": np.linspace(xMin, xMax, da.shape[1]),\n        \"wavelength\": wavelengths,\n    }\n\n    xda = xr.DataArray(\n        da,\n        coords=coords,\n        dims=[\"y\", \"x\", \"wavelength\"],\n        attrs={\n            \"scale_factor\": scaleFactor,\n            \"no_data_value\": noDataValue,\n            \"crs\": f\"EPSG:{epsg_code_number}\",\n            \"transform\": (res[0], 0.0, xMin, 0.0, -res[1], yMax),\n        },\n    )\n\n    if wavelengths is not None:\n        xda = xda.sel(wavelength=wavelengths, method=method, **kwargs)\n\n    dataset = xda.to_dataset(name=\"reflectance\")\n    dataset.attrs = dataset[\"reflectance\"].attrs\n\n    return dataset\n</code></pre>"},{"location":"pace/","title":"pace module","text":"<p>This module contains functions to read and process PACE data.</p>"},{"location":"pace/#hypercoast.pace.extract_pace","title":"<code>extract_pace(dataset, latitude, longitude, delta=0.01, return_plot=False, **kwargs)</code>","text":"<p>Extracts data from a PACE dataset for a given latitude and longitude range     and calculates the mean over these dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[xr.Dataset, str]</code> <p>The PACE dataset or path to the dataset file.</p> required <code>latitude</code> <code>Union[float, Tuple[float, float]]</code> <p>The latitude or range of latitudes to extract data for.</p> required <code>longitude</code> <code>Union[float, Tuple[float, float]]</code> <p>The longitude or range of longitudes to extract data for.</p> required <code>delta</code> <code>float</code> <p>The range to add/subtract to the latitude and longitude if they are not ranges. Defaults to 0.01.</p> <code>0.01</code> <code>return_plot</code> <code>bool</code> <p>Whether to return a plot of the data. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the plot function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[xr.DataArray, plt.figure.Figure]</code> <p>The mean data over the latitude     and longitude dimensions, or a plot of this data if return_plot is True.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def extract_pace(\n    dataset: Union[xr.Dataset, str],\n    latitude: Union[float, Tuple[float, float]],\n    longitude: Union[float, Tuple[float, float]],\n    delta: float = 0.01,\n    return_plot: bool = False,\n    **kwargs,\n) -&gt; Union[xr.DataArray, plt.Figure]:\n    \"\"\"\n    Extracts data from a PACE dataset for a given latitude and longitude range\n        and calculates the mean over these dimensions.\n\n    Args:\n        dataset (Union[xr.Dataset, str]): The PACE dataset or path to the dataset file.\n        latitude (Union[float, Tuple[float, float]]): The latitude or range of\n            latitudes to extract data for.\n        longitude (Union[float, Tuple[float, float]]): The longitude or range of\n            longitudes to extract data for.\n        delta (float, optional): The range to add/subtract to the latitude and\n            longitude if they are not ranges. Defaults to 0.01.\n        return_plot (bool, optional): Whether to return a plot of the data. Defaults to False.\n        **kwargs: Additional keyword arguments to pass to the plot function.\n\n    Returns:\n        Union[xr.DataArray, plt.figure.Figure]: The mean data over the latitude\n            and longitude dimensions, or a plot of this data if return_plot is True.\n    \"\"\"\n    if isinstance(latitude, list) or isinstance(latitude, tuple):\n        pass\n    else:\n        latitude = (latitude - delta, latitude + delta)\n\n    if isinstance(longitude, list) or isinstance(longitude, tuple):\n        pass\n    else:\n        longitude = (longitude - delta, longitude + delta)\n\n    ds = filter_pace(dataset, latitude, longitude, return_plot=False)\n    data = ds.mean(dim=[\"latitude\", \"longitude\"])\n    if return_plot:\n        return data.plot.line(**kwargs)\n    else:\n        return data\n</code></pre>"},{"location":"pace/#hypercoast.pace.filter_pace","title":"<code>filter_pace(dataset, latitude, longitude, drop=True, return_plot=False, **kwargs)</code>","text":"<p>Filters a PACE dataset based on latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xr.Dataset</code> <p>The PACE dataset to filter.</p> required <code>latitude</code> <code>float or tuple</code> <p>The latitude to filter by. If a tuple or list, it represents a range.</p> required <code>longitude</code> <code>float or tuple</code> <p>The longitude to filter by. If a tuple or list, it represents a range.</p> required <code>drop</code> <code>bool</code> <p>Whether to drop the filtered out data. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>xr.DataArray</code> <p>The filtered PACE data.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def filter_pace(dataset, latitude, longitude, drop=True, return_plot=False, **kwargs):\n    \"\"\"\n    Filters a PACE dataset based on latitude and longitude.\n\n    Args:\n        dataset (xr.Dataset): The PACE dataset to filter.\n        latitude (float or tuple): The latitude to filter by. If a tuple or list, it represents a range.\n        longitude (float or tuple): The longitude to filter by. If a tuple or list, it represents a range.\n        drop (bool, optional): Whether to drop the filtered out data. Defaults to True.\n\n    Returns:\n        xr.DataArray: The filtered PACE data.\n    \"\"\"\n    if isinstance(latitude, list) or isinstance(latitude, tuple):\n        lat_con = (dataset[\"latitude\"] &gt; latitude[0]) &amp; (\n            dataset[\"latitude\"] &lt; latitude[1]\n        )\n    else:\n        lat_con = dataset[\"latitude\"] == latitude\n\n    if isinstance(longitude, list) or isinstance(longitude, tuple):\n        lon_con = (dataset[\"longitude\"] &gt; longitude[0]) &amp; (\n            dataset[\"longitude\"] &lt; longitude[1]\n        )\n    else:\n        lon_con = dataset[\"longitude\"] == longitude\n\n    da = dataset[\"Rrs\"].where(lat_con &amp; lon_con, drop=drop, **kwargs)\n    da_filtered = da.dropna(dim=\"latitude\", how=\"all\")\n    da_filtered = da_filtered.dropna(dim=\"longitude\", how=\"all\")\n\n    if return_plot:\n        rrs_stack = da_filtered.stack(\n            {\"pixel\": [\"latitude\", \"longitude\"]},\n            create_index=False,\n        )\n        rrs_stack.plot.line(hue=\"pixel\")\n    else:\n        return da_filtered\n</code></pre>"},{"location":"pace/#hypercoast.pace.grid_pace","title":"<code>grid_pace(dataset, wavelengths=None, method='nearest', **kwargs)</code>","text":"<p>Grids a PACE dataset based on latitude and longitude.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xr.Dataset</code> <p>The PACE dataset to grid.</p> required <code>wavelengths</code> <code>float or int</code> <p>The wavelength to select.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for griddata interpolation. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the xr.Dataset constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>xr.DataArray</code> <p>The gridded PACE data.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def grid_pace(dataset, wavelengths=None, method=\"nearest\", **kwargs):\n    \"\"\"\n    Grids a PACE dataset based on latitude and longitude.\n\n    Args:\n        dataset (xr.Dataset): The PACE dataset to grid.\n        wavelengths (float or int): The wavelength to select.\n        method (str, optional): The method to use for griddata interpolation.\n            Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to pass to the xr.Dataset constructor.\n\n    Returns:\n        xr.DataArray: The gridded PACE data.\n    \"\"\"\n    from scipy.interpolate import griddata\n\n    if wavelengths is None:\n        wavelengths = dataset.coords[\"wavelength\"].values[0]\n\n    # Ensure wavelengths is a list\n    if not isinstance(wavelengths, list):\n        wavelengths = [wavelengths]\n\n    lat = dataset.latitude\n    lon = dataset.longitude\n\n    grid_lat = np.linspace(lat.min(), lat.max(), lat.shape[0])\n    grid_lon = np.linspace(lon.min(), lon.max(), lon.shape[1])\n    grid_lon_2d, grid_lat_2d = np.meshgrid(grid_lon, grid_lat)\n\n    gridded_data_dict = {}\n    for wavelength in wavelengths:\n        data = dataset.sel(wavelength=wavelength, method=method)[\"Rrs\"]\n        gridded_data = griddata(\n            (lat.data.flatten(), lon.data.flatten()),\n            data.data.flatten(),\n            (grid_lat_2d, grid_lon_2d),\n            method=method,\n        )\n        gridded_data_dict[wavelength] = gridded_data\n\n    # Create a 3D array with dimensions latitude, longitude, and wavelength\n    gridded_data_3d = np.dstack(list(gridded_data_dict.values()))\n\n    dataset2 = xr.Dataset(\n        {\"Rrs\": ((\"latitude\", \"longitude\", \"wavelength\"), gridded_data_3d)},\n        coords={\n            \"latitude\": (\"latitude\", grid_lat),\n            \"longitude\": (\"longitude\", grid_lon),\n            \"wavelength\": (\"wavelength\", list(gridded_data_dict.keys())),\n        },\n        **kwargs,\n    )\n\n    dataset2[\"Rrs\"].rio.write_crs(\"EPSG:4326\", inplace=True)\n\n    return dataset2\n</code></pre>"},{"location":"pace/#hypercoast.pace.pace_to_image","title":"<code>pace_to_image(dataset, wavelengths=None, method='nearest', gridded=False, output=None, **kwargs)</code>","text":"<p>Converts an PACE dataset to an image.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xarray.Dataset or str</code> <p>The dataset containing the EMIT data or the file path to the dataset.</p> required <code>wavelengths</code> <code>array-like</code> <p>The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to use for data interpolation. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>gridded</code> <code>bool</code> <p>Whether the dataset is a gridded dataset. Defaults to False,</p> <code>False</code> <code>output</code> <code>str</code> <p>The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to <code>leafmap.array_to_image</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>rasterio.Dataset or None</code> <p>The image converted from the dataset. If <code>output</code> is provided, the image will be saved to the specified file and the function will return None.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def pace_to_image(\n    dataset, wavelengths=None, method=\"nearest\", gridded=False, output=None, **kwargs\n):\n    \"\"\"\n    Converts an PACE dataset to an image.\n\n    Args:\n        dataset (xarray.Dataset or str): The dataset containing the EMIT data or the file path to the dataset.\n        wavelengths (array-like, optional): The specific wavelengths to select. If None, all wavelengths are selected. Defaults to None.\n        method (str, optional): The method to use for data interpolation. Defaults to \"nearest\".\n        gridded (bool, optional): Whether the dataset is a gridded dataset. Defaults to False,\n        output (str, optional): The file path where the image will be saved. If None, the image will be returned as a PIL Image object. Defaults to None.\n        **kwargs: Additional keyword arguments to be passed to `leafmap.array_to_image`.\n\n    Returns:\n        rasterio.Dataset or None: The image converted from the dataset. If `output` is provided, the image will be saved to the specified file and the function will return None.\n    \"\"\"\n    from leafmap import array_to_image\n\n    if isinstance(dataset, str):\n        dataset = read_pace(dataset, wavelengths=wavelengths, method=\"nearest\")\n\n    if wavelengths is not None:\n        dataset = dataset.sel(wavelength=wavelengths, method=\"nearest\")\n\n    if not gridded:\n        grid = grid_pace(dataset, wavelengths=wavelengths, method=method)\n    else:\n        grid = dataset\n    data = grid[\"Rrs\"]\n    data.rio.write_crs(\"EPSG:4326\", inplace=True)\n\n    return array_to_image(data, transpose=False, output=output, **kwargs)\n</code></pre>"},{"location":"pace/#hypercoast.pace.read_pace","title":"<code>read_pace(filepath, wavelengths=None, method='nearest', **kwargs)</code>","text":"<p>Reads PACE data from a given file and returns an xarray Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to the file to read.</p> required <code>wavelengths</code> <code>array-like</code> <p>Specific wavelengths to select. If None, all wavelengths are selected.</p> <code>None</code> <code>method</code> <code>str</code> <p>Method to use for selection when wavelengths is not None. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the <code>sel</code> method when wavelengths is not None.</p> <code>{}</code> <p>Returns:</p> Type Description <code>xr.Dataset</code> <p>An xarray Dataset containing the PACE data.</p> Source code in <code>hypercoast/pace.py</code> <pre><code>def read_pace(filepath, wavelengths=None, method=\"nearest\", **kwargs):\n    \"\"\"\n    Reads PACE data from a given file and returns an xarray Dataset.\n\n    Args:\n        filepath (str): Path to the file to read.\n        wavelengths (array-like, optional): Specific wavelengths to select. If None, all wavelengths are selected.\n        method (str, optional): Method to use for selection when wavelengths is not None. Defaults to \"nearest\".\n        **kwargs: Additional keyword arguments to pass to the `sel` method when wavelengths is not None.\n\n    Returns:\n        xr.Dataset: An xarray Dataset containing the PACE data.\n    \"\"\"\n\n    rrs = xr.open_dataset(filepath, group=\"geophysical_data\")[\"Rrs\"]\n    wvl = xr.open_dataset(filepath, group=\"sensor_band_parameters\")\n    dataset = xr.open_dataset(filepath, group=\"navigation_data\")\n    dataset = dataset.set_coords((\"longitude\", \"latitude\"))\n    dataset = dataset.rename({\"pixel_control_points\": \"pixels_per_line\"})\n    dataset = xr.merge([rrs, dataset.coords.to_dataset()])\n    dataset.coords[\"wavelength_3d\"] = wvl.coords[\"wavelength_3d\"]\n    dataset = dataset.rename(\n        {\n            \"number_of_lines\": \"latitude\",\n            \"pixels_per_line\": \"longitude\",\n            \"wavelength_3d\": \"wavelength\",\n        }\n    )\n\n    if wavelengths is not None:\n        dataset = dataset.sel(wavelength=wavelengths, method=method, **kwargs)\n\n    return dataset\n</code></pre>"},{"location":"pace/#hypercoast.pace.viz_pace","title":"<code>viz_pace(dataset, wavelengths=None, method='nearest', figsize=(6.4, 4.8), cmap='jet', vmin=0, vmax=0.02, ncols=1, crs=None, xlim=None, ylim=None, **kwargs)</code>","text":"<p>Plots PACE data from a given xarray Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>xr.Dataset</code> <p>An xarray Dataset containing the PACE data.</p> required <code>wavelengths</code> <code>array-like</code> <p>Specific wavelengths to select. If None, all wavelengths are selected.</p> <code>None</code> <code>method</code> <code>str</code> <p>Method to use for selection when wavelengths is not None. Defaults to \"nearest\".</p> <code>'nearest'</code> <code>figsize</code> <code>tuple</code> <p>Figure size. Defaults to (6.4, 4.8).</p> <code>(6.4, 4.8)</code> <code>cmap</code> <code>str</code> <p>Colormap to use. Defaults to \"jet\".</p> <code>'jet'</code> <code>vmin</code> <code>float</code> <p>Minimum value for the colormap. Defaults to 0.</p> <code>0</code> <code>vmax</code> <code>float</code> <p>Maximum value for the colormap. Defaults to 0.02.</p> <code>0.02</code> <code>ncols</code> <code>int</code> <p>Number of columns in the plot. Defaults to 1.</p> <code>1</code> <code>crs</code> <code>str or cartopy.crs.CRS</code> <p>Coordinate reference system to use. If None, a simple plot is created. Defaults to None. See https://scitools.org.uk/cartopy/docs/latest/reference/projections.html</p> <code>None</code> <code>xlim</code> <code>array-like</code> <p>Limits for the x-axis. Defaults to None.</p> <code>None</code> <code>ylim</code> <code>array-like</code> <p>Limits for the y-axis. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the <code>plt.subplots</code> function.</p> <code>{}</code> Source code in <code>hypercoast/pace.py</code> <pre><code>def viz_pace(\n    dataset: Union[xr.Dataset, str],\n    wavelengths: Optional[Union[List[float], float]] = None,\n    method: str = \"nearest\",\n    figsize: Tuple[float, float] = (6.4, 4.8),\n    cmap: str = \"jet\",\n    vmin: float = 0,\n    vmax: float = 0.02,\n    ncols: int = 1,\n    crs: Optional[str] = None,\n    xlim: Optional[List[float]] = None,\n    ylim: Optional[List[float]] = None,\n    **kwargs,\n):\n    \"\"\"\n    Plots PACE data from a given xarray Dataset.\n\n    Args:\n        dataset (xr.Dataset): An xarray Dataset containing the PACE data.\n        wavelengths (array-like, optional): Specific wavelengths to select. If None, all wavelengths are selected.\n        method (str, optional): Method to use for selection when wavelengths is not None. Defaults to \"nearest\".\n        figsize (tuple, optional): Figure size. Defaults to (6.4, 4.8).\n        cmap (str, optional): Colormap to use. Defaults to \"jet\".\n        vmin (float, optional): Minimum value for the colormap. Defaults to 0.\n        vmax (float, optional): Maximum value for the colormap. Defaults to 0.02.\n        ncols (int, optional): Number of columns in the plot. Defaults to 1.\n        crs (str or cartopy.crs.CRS, optional): Coordinate reference system to use. If None, a simple plot is created. Defaults to None.\n            See https://scitools.org.uk/cartopy/docs/latest/reference/projections.html\n        xlim (array-like, optional): Limits for the x-axis. Defaults to None.\n        ylim (array-like, optional): Limits for the y-axis. Defaults to None.\n        **kwargs: Additional keyword arguments to pass to the `plt.subplots` function.\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import math\n\n    if isinstance(dataset, str):\n        dataset = read_pace(dataset, wavelengths, method)\n\n    if wavelengths is not None:\n        if not isinstance(wavelengths, list):\n            wavelengths = [wavelengths]\n        dataset = dataset.sel(wavelength=wavelengths, method=method)\n    else:\n        wavelengths = dataset.coords[\"wavelength\"][0].values.tolist()\n\n    lat = dataset.coords[\"latitude\"]\n    lon = dataset.coords[\"longitude\"]\n\n    nrows = math.ceil(len(wavelengths) / ncols)\n\n    if crs is None:\n\n        fig, axes = plt.subplots(\n            nrows=nrows,\n            ncols=ncols,\n            figsize=(figsize[0] * ncols, figsize[1] * nrows),\n            **kwargs,\n        )\n\n        for i in range(nrows):\n            for j in range(ncols):\n                index = i * ncols + j\n                if index &lt; len(wavelengths):\n                    wavelength = wavelengths[index]\n                    data = dataset.sel(wavelength=wavelength, method=method)[\"Rrs\"]\n\n                    if min(nrows, ncols) == 1:\n                        ax = axes[index]\n                    else:\n                        ax = axes[i, j]\n                    im = ax.pcolormesh(\n                        lon, lat, np.squeeze(data), cmap=cmap, vmin=vmin, vmax=vmax\n                    )\n                    ax.set_xlabel(\"Longitude\")\n                    ax.set_ylabel(\"Latitude\")\n                    ax.set_title(\n                        f\"wavelength = {dataset.coords['wavelength'].values[index]} [nm]\"\n                    )\n                    fig.colorbar(im, ax=ax, label=\"Reflectance\")\n\n        plt.tight_layout()\n        plt.show()\n\n    else:\n\n        import cartopy\n        from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n\n        if crs == \"default\":\n            crs = cartopy.crs.PlateCarree()\n\n        if xlim is None:\n            xlim = [math.floor(lon.min()), math.ceil(lon.max())]\n\n        if ylim is None:\n            ylim = [math.floor(lat.min()), math.ceil(lat.max())]\n\n        fig, axes = plt.subplots(\n            nrows=nrows,\n            ncols=ncols,\n            figsize=(figsize[0] * ncols, figsize[1] * nrows),\n            subplot_kw={\"projection\": cartopy.crs.PlateCarree()},\n            **kwargs,\n        )\n\n        for i in range(nrows):\n            for j in range(ncols):\n                index = i * ncols + j\n                if index &lt; len(wavelengths):\n                    wavelength = wavelengths[index]\n                    data = dataset.sel(wavelength=wavelength, method=method)[\"Rrs\"]\n\n                    if min(nrows, ncols) == 1:\n                        ax = axes[index]\n                    else:\n                        ax = axes[i, j]\n                    im = ax.pcolormesh(lon, lat, data, cmap=\"jet\", vmin=0, vmax=0.02)\n                    ax.coastlines()\n                    ax.add_feature(cartopy.feature.STATES, linewidth=0.5)\n                    ax.set_xticks(np.linspace(xlim[0], xlim[1], 5), crs=crs)\n                    ax.set_yticks(np.linspace(ylim[0], ylim[1], 5), crs=crs)\n                    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n                    lat_formatter = LatitudeFormatter()\n                    ax.xaxis.set_major_formatter(lon_formatter)\n                    ax.yaxis.set_major_formatter(lat_formatter)\n                    ax.set_xlabel(\"Longitude\")\n                    ax.set_ylabel(\"Latitude\")\n                    ax.set_title(\n                        f\"wavelength = {dataset.coords['wavelength'].values[index]} [nm]\"\n                    )\n                    plt.colorbar(im, label=\"Reflectance\")\n\n        plt.tight_layout()\n        plt.show()\n</code></pre>"},{"location":"ui/","title":"ui module","text":"<p>This module contains the user interface for the hypercoast package.</p>"},{"location":"ui/#hypercoast.ui.SpectralWidget","title":"<code> SpectralWidget            (HBox)         </code>","text":"<p>A widget for spectral data visualization on a map.</p> <p>Attributes:</p> Name Type Description <code>_host_map</code> <code>Map</code> <p>The map to host the widget.</p> <code>on_close</code> <code>function</code> <p>Function to be called when the widget is closed.</p> <code>_output_widget</code> <code>widgets.Output</code> <p>The output widget to display results.</p> <code>_output_control</code> <code>ipyleaflet.WidgetControl</code> <p>The control for the output widget.</p> <code>_on_map_interaction</code> <code>function</code> <p>Function to handle map interactions.</p> <code>_spectral_widget</code> <code>SpectralWidget</code> <p>The spectral widget itself.</p> <code>_spectral_control</code> <code>ipyleaflet.WidgetControl</code> <p>The control for the spectral widget.</p> Source code in <code>hypercoast/ui.py</code> <pre><code>class SpectralWidget(widgets.HBox):\n    \"\"\"\n    A widget for spectral data visualization on a map.\n\n    Attributes:\n        _host_map (Map): The map to host the widget.\n        on_close (function): Function to be called when the widget is closed.\n        _output_widget (widgets.Output): The output widget to display results.\n        _output_control (ipyleaflet.WidgetControl): The control for the output widget.\n        _on_map_interaction (function): Function to handle map interactions.\n        _spectral_widget (SpectralWidget): The spectral widget itself.\n        _spectral_control (ipyleaflet.WidgetControl): The control for the spectral widget.\n    \"\"\"\n\n    def __init__(self, host_map, stack=True, position=\"topright\"):\n        \"\"\"\n        Initializes a new instance of the SpectralWidget class.\n\n        Args:\n            host_map (Map): The map to host the widget.\n            position (str, optional): The position of the widget on the map. Defaults to \"topright\".\n        \"\"\"\n        self._host_map = host_map\n        self.on_close = None\n        self._stack = stack\n        self._show_plot = False\n\n        fig_margin = {\"top\": 20, \"bottom\": 35, \"left\": 50, \"right\": 20}\n        fig = plt.figure(\n            # title=None,\n            fig_margin=fig_margin,\n            layout={\"width\": \"500px\", \"height\": \"300px\"},\n        )\n\n        self._fig = fig\n        self._host_map._fig = fig\n\n        close_btn = widgets.Button(\n            icon=\"times\",\n            tooltip=\"Close the widget\",\n            button_style=\"primary\",\n            layout=widgets.Layout(width=\"32px\"),\n        )\n\n        reset_btn = widgets.Button(\n            icon=\"trash\",\n            tooltip=\"Remove all markers\",\n            button_style=\"primary\",\n            layout=widgets.Layout(width=\"32px\"),\n        )\n\n        stack_btn = widgets.ToggleButton(\n            value=stack,\n            icon=\"area-chart\",\n            button_style=\"primary\",\n            layout=widgets.Layout(width=\"32px\"),\n        )\n\n        def reset_btn_click(_):\n            if hasattr(self._host_map, \"_plot_marker_cluster\"):\n                self._host_map._plot_marker_cluster.markers = []\n                self._host_map._plot_markers = []\n\n            if hasattr(self._host_map, \"_spectral_data\"):\n                self._host_map._spectral_data = {}\n\n            self._output_widget.clear_output()\n            self._show_plot = False\n            plt.clear()\n\n        reset_btn.on_click(reset_btn_click)\n\n        save_btn = widgets.Button(\n            icon=\"floppy-o\",\n            tooltip=\"Save the data to a CSV\",\n            button_style=\"primary\",\n            layout=widgets.Layout(width=\"32px\"),\n        )\n\n        def chooser_callback(chooser):\n            if chooser.selected:\n                file_path = chooser.selected\n                self._host_map.spectral_to_csv(file_path)\n                if (\n                    hasattr(self._host_map, \"_file_chooser_control\")\n                    and self._host_map._file_chooser_control in self._host_map.controls\n                ):\n                    self._host_map.remove_control(self._host_map._file_chooser_control)\n                    self._host_map._file_chooser.close()\n\n        def save_btn_click(_):\n            if not hasattr(self._host_map, \"_spectral_data\"):\n                return\n\n            self._output_widget.clear_output()\n            file_chooser = FileChooser(\n                os.getcwd(), layout=widgets.Layout(width=\"454px\")\n            )\n            file_chooser.filter_pattern = \"*.csv\"\n            file_chooser.use_dir_icons = True\n            file_chooser.title = \"Save spectral data to a CSV file\"\n            file_chooser.default_filename = \"spectral_data.csv\"\n            file_chooser.show_hidden = False\n            file_chooser.register_callback(chooser_callback)\n            file_chooser_control = ipyleaflet.WidgetControl(\n                widget=file_chooser, position=\"topright\"\n            )\n            self._host_map.add(file_chooser_control)\n            setattr(self._host_map, \"_file_chooser\", file_chooser)\n            setattr(self._host_map, \"_file_chooser_control\", file_chooser_control)\n\n        save_btn.on_click(save_btn_click)\n\n        def close_widget(_):\n            self.cleanup()\n\n        close_btn.on_click(close_widget)\n\n        layer_names = list(host_map.cog_layer_dict.keys())\n        layers_widget = widgets.Dropdown(options=layer_names)\n        layers_widget.layout.width = \"18ex\"\n        super().__init__([layers_widget, stack_btn, reset_btn, save_btn, close_btn])\n\n        output = widgets.Output()\n        output_control = ipyleaflet.WidgetControl(widget=output, position=\"bottomright\")\n        self._output_widget = output\n        self._output_control = output_control\n        self._host_map.add(output_control)\n\n        if not hasattr(self._host_map, \"_spectral_data\"):\n            self._host_map._spectral_data = {}\n\n        def handle_interaction(**kwargs):\n\n            latlon = kwargs.get(\"coordinates\")\n            lat = latlon[0]\n            lon = latlon[1]\n            if kwargs.get(\"type\") == \"click\":\n                layer_name = layers_widget.value\n\n                if not hasattr(self._host_map, \"_plot_markers\"):\n                    self._host_map._plot_markers = []\n                markers = self._host_map._plot_markers\n                marker_cluster = self._host_map._plot_marker_cluster\n                markers.append(ipyleaflet.Marker(location=latlon, draggable=False))\n                marker_cluster.markers = markers\n                self._host_map._plot_marker_cluster = marker_cluster\n\n                ds = self._host_map.cog_layer_dict[layer_name][\"xds\"]\n                if self._host_map.cog_layer_dict[layer_name][\"hyper\"] == \"EMIT\":\n                    da = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")[\n                        \"reflectance\"\n                    ]\n\n                    if \"wavelengths\" not in self._host_map._spectral_data:\n                        self._host_map._spectral_data[\"wavelengths\"] = ds[\n                            \"wavelengths\"\n                        ].values\n                elif self._host_map.cog_layer_dict[layer_name][\"hyper\"] == \"PACE\":\n                    try:\n                        da = extract_pace(ds, lat, lon)\n                    except:\n                        da = xr.DataArray(\n                            np.full(len(ds[\"wavelength\"]), np.nan),\n                            dims=[\"wavelength\"],\n                            coords={\"wavelength\": ds[\"wavelength\"]},\n                        )\n                    if \"wavelengths\" not in self._host_map._spectral_data:\n                        self._host_map._spectral_data[\"wavelengths\"] = ds[\n                            \"wavelength\"\n                        ].values\n\n                elif self._host_map.cog_layer_dict[layer_name][\"hyper\"] == \"DESIS\":\n                    da = extract_desis(ds, lat, lon)\n\n                elif self._host_map.cog_layer_dict[layer_name][\"hyper\"] == \"NEON\":\n                    da = extract_neon(ds, lat, lon)\n\n                self._host_map._spectral_data[f\"({lat:.4f} {lon:.4f})\"] = da.values\n\n                da[da &lt; 0] = np.nan\n                axes_options = {\n                    \"x\": {\"label_offset\": \"30px\"},\n                    \"y\": {\"label_offset\": \"35px\"},\n                }\n\n                if not stack_btn.value:\n                    plt.clear()\n                    plt.plot(\n                        da.coords[da.dims[0]].values,\n                        da.values,\n                        axes_options=axes_options,\n                    )\n                else:\n                    color = np.random.rand(\n                        3,\n                    )\n                    plt.plot(\n                        da.coords[da.dims[0]].values,\n                        da.values,\n                        color=color,\n                        axes_options=axes_options,\n                    )\n                    try:\n                        if isinstance(self._fig.axes[0], bqplot.ColorAxis):\n                            self._fig.axes = self._fig.axes[1:]\n                        elif isinstance(self._fig.axes[-1], bqplot.ColorAxis):\n                            self._fig.axes = self._fig.axes[:-1]\n                    except:\n                        pass\n                plt.xlabel(\"Wavelength (nm)\")\n                plt.ylabel(\"Reflectance\")\n\n                if not self._show_plot:\n                    with self._output_widget:\n                        plt.show()\n                        self._show_plot = True\n\n                self._host_map.default_style = {\"cursor\": \"crosshair\"}\n\n        self._host_map.on_interaction(handle_interaction)\n        self._on_map_interaction = handle_interaction\n\n        self._spectral_widget = self\n        self._spectral_control = ipyleaflet.WidgetControl(\n            widget=self, position=position\n        )\n        self._host_map.add(self._spectral_control)\n\n    def cleanup(self):\n        \"\"\"Removes the widget from the map and performs cleanup.\"\"\"\n        if self._host_map:\n            self._host_map.default_style = {\"cursor\": \"default\"}\n            self._host_map.on_interaction(self._on_map_interaction, remove=True)\n\n            if self._output_control:\n                self._host_map.remove_control(self._output_control)\n\n                if self._output_widget:\n                    self._output_widget.close()\n                    self._output_widget = None\n\n            if self._spectral_control:\n                self._host_map.remove_control(self._spectral_control)\n                self._spectral_control = None\n\n                if self._spectral_widget:\n                    self._spectral_widget.close()\n                    self._spectral_widget = None\n\n            if hasattr(self._host_map, \"_plot_marker_cluster\"):\n                self._host_map._plot_marker_cluster.markers = []\n                self._host_map._plot_markers = []\n\n            if hasattr(self._host_map, \"_spectral_data\"):\n                self._host_map._spectral_data = {}\n\n            if hasattr(self, \"_output_widget\") and self._output_widget is not None:\n                self._output_widget.clear_output()\n\n        if self.on_close is not None:\n            self.on_close()\n</code></pre>"},{"location":"ui/#hypercoast.ui.SpectralWidget.__init__","title":"<code>__init__(self, host_map, stack=True, position='topright')</code>  <code>special</code>","text":"<p>Initializes a new instance of the SpectralWidget class.</p> <p>Parameters:</p> Name Type Description Default <code>host_map</code> <code>Map</code> <p>The map to host the widget.</p> required <code>position</code> <code>str</code> <p>The position of the widget on the map. Defaults to \"topright\".</p> <code>'topright'</code> Source code in <code>hypercoast/ui.py</code> <pre><code>def __init__(self, host_map, stack=True, position=\"topright\"):\n    \"\"\"\n    Initializes a new instance of the SpectralWidget class.\n\n    Args:\n        host_map (Map): The map to host the widget.\n        position (str, optional): The position of the widget on the map. Defaults to \"topright\".\n    \"\"\"\n    self._host_map = host_map\n    self.on_close = None\n    self._stack = stack\n    self._show_plot = False\n\n    fig_margin = {\"top\": 20, \"bottom\": 35, \"left\": 50, \"right\": 20}\n    fig = plt.figure(\n        # title=None,\n        fig_margin=fig_margin,\n        layout={\"width\": \"500px\", \"height\": \"300px\"},\n    )\n\n    self._fig = fig\n    self._host_map._fig = fig\n\n    close_btn = widgets.Button(\n        icon=\"times\",\n        tooltip=\"Close the widget\",\n        button_style=\"primary\",\n        layout=widgets.Layout(width=\"32px\"),\n    )\n\n    reset_btn = widgets.Button(\n        icon=\"trash\",\n        tooltip=\"Remove all markers\",\n        button_style=\"primary\",\n        layout=widgets.Layout(width=\"32px\"),\n    )\n\n    stack_btn = widgets.ToggleButton(\n        value=stack,\n        icon=\"area-chart\",\n        button_style=\"primary\",\n        layout=widgets.Layout(width=\"32px\"),\n    )\n\n    def reset_btn_click(_):\n        if hasattr(self._host_map, \"_plot_marker_cluster\"):\n            self._host_map._plot_marker_cluster.markers = []\n            self._host_map._plot_markers = []\n\n        if hasattr(self._host_map, \"_spectral_data\"):\n            self._host_map._spectral_data = {}\n\n        self._output_widget.clear_output()\n        self._show_plot = False\n        plt.clear()\n\n    reset_btn.on_click(reset_btn_click)\n\n    save_btn = widgets.Button(\n        icon=\"floppy-o\",\n        tooltip=\"Save the data to a CSV\",\n        button_style=\"primary\",\n        layout=widgets.Layout(width=\"32px\"),\n    )\n\n    def chooser_callback(chooser):\n        if chooser.selected:\n            file_path = chooser.selected\n            self._host_map.spectral_to_csv(file_path)\n            if (\n                hasattr(self._host_map, \"_file_chooser_control\")\n                and self._host_map._file_chooser_control in self._host_map.controls\n            ):\n                self._host_map.remove_control(self._host_map._file_chooser_control)\n                self._host_map._file_chooser.close()\n\n    def save_btn_click(_):\n        if not hasattr(self._host_map, \"_spectral_data\"):\n            return\n\n        self._output_widget.clear_output()\n        file_chooser = FileChooser(\n            os.getcwd(), layout=widgets.Layout(width=\"454px\")\n        )\n        file_chooser.filter_pattern = \"*.csv\"\n        file_chooser.use_dir_icons = True\n        file_chooser.title = \"Save spectral data to a CSV file\"\n        file_chooser.default_filename = \"spectral_data.csv\"\n        file_chooser.show_hidden = False\n        file_chooser.register_callback(chooser_callback)\n        file_chooser_control = ipyleaflet.WidgetControl(\n            widget=file_chooser, position=\"topright\"\n        )\n        self._host_map.add(file_chooser_control)\n        setattr(self._host_map, \"_file_chooser\", file_chooser)\n        setattr(self._host_map, \"_file_chooser_control\", file_chooser_control)\n\n    save_btn.on_click(save_btn_click)\n\n    def close_widget(_):\n        self.cleanup()\n\n    close_btn.on_click(close_widget)\n\n    layer_names = list(host_map.cog_layer_dict.keys())\n    layers_widget = widgets.Dropdown(options=layer_names)\n    layers_widget.layout.width = \"18ex\"\n    super().__init__([layers_widget, stack_btn, reset_btn, save_btn, close_btn])\n\n    output = widgets.Output()\n    output_control = ipyleaflet.WidgetControl(widget=output, position=\"bottomright\")\n    self._output_widget = output\n    self._output_control = output_control\n    self._host_map.add(output_control)\n\n    if not hasattr(self._host_map, \"_spectral_data\"):\n        self._host_map._spectral_data = {}\n\n    def handle_interaction(**kwargs):\n\n        latlon = kwargs.get(\"coordinates\")\n        lat = latlon[0]\n        lon = latlon[1]\n        if kwargs.get(\"type\") == \"click\":\n            layer_name = layers_widget.value\n\n            if not hasattr(self._host_map, \"_plot_markers\"):\n                self._host_map._plot_markers = []\n            markers = self._host_map._plot_markers\n            marker_cluster = self._host_map._plot_marker_cluster\n            markers.append(ipyleaflet.Marker(location=latlon, draggable=False))\n            marker_cluster.markers = markers\n            self._host_map._plot_marker_cluster = marker_cluster\n\n            ds = self._host_map.cog_layer_dict[layer_name][\"xds\"]\n            if self._host_map.cog_layer_dict[layer_name][\"hyper\"] == \"EMIT\":\n                da = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")[\n                    \"reflectance\"\n                ]\n\n                if \"wavelengths\" not in self._host_map._spectral_data:\n                    self._host_map._spectral_data[\"wavelengths\"] = ds[\n                        \"wavelengths\"\n                    ].values\n            elif self._host_map.cog_layer_dict[layer_name][\"hyper\"] == \"PACE\":\n                try:\n                    da = extract_pace(ds, lat, lon)\n                except:\n                    da = xr.DataArray(\n                        np.full(len(ds[\"wavelength\"]), np.nan),\n                        dims=[\"wavelength\"],\n                        coords={\"wavelength\": ds[\"wavelength\"]},\n                    )\n                if \"wavelengths\" not in self._host_map._spectral_data:\n                    self._host_map._spectral_data[\"wavelengths\"] = ds[\n                        \"wavelength\"\n                    ].values\n\n            elif self._host_map.cog_layer_dict[layer_name][\"hyper\"] == \"DESIS\":\n                da = extract_desis(ds, lat, lon)\n\n            elif self._host_map.cog_layer_dict[layer_name][\"hyper\"] == \"NEON\":\n                da = extract_neon(ds, lat, lon)\n\n            self._host_map._spectral_data[f\"({lat:.4f} {lon:.4f})\"] = da.values\n\n            da[da &lt; 0] = np.nan\n            axes_options = {\n                \"x\": {\"label_offset\": \"30px\"},\n                \"y\": {\"label_offset\": \"35px\"},\n            }\n\n            if not stack_btn.value:\n                plt.clear()\n                plt.plot(\n                    da.coords[da.dims[0]].values,\n                    da.values,\n                    axes_options=axes_options,\n                )\n            else:\n                color = np.random.rand(\n                    3,\n                )\n                plt.plot(\n                    da.coords[da.dims[0]].values,\n                    da.values,\n                    color=color,\n                    axes_options=axes_options,\n                )\n                try:\n                    if isinstance(self._fig.axes[0], bqplot.ColorAxis):\n                        self._fig.axes = self._fig.axes[1:]\n                    elif isinstance(self._fig.axes[-1], bqplot.ColorAxis):\n                        self._fig.axes = self._fig.axes[:-1]\n                except:\n                    pass\n            plt.xlabel(\"Wavelength (nm)\")\n            plt.ylabel(\"Reflectance\")\n\n            if not self._show_plot:\n                with self._output_widget:\n                    plt.show()\n                    self._show_plot = True\n\n            self._host_map.default_style = {\"cursor\": \"crosshair\"}\n\n    self._host_map.on_interaction(handle_interaction)\n    self._on_map_interaction = handle_interaction\n\n    self._spectral_widget = self\n    self._spectral_control = ipyleaflet.WidgetControl(\n        widget=self, position=position\n    )\n    self._host_map.add(self._spectral_control)\n</code></pre>"},{"location":"ui/#hypercoast.ui.SpectralWidget.cleanup","title":"<code>cleanup(self)</code>","text":"<p>Removes the widget from the map and performs cleanup.</p> Source code in <code>hypercoast/ui.py</code> <pre><code>def cleanup(self):\n    \"\"\"Removes the widget from the map and performs cleanup.\"\"\"\n    if self._host_map:\n        self._host_map.default_style = {\"cursor\": \"default\"}\n        self._host_map.on_interaction(self._on_map_interaction, remove=True)\n\n        if self._output_control:\n            self._host_map.remove_control(self._output_control)\n\n            if self._output_widget:\n                self._output_widget.close()\n                self._output_widget = None\n\n        if self._spectral_control:\n            self._host_map.remove_control(self._spectral_control)\n            self._spectral_control = None\n\n            if self._spectral_widget:\n                self._spectral_widget.close()\n                self._spectral_widget = None\n\n        if hasattr(self._host_map, \"_plot_marker_cluster\"):\n            self._host_map._plot_marker_cluster.markers = []\n            self._host_map._plot_markers = []\n\n        if hasattr(self._host_map, \"_spectral_data\"):\n            self._host_map._spectral_data = {}\n\n        if hasattr(self, \"_output_widget\") and self._output_widget is not None:\n            self._output_widget.clear_output()\n\n    if self.on_close is not None:\n        self.on_close()\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use HyperCoast in a project:</p> <pre><code>import hypercoast\n</code></pre>"},{"location":"examples/desis/","title":"Desis","text":"In\u00a0[1]: Copied! <pre># %pip install \"hypercoast[extra]\"\n</pre> # %pip install \"hypercoast[extra]\" In\u00a0[2]: Copied! <pre>import hypercoast\n</pre> import hypercoast In\u00a0[3]: Copied! <pre>url = \"https://github.com/opengeos/datasets/releases/download/hypercoast/desis.tif\"\nfilepath = \"data/desis.tif\"\nhypercoast.download_file(url, filepath)\n</pre> url = \"https://github.com/opengeos/datasets/releases/download/hypercoast/desis.tif\" filepath = \"data/desis.tif\" hypercoast.download_file(url, filepath) <pre>Downloading...\nFrom: https://github.com/opengeos/datasets/releases/download/hypercoast/desis.tif\nTo: /home/runner/work/HyperCoast/HyperCoast/docs/examples/data/desis.tif\n</pre> <pre>\r  0%|          | 0.00/35.8M [00:00&lt;?, ?B/s]</pre> <pre>\r 15%|\u2588\u258d        | 5.24M/35.8M [00:00&lt;00:00, 41.4MB/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 11.0M/35.8M [00:00&lt;00:00, 42.2MB/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2589     | 17.8M/35.8M [00:00&lt;00:00, 50.9MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 23.1M/35.8M [00:00&lt;00:00, 46.1MB/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 28.8M/35.8M [00:00&lt;00:00, 48.7MB/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 34.1M/35.8M [00:00&lt;00:00, 36.7MB/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35.8M/35.8M [00:00&lt;00:00, 42.0MB/s]</pre> <pre>\n</pre> Out[3]: <pre>'/home/runner/work/HyperCoast/HyperCoast/docs/examples/data/desis.tif'</pre> <p>Load the dataset as a xarray.Dataset object.</p> In\u00a0[4]: Copied! <pre>dataset = hypercoast.read_desis(filepath)\n</pre> dataset = hypercoast.read_desis(filepath) <p>Plot the spectral signature of a pixel.</p> In\u00a0[5]: Copied! <pre>hypercoast.filter_desis(dataset, lat=29.4315, lon=91.2927, return_plot=True)\n</pre> hypercoast.filter_desis(dataset, lat=29.4315, lon=91.2927, return_plot=True) <p>Visualize a single band of the hyperspectral image.</p> In\u00a0[6]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"Hybrid\")\nm.add_desis(filepath, bands=[200], vmin=0, vmax=5000, nodata=0, colormap=\"jet\")\nm.add_colormap(cmap=\"jet\", vmin=0, vmax=0.5, label=\"Reflectance\")\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"Hybrid\") m.add_desis(filepath, bands=[200], vmin=0, vmax=5000, nodata=0, colormap=\"jet\") m.add_colormap(cmap=\"jet\", vmin=0, vmax=0.5, label=\"Reflectance\") m Out[6]: <p></p> <p>Plot the spectral signature of a pixel interactively.</p> In\u00a0[7]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"Hybrid\")\nm.add_desis(filepath, bands=[50, 100, 200], vmin=0, vmax=1000, nodata=0)\nm.add(\"spectral\")\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"Hybrid\") m.add_desis(filepath, bands=[50, 100, 200], vmin=0, vmax=1000, nodata=0) m.add(\"spectral\") m Out[7]: <p></p>"},{"location":"examples/desis/#visualizing-desis-data-interactively-with-hypercoast","title":"Visualizing DESIS data interactively with HyperCoast\u00b6","text":"<p>This notebook demonstrates how to visualize DESIS hyperspectral data interactively with HyperCoast.</p>"},{"location":"examples/ecostress/","title":"Ecostress","text":"In\u00a0[\u00a0]: Copied! <pre>import hypercoast\n</pre> import hypercoast In\u00a0[\u00a0]: Copied! <pre>hypercoast.nasa_earth_login()\n</pre> hypercoast.nasa_earth_login() In\u00a0[\u00a0]: Copied! <pre>results, gdf = hypercoast.search_ecostress(\n    bbox=(-120.522, 34.4266, -120.2665, 34.5653),\n    temporal=(\"2023-04-01\", \"2023-04-02\"),\n    count=-1,  # use -1 to return all datasets\n    return_gdf=True,\n)\n</pre> results, gdf = hypercoast.search_ecostress(     bbox=(-120.522, 34.4266, -120.2665, 34.5653),     temporal=(\"2023-04-01\", \"2023-04-02\"),     count=-1,  # use -1 to return all datasets     return_gdf=True, ) In\u00a0[\u00a0]: Copied! <pre>gdf.explore()\n</pre> gdf.explore() In\u00a0[\u00a0]: Copied! <pre>hypercoast.download_ecostress(results[:5], out_dir=\"data\")\n</pre> hypercoast.download_ecostress(results[:5], out_dir=\"data\") In\u00a0[\u00a0]: Copied! <pre>m = hypercoast.Map(center=[34.5014, -120.4032], zoom=11)\nm.search_ecostress()\nm\n</pre> m = hypercoast.Map(center=[34.5014, -120.4032], zoom=11) m.search_ecostress() m In\u00a0[\u00a0]: Copied! <pre># m._NASA_DATA_GDF.head()\n</pre> # m._NASA_DATA_GDF.head() In\u00a0[\u00a0]: Copied! <pre># hypercoast.download_ecostress(m._NASA_DATA_RESULTS[:2], out_dir=\"data\")\n</pre> # hypercoast.download_ecostress(m._NASA_DATA_RESULTS[:2], out_dir=\"data\") In\u00a0[\u00a0]: Copied! <pre>url = \"https://github.com/opengeos/datasets/releases/download/raster/ECOv002_L2T_LSTE_26860_001_10SGD_20230401T203733_0710_01_LST.tif\"\n</pre> url = \"https://github.com/opengeos/datasets/releases/download/raster/ECOv002_L2T_LSTE_26860_001_10SGD_20230401T203733_0710_01_LST.tif\" In\u00a0[\u00a0]: Copied! <pre>filepath = \"data/ECOv002_L2T_LSTE_26860_001_10SGD_20230401T203733_0710_01_LST.tif\"\nhypercoast.download_file(url, filepath)\n</pre> filepath = \"data/ECOv002_L2T_LSTE_26860_001_10SGD_20230401T203733_0710_01_LST.tif\" hypercoast.download_file(url, filepath) <p>Viusalize the data with HyperCoast.</p> In\u00a0[\u00a0]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"HYBRID\")\nm.add_raster(filepath, colormap=\"jet\", layer_name=\"LST\")\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"HYBRID\") m.add_raster(filepath, colormap=\"jet\", layer_name=\"LST\") m <p></p>"},{"location":"examples/ecostress/#search-and-download-nasa-ecostress-data-with-hypercoast","title":"Search and download NASA ECOSTRESS data with HyperCoast\u00b6","text":"<p>This notebook demonstrates how to search and visualize NASA ECOSTRESS temperature data with HyperCoast.</p>"},{"location":"examples/ecostress/#search-for-ecostress-data-programmatically","title":"Search for ECOSTRESS data programmatically\u00b6","text":""},{"location":"examples/ecostress/#download-ecostress-data","title":"Download ECOSTRESS data\u00b6","text":""},{"location":"examples/ecostress/#search-for-ecostress-data-interactively","title":"Search for ECOSTRESS data interactively\u00b6","text":""},{"location":"examples/ecostress/#visualize-ecostress-data","title":"Visualize ECOSTRESS data\u00b6","text":"<p>Download a sample ECOSTRESS data file and visualize it with HyperCoast.</p>"},{"location":"examples/emit/","title":"Emit","text":"In\u00a0[1]: Copied! <pre># %pip install hypercoast\n</pre> # %pip install hypercoast In\u00a0[2]: Copied! <pre>import hypercoast\n</pre> import hypercoast <p>Download a sample EMIT data file from here.</p> In\u00a0[3]: Copied! <pre>url = \"https://github.com/opengeos/datasets/releases/download/netcdf/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\"\n</pre> url = \"https://github.com/opengeos/datasets/releases/download/netcdf/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\" In\u00a0[4]: Copied! <pre>filepath = \"EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\"\nhypercoast.download_file(url)\n</pre> filepath = \"EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\" hypercoast.download_file(url) <pre>Downloading...\nFrom: https://github.com/opengeos/datasets/releases/download/netcdf/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\nTo: /home/runner/work/HyperCoast/HyperCoast/docs/examples/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc\n</pre> <pre>\r  0%|          | 0.00/1.85G [00:00&lt;?, ?B/s]</pre> <pre>\r  0%|          | 8.91M/1.85G [00:00&lt;00:25, 72.1MB/s]</pre> <pre>\r  1%|          | 16.3M/1.85G [00:00&lt;00:26, 68.7MB/s]</pre> <pre>\r  1%|\u258f         | 23.6M/1.85G [00:00&lt;00:26, 68.4MB/s]</pre> <pre>\r  2%|\u258f         | 30.9M/1.85G [00:00&lt;00:26, 68.2MB/s]</pre> <pre>\r  2%|\u258f         | 38.3M/1.85G [00:00&lt;00:26, 68.0MB/s]</pre> <pre>\r  2%|\u258f         | 45.1M/1.85G [00:00&lt;00:31, 56.9MB/s]</pre> <pre>\r  3%|\u258e         | 51.4M/1.85G [00:00&lt;00:31, 57.6MB/s]</pre> <pre>\r  3%|\u258e         | 58.2M/1.85G [00:00&lt;00:29, 60.5MB/s]</pre> <pre>\r  4%|\u258e         | 65.0M/1.85G [00:01&lt;00:28, 62.6MB/s]</pre> <pre>\r  4%|\u258d         | 71.8M/1.85G [00:01&lt;00:32, 55.0MB/s]</pre> <pre>\r  4%|\u258d         | 78.1M/1.85G [00:01&lt;00:32, 53.9MB/s]</pre> <pre>\r  5%|\u258d         | 83.9M/1.85G [00:01&lt;00:33, 52.0MB/s]</pre> <pre>\r  5%|\u258d         | 89.7M/1.85G [00:01&lt;00:35, 49.1MB/s]</pre> <pre>\r  5%|\u258c         | 97.0M/1.85G [00:01&lt;00:32, 54.2MB/s]</pre> <pre>\r  6%|\u258c         | 103M/1.85G [00:01&lt;00:35, 49.1MB/s] </pre> <pre>\r  6%|\u258c         | 108M/1.85G [00:01&lt;00:35, 49.5MB/s]</pre> <pre>\r  6%|\u258c         | 113M/1.85G [00:02&lt;00:38, 45.4MB/s]</pre> <pre>\r  6%|\u258b         | 120M/1.85G [00:02&lt;00:34, 50.8MB/s]</pre> <pre>\r  7%|\u258b         | 126M/1.85G [00:02&lt;00:36, 46.9MB/s]</pre> <pre>\r  7%|\u258b         | 133M/1.85G [00:02&lt;00:34, 49.1MB/s]</pre> <pre>\r  8%|\u258a         | 141M/1.85G [00:02&lt;00:31, 54.2MB/s]</pre> <pre>\r  8%|\u258a         | 146M/1.85G [00:02&lt;00:32, 52.0MB/s]</pre> <pre>\r  8%|\u258a         | 153M/1.85G [00:02&lt;00:32, 52.8MB/s]</pre> <pre>\r  9%|\u258a         | 159M/1.85G [00:02&lt;00:30, 55.9MB/s]</pre> <pre>\r  9%|\u2589         | 166M/1.85G [00:03&lt;00:29, 56.9MB/s]</pre> <pre>\r  9%|\u2589         | 171M/1.85G [00:03&lt;00:33, 50.7MB/s]</pre> <pre>\r 10%|\u2589         | 178M/1.85G [00:03&lt;00:32, 51.7MB/s]</pre> <pre>\r 10%|\u2588         | 186M/1.85G [00:03&lt;00:28, 58.2MB/s]</pre> <pre>\r 10%|\u2588         | 193M/1.85G [00:03&lt;00:27, 60.3MB/s]</pre> <pre>\r 11%|\u2588         | 199M/1.85G [00:03&lt;00:30, 53.8MB/s]</pre> <pre>\r 11%|\u2588         | 206M/1.85G [00:03&lt;00:30, 54.7MB/s]</pre> <pre>\r 11%|\u2588\u258f        | 212M/1.85G [00:03&lt;00:33, 49.1MB/s]</pre> <pre>\r 12%|\u2588\u258f        | 219M/1.85G [00:04&lt;00:30, 53.3MB/s]</pre> <pre>\r 12%|\u2588\u258f        | 225M/1.85G [00:04&lt;00:28, 57.1MB/s]</pre> <pre>\r 13%|\u2588\u258e        | 232M/1.85G [00:04&lt;00:27, 59.6MB/s]</pre> <pre>\r 13%|\u2588\u258e        | 240M/1.85G [00:04&lt;00:25, 63.7MB/s]</pre> <pre>\r 13%|\u2588\u258e        | 247M/1.85G [00:04&lt;00:29, 54.1MB/s]</pre> <pre>\r 14%|\u2588\u258e        | 253M/1.85G [00:04&lt;00:29, 54.7MB/s]</pre> <pre>\r 14%|\u2588\u258d        | 258M/1.85G [00:04&lt;00:30, 52.2MB/s]</pre> <pre>\r 14%|\u2588\u258d        | 264M/1.85G [00:04&lt;00:31, 50.0MB/s]</pre> <pre>\r 15%|\u2588\u258d        | 272M/1.85G [00:04&lt;00:28, 55.1MB/s]</pre> <pre>\r 15%|\u2588\u258c        | 280M/1.85G [00:05&lt;00:25, 60.7MB/s]</pre> <pre>\r 15%|\u2588\u258c        | 287M/1.85G [00:05&lt;00:25, 62.2MB/s]</pre> <pre>\r 16%|\u2588\u258c        | 294M/1.85G [00:05&lt;00:24, 63.3MB/s]</pre> <pre>\r 16%|\u2588\u258b        | 301M/1.85G [00:05&lt;00:23, 67.1MB/s]</pre> <pre>\r 17%|\u2588\u258b        | 308M/1.85G [00:05&lt;00:26, 57.4MB/s]</pre> <pre>\r 17%|\u2588\u258b        | 315M/1.85G [00:05&lt;00:29, 52.7MB/s]</pre> <pre>\r 17%|\u2588\u258b        | 320M/1.85G [00:05&lt;00:34, 44.1MB/s]</pre> <pre>\r 18%|\u2588\u258a        | 327M/1.85G [00:05&lt;00:32, 46.9MB/s]</pre> <pre>\r 18%|\u2588\u258a        | 334M/1.85G [00:06&lt;00:27, 54.2MB/s]</pre> <pre>\r 18%|\u2588\u258a        | 341M/1.85G [00:06&lt;00:26, 56.7MB/s]</pre> <pre>\r 19%|\u2588\u2589        | 349M/1.85G [00:06&lt;00:24, 60.5MB/s]</pre> <pre>\r 19%|\u2588\u2589        | 357M/1.85G [00:06&lt;00:22, 65.3MB/s]</pre> <pre>\r 20%|\u2588\u2589        | 363M/1.85G [00:06&lt;00:24, 59.7MB/s]</pre> <pre>\r 20%|\u2588\u2588        | 371M/1.85G [00:06&lt;00:22, 64.3MB/s]</pre> <pre>\r 20%|\u2588\u2588        | 378M/1.85G [00:06&lt;00:22, 65.3MB/s]</pre> <pre>\r 21%|\u2588\u2588        | 385M/1.85G [00:06&lt;00:27, 53.5MB/s]</pre> <pre>\r 21%|\u2588\u2588        | 393M/1.85G [00:07&lt;00:24, 59.2MB/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 401M/1.85G [00:07&lt;00:22, 63.8MB/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 408M/1.85G [00:07&lt;00:26, 53.9MB/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 414M/1.85G [00:07&lt;00:28, 49.8MB/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 420M/1.85G [00:07&lt;00:27, 52.7MB/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 427M/1.85G [00:07&lt;00:25, 55.9MB/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 435M/1.85G [00:07&lt;00:23, 59.6MB/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 441M/1.85G [00:07&lt;00:22, 61.8MB/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 449M/1.85G [00:07&lt;00:21, 64.1MB/s]</pre> <pre>\r 25%|\u2588\u2588\u258d       | 456M/1.85G [00:08&lt;00:24, 56.1MB/s]</pre> <pre>\r 25%|\u2588\u2588\u258d       | 462M/1.85G [00:08&lt;00:25, 54.9MB/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 469M/1.85G [00:08&lt;00:23, 58.8MB/s]</pre> <pre>\r 26%|\u2588\u2588\u258c       | 476M/1.85G [00:08&lt;00:24, 56.9MB/s]</pre> <pre>\r 26%|\u2588\u2588\u258c       | 485M/1.85G [00:08&lt;00:20, 65.7MB/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 492M/1.85G [00:08&lt;00:20, 64.8MB/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 500M/1.85G [00:08&lt;00:19, 68.0MB/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 507M/1.85G [00:08&lt;00:19, 67.3MB/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 514M/1.85G [00:09&lt;00:19, 67.4MB/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 522M/1.85G [00:09&lt;00:19, 68.2MB/s]</pre> <pre>\r 29%|\u2588\u2588\u258a       | 530M/1.85G [00:09&lt;00:18, 69.9MB/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 537M/1.85G [00:09&lt;00:19, 68.8MB/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 544M/1.85G [00:09&lt;00:21, 61.3MB/s]</pre> <pre>\r 30%|\u2588\u2588\u2589       | 551M/1.85G [00:09&lt;00:22, 57.1MB/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 557M/1.85G [00:09&lt;00:25, 51.7MB/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 563M/1.85G [00:09&lt;00:27, 46.2MB/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 569M/1.85G [00:10&lt;00:31, 41.0MB/s]</pre> <pre>\r 31%|\u2588\u2588\u2588       | 576M/1.85G [00:10&lt;00:27, 46.5MB/s]</pre> <pre>\r 31%|\u2588\u2588\u2588\u258f      | 581M/1.85G [00:10&lt;00:29, 42.5MB/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 588M/1.85G [00:10&lt;00:27, 45.8MB/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 596M/1.85G [00:10&lt;00:23, 53.0MB/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 601M/1.85G [00:11&lt;00:39, 31.4MB/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 609M/1.85G [00:11&lt;00:32, 38.2MB/s]</pre> <pre>\r 33%|\u2588\u2588\u2588\u258e      | 616M/1.85G [00:11&lt;00:27, 44.6MB/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258e      | 622M/1.85G [00:11&lt;00:26, 46.5MB/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 628M/1.85G [00:11&lt;00:27, 44.7MB/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258d      | 634M/1.85G [00:11&lt;00:24, 49.6MB/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258d      | 642M/1.85G [00:11&lt;00:21, 56.8MB/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258c      | 649M/1.85G [00:11&lt;00:22, 54.1MB/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258c      | 655M/1.85G [00:11&lt;00:23, 50.8MB/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 662M/1.85G [00:12&lt;00:21, 55.8MB/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 670M/1.85G [00:12&lt;00:19, 59.5MB/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 677M/1.85G [00:12&lt;00:18, 62.6MB/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 684M/1.85G [00:12&lt;00:17, 64.9MB/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 691M/1.85G [00:12&lt;00:20, 56.0MB/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 697M/1.85G [00:12&lt;00:20, 55.6MB/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 705M/1.85G [00:12&lt;00:19, 59.5MB/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 712M/1.85G [00:12&lt;00:21, 51.8MB/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u2589      | 718M/1.85G [00:13&lt;00:22, 50.5MB/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u2589      | 727M/1.85G [00:13&lt;00:18, 61.2MB/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2589      | 735M/1.85G [00:13&lt;00:17, 64.1MB/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 741M/1.85G [00:13&lt;00:19, 57.5MB/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 748M/1.85G [00:13&lt;00:21, 51.1MB/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588      | 753M/1.85G [00:13&lt;00:22, 49.4MB/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588      | 759M/1.85G [00:13&lt;00:24, 45.5MB/s]</pre> <pre>\r 41%|\u2588\u2588\u2588\u2588\u258f     | 766M/1.85G [00:13&lt;00:21, 50.4MB/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 773M/1.85G [00:14&lt;00:19, 54.5MB/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 780M/1.85G [00:14&lt;00:18, 57.9MB/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 787M/1.85G [00:14&lt;00:16, 63.2MB/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 794M/1.85G [00:14&lt;00:20, 52.4MB/s]</pre> <pre>\r 43%|\u2588\u2588\u2588\u2588\u258e     | 801M/1.85G [00:14&lt;00:19, 55.2MB/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258e     | 808M/1.85G [00:14&lt;00:17, 58.9MB/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 816M/1.85G [00:14&lt;00:16, 62.2MB/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 823M/1.85G [00:14&lt;00:15, 65.0MB/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258d     | 830M/1.85G [00:14&lt;00:15, 66.8MB/s]</pre> <pre>\r 45%|\u2588\u2588\u2588\u2588\u258c     | 838M/1.85G [00:15&lt;00:17, 58.3MB/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 844M/1.85G [00:15&lt;00:17, 56.1MB/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 851M/1.85G [00:15&lt;00:16, 60.4MB/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258b     | 858M/1.85G [00:15&lt;00:18, 54.5MB/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 864M/1.85G [00:15&lt;00:18, 53.6MB/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 871M/1.85G [00:15&lt;00:18, 51.7MB/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 877M/1.85G [00:15&lt;00:20, 48.2MB/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 883M/1.85G [00:16&lt;00:19, 49.1MB/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 891M/1.85G [00:16&lt;00:17, 54.6MB/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u258a     | 898M/1.85G [00:16&lt;00:16, 59.1MB/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 905M/1.85G [00:16&lt;00:15, 61.4MB/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 912M/1.85G [00:16&lt;00:16, 56.8MB/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2589     | 918M/1.85G [00:16&lt;00:16, 57.6MB/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2589     | 925M/1.85G [00:16&lt;00:14, 61.8MB/s]</pre> <pre>\r 50%|\u2588\u2588\u2588\u2588\u2588     | 932M/1.85G [00:16&lt;00:16, 54.5MB/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588     | 939M/1.85G [00:16&lt;00:15, 58.0MB/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588\u258f    | 951M/1.85G [00:17&lt;00:12, 74.5MB/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 959M/1.85G [00:17&lt;00:12, 74.2MB/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 967M/1.85G [00:17&lt;00:14, 62.3MB/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 974M/1.85G [00:17&lt;00:13, 64.8MB/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 981M/1.85G [00:17&lt;00:13, 66.7MB/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 989M/1.85G [00:17&lt;00:12, 68.2MB/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 996M/1.85G [00:17&lt;00:14, 59.1MB/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 1.00G/1.85G [00:17&lt;00:13, 62.5MB/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 1.01G/1.85G [00:18&lt;00:12, 64.9MB/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 1.02G/1.85G [00:18&lt;00:12, 66.8MB/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 1.03G/1.85G [00:18&lt;00:11, 68.8MB/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 1.03G/1.85G [00:18&lt;00:11, 70.0MB/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 1.04G/1.85G [00:18&lt;00:13, 60.0MB/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 1.05G/1.85G [00:18&lt;00:12, 62.1MB/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 1.05G/1.85G [00:18&lt;00:12, 64.7MB/s]</pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 1.06G/1.85G [00:18&lt;00:11, 67.0MB/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 1.07G/1.85G [00:18&lt;00:11, 68.6MB/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 1.08G/1.85G [00:18&lt;00:11, 69.6MB/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u258a    | 1.08G/1.85G [00:19&lt;00:11, 69.4MB/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 1.09G/1.85G [00:19&lt;00:12, 60.7MB/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 1.10G/1.85G [00:19&lt;00:11, 63.4MB/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 1.11G/1.85G [00:19&lt;00:11, 65.3MB/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 1.11G/1.85G [00:19&lt;00:10, 67.4MB/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 1.12G/1.85G [00:19&lt;00:10, 68.7MB/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 1.13G/1.85G [00:19&lt;00:12, 59.4MB/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 1.14G/1.85G [00:19&lt;00:13, 53.3MB/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 1.14G/1.85G [00:20&lt;00:14, 49.8MB/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 1.15G/1.85G [00:20&lt;00:15, 46.7MB/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 1.15G/1.85G [00:20&lt;00:13, 51.4MB/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 1.16G/1.85G [00:20&lt;00:12, 56.6MB/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 1.17G/1.85G [00:20&lt;00:11, 60.7MB/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 1.18G/1.85G [00:20&lt;00:10, 63.9MB/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 1.18G/1.85G [00:20&lt;00:10, 66.4MB/s]</pre> <pre>\r 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 1.19G/1.85G [00:20&lt;00:09, 68.2MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 1.20G/1.85G [00:20&lt;00:09, 69.1MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 1.21G/1.85G [00:21&lt;00:09, 69.9MB/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 1.21G/1.85G [00:21&lt;00:08, 71.5MB/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 1.22G/1.85G [00:21&lt;00:09, 68.5MB/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 1.23G/1.85G [00:21&lt;00:16, 38.3MB/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 1.24G/1.85G [00:21&lt;00:13, 44.7MB/s]</pre> <pre>\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 1.24G/1.85G [00:21&lt;00:11, 52.3MB/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 1.25G/1.85G [00:22&lt;00:10, 56.4MB/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 1.26G/1.85G [00:22&lt;00:09, 59.9MB/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 1.27G/1.85G [00:22&lt;00:11, 52.9MB/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 1.27G/1.85G [00:22&lt;00:10, 54.5MB/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 1.28G/1.85G [00:22&lt;00:09, 59.4MB/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 1.29G/1.85G [00:22&lt;00:08, 63.2MB/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 1.30G/1.85G [00:22&lt;00:08, 66.0MB/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 1.30G/1.85G [00:22&lt;00:07, 68.5MB/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 1.31G/1.85G [00:22&lt;00:07, 70.0MB/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1.32G/1.85G [00:23&lt;00:08, 60.3MB/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1.33G/1.85G [00:23&lt;00:08, 63.6MB/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1.33G/1.85G [00:23&lt;00:07, 66.1MB/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 1.34G/1.85G [00:23&lt;00:07, 64.1MB/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 1.35G/1.85G [00:23&lt;00:08, 59.5MB/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 1.35G/1.85G [00:23&lt;00:08, 57.2MB/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 1.36G/1.85G [00:23&lt;00:10, 48.0MB/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 1.37G/1.85G [00:23&lt;00:08, 53.8MB/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 1.37G/1.85G [00:24&lt;00:08, 57.2MB/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 1.38G/1.85G [00:24&lt;00:07, 61.3MB/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 1.39G/1.85G [00:24&lt;00:07, 64.9MB/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 1.40G/1.85G [00:24&lt;00:06, 67.4MB/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 1.41G/1.85G [00:24&lt;00:06, 69.4MB/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 1.41G/1.85G [00:24&lt;00:07, 59.5MB/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 1.42G/1.85G [00:24&lt;00:06, 62.3MB/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 1.43G/1.85G [00:24&lt;00:06, 65.4MB/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 1.44G/1.85G [00:24&lt;00:06, 67.7MB/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 1.44G/1.85G [00:25&lt;00:05, 69.4MB/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 1.45G/1.85G [00:25&lt;00:05, 70.5MB/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 1.46G/1.85G [00:25&lt;00:05, 70.0MB/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 1.47G/1.85G [00:25&lt;00:05, 72.0MB/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 1.47G/1.85G [00:25&lt;00:05, 72.8MB/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 1.48G/1.85G [00:25&lt;00:05, 73.3MB/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 1.49G/1.85G [00:25&lt;00:04, 73.5MB/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 1.50G/1.85G [00:25&lt;00:04, 73.5MB/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 1.51G/1.85G [00:25&lt;00:05, 64.7MB/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 1.51G/1.85G [00:26&lt;00:05, 62.6MB/s]</pre> <pre>\r 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 1.52G/1.85G [00:26&lt;00:05, 56.3MB/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 1.53G/1.85G [00:26&lt;00:05, 56.1MB/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 1.54G/1.85G [00:26&lt;00:05, 62.2MB/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 1.54G/1.85G [00:26&lt;00:05, 54.0MB/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 1.55G/1.85G [00:26&lt;00:06, 48.0MB/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 1.56G/1.85G [00:26&lt;00:06, 45.8MB/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 1.56G/1.85G [00:27&lt;00:05, 50.4MB/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 1.57G/1.85G [00:27&lt;00:05, 47.9MB/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 1.57G/1.85G [00:27&lt;00:05, 52.4MB/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 1.58G/1.85G [00:27&lt;00:04, 58.1MB/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 1.59G/1.85G [00:27&lt;00:04, 62.0MB/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 1.60G/1.85G [00:27&lt;00:04, 59.6MB/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 1.60G/1.85G [00:27&lt;00:04, 54.4MB/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 1.61G/1.85G [00:27&lt;00:04, 59.6MB/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 1.62G/1.85G [00:28&lt;00:03, 63.7MB/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 1.63G/1.85G [00:28&lt;00:03, 66.8MB/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 1.63G/1.85G [00:28&lt;00:03, 69.0MB/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 1.64G/1.85G [00:28&lt;00:03, 60.7MB/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 1.65G/1.85G [00:28&lt;00:03, 63.2MB/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 1.66G/1.85G [00:28&lt;00:02, 66.4MB/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 1.67G/1.85G [00:28&lt;00:02, 68.6MB/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 1.67G/1.85G [00:28&lt;00:02, 70.4MB/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 1.68G/1.85G [00:28&lt;00:02, 71.3MB/s]</pre> <pre>\r 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 1.69G/1.85G [00:29&lt;00:02, 72.4MB/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 1.70G/1.85G [00:29&lt;00:02, 72.7MB/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 1.70G/1.85G [00:29&lt;00:02, 73.5MB/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 1.71G/1.85G [00:29&lt;00:02, 67.5MB/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 1.72G/1.85G [00:29&lt;00:02, 61.9MB/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 1.73G/1.85G [00:29&lt;00:01, 65.3MB/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 1.73G/1.85G [00:29&lt;00:01, 62.0MB/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 1.74G/1.85G [00:29&lt;00:02, 52.3MB/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 1.75G/1.85G [00:30&lt;00:01, 55.2MB/s]</pre> <pre>\r 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 1.75G/1.85G [00:30&lt;00:02, 35.9MB/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 1.77G/1.85G [00:30&lt;00:01, 67.7MB/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 1.78G/1.85G [00:30&lt;00:01, 62.3MB/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 1.79G/1.85G [00:30&lt;00:01, 56.9MB/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 1.80G/1.85G [00:31&lt;00:01, 43.8MB/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 1.81G/1.85G [00:31&lt;00:01, 42.4MB/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 1.81G/1.85G [00:31&lt;00:00, 40.1MB/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 1.82G/1.85G [00:31&lt;00:00, 57.0MB/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1.84G/1.85G [00:31&lt;00:00, 74.8MB/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 1.85G/1.85G [00:31&lt;00:00, 68.1MB/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.85G/1.85G [00:31&lt;00:00, 58.0MB/s]</pre> <pre>\n</pre> Out[4]: <pre>'/home/runner/work/HyperCoast/HyperCoast/docs/examples/EMIT_L2A_RFL_001_20240404T161230_2409511_009.nc'</pre> <p>Load the dataset as a <code>xarray.Dataset</code> object.</p> In\u00a0[5]: Copied! <pre>dataset = hypercoast.read_emit(filepath)\n</pre> dataset = hypercoast.read_emit(filepath) <p>Visualize the data interactively with HyperCoast.</p> In\u00a0[6]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"SATELLITE\")\nm.add_emit(dataset, wavelengths=[500, 600, 1000], indexes=[3, 2, 1], layer_name=\"EMIT\")\nm.add(\"spectral\")\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"SATELLITE\") m.add_emit(dataset, wavelengths=[500, 600, 1000], indexes=[3, 2, 1], layer_name=\"EMIT\") m.add(\"spectral\") m Out[6]: <p></p>"},{"location":"examples/emit/#visualizing-emit-data-interactively-with-hypercoast","title":"Visualizing EMIT data interactively with HyperCoast\u00b6","text":"<p>This notebook demonstrates how to visualize Earth Surface Mineral Dust Source Investigation (EMIT) data interactively with HyperCoast. This notebook is inspired by the EMIT data visualization tutorial - Exploring_EMIT_L2A_Reflectance.ipynb. We have made it much easier to visualize the data interactively with HyperCoast.</p>"},{"location":"examples/neon/","title":"Neon","text":"In\u00a0[1]: Copied! <pre># %pip install \"hypercoast[extra]\"\n</pre> # %pip install \"hypercoast[extra]\" In\u00a0[2]: Copied! <pre>import hypercoast\n</pre> import hypercoast In\u00a0[3]: Copied! <pre>url = \"https://github.com/opengeos/datasets/releases/download/hypercoast/NEON_D02_SERC_DP3_368000_4306000_reflectance.h5\"\nfilepath = \"data/neon.h5\"\nhypercoast.download_file(url, filepath)\n</pre> url = \"https://github.com/opengeos/datasets/releases/download/hypercoast/NEON_D02_SERC_DP3_368000_4306000_reflectance.h5\" filepath = \"data/neon.h5\" hypercoast.download_file(url, filepath) <pre>Downloading...\nFrom: https://github.com/opengeos/datasets/releases/download/hypercoast/NEON_D02_SERC_DP3_368000_4306000_reflectance.h5\nTo: /home/runner/work/HyperCoast/HyperCoast/docs/examples/data/neon.h5\n</pre> <pre>\r  0%|          | 0.00/629M [00:00&lt;?, ?B/s]</pre> <pre>\r  0%|          | 524k/629M [00:00&lt;02:40, 3.92MB/s]</pre> <pre>\r  0%|          | 1.57M/629M [00:00&lt;01:33, 6.72MB/s]</pre> <pre>\r  1%|          | 5.77M/629M [00:00&lt;00:30, 20.8MB/s]</pre> <pre>\r  2%|\u258f         | 13.1M/629M [00:00&lt;00:15, 39.4MB/s]</pre> <pre>\r  4%|\u258e         | 22.5M/629M [00:00&lt;00:10, 57.3MB/s]</pre> <pre>\r  5%|\u258c         | 33.6M/629M [00:00&lt;00:08, 74.2MB/s]</pre> <pre>\r  8%|\u258a         | 47.2M/629M [00:00&lt;00:06, 93.2MB/s]</pre> <pre>\r  9%|\u2589         | 57.1M/629M [00:00&lt;00:08, 69.7MB/s]</pre> <pre>\r 10%|\u2588         | 65.5M/629M [00:01&lt;00:09, 60.3MB/s]</pre> <pre>\r 12%|\u2588\u258f        | 72.9M/629M [00:01&lt;00:08, 62.2MB/s]</pre> <pre>\r 13%|\u2588\u258e        | 80.2M/629M [00:01&lt;00:08, 63.9MB/s]</pre> <pre>\r 14%|\u2588\u258d        | 87.6M/629M [00:01&lt;00:08, 65.2MB/s]</pre> <pre>\r 15%|\u2588\u258c        | 94.9M/629M [00:01&lt;00:08, 66.1MB/s]</pre> <pre>\r 16%|\u2588\u258b        | 102M/629M [00:01&lt;00:07, 66.9MB/s] </pre> <pre>\r 17%|\u2588\u258b        | 110M/629M [00:01&lt;00:07, 67.4MB/s]</pre> <pre>\r 19%|\u2588\u258a        | 117M/629M [00:01&lt;00:07, 67.8MB/s]</pre> <pre>\r 20%|\u2588\u2589        | 124M/629M [00:02&lt;00:07, 68.1MB/s]</pre> <pre>\r 21%|\u2588\u2588        | 132M/629M [00:02&lt;00:07, 68.0MB/s]</pre> <pre>\r 22%|\u2588\u2588\u258f       | 139M/629M [00:02&lt;00:07, 68.6MB/s]</pre> <pre>\r 23%|\u2588\u2588\u258e       | 146M/629M [00:02&lt;00:08, 58.0MB/s]</pre> <pre>\r 24%|\u2588\u2588\u258d       | 153M/629M [00:02&lt;00:08, 56.8MB/s]</pre> <pre>\r 25%|\u2588\u2588\u258c       | 160M/629M [00:02&lt;00:07, 59.9MB/s]</pre> <pre>\r 27%|\u2588\u2588\u258b       | 167M/629M [00:02&lt;00:07, 62.1MB/s]</pre> <pre>\r 28%|\u2588\u2588\u258a       | 175M/629M [00:02&lt;00:07, 64.4MB/s]</pre> <pre>\r 29%|\u2588\u2588\u2589       | 182M/629M [00:02&lt;00:06, 65.4MB/s]</pre> <pre>\r 30%|\u2588\u2588\u2588       | 189M/629M [00:03&lt;00:06, 66.5MB/s]</pre> <pre>\r 31%|\u2588\u2588\u2588\u258f      | 197M/629M [00:03&lt;00:06, 67.1MB/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 204M/629M [00:03&lt;00:06, 67.7MB/s]</pre> <pre>\r 34%|\u2588\u2588\u2588\u258e      | 211M/629M [00:03&lt;00:06, 67.9MB/s]</pre> <pre>\r 35%|\u2588\u2588\u2588\u258d      | 219M/629M [00:03&lt;00:06, 68.2MB/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 226M/629M [00:03&lt;00:05, 68.5MB/s]</pre> <pre>\r 37%|\u2588\u2588\u2588\u258b      | 233M/629M [00:03&lt;00:05, 68.5MB/s]</pre> <pre>\r 38%|\u2588\u2588\u2588\u258a      | 241M/629M [00:03&lt;00:05, 68.4MB/s]</pre> <pre>\r 39%|\u2588\u2588\u2588\u2589      | 248M/629M [00:04&lt;00:08, 45.3MB/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 254M/629M [00:04&lt;00:08, 42.7MB/s]</pre> <pre>\r 42%|\u2588\u2588\u2588\u2588\u258f     | 263M/629M [00:04&lt;00:06, 53.2MB/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258e     | 274M/629M [00:04&lt;00:05, 60.0MB/s]</pre> <pre>\r 46%|\u2588\u2588\u2588\u2588\u258c     | 287M/629M [00:04&lt;00:04, 76.4MB/s]</pre> <pre>\r 47%|\u2588\u2588\u2588\u2588\u258b     | 296M/629M [00:04&lt;00:04, 69.8MB/s]</pre> <pre>\r 48%|\u2588\u2588\u2588\u2588\u258a     | 304M/629M [00:04&lt;00:05, 64.7MB/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u2589     | 311M/629M [00:05&lt;00:04, 65.6MB/s]</pre> <pre>\r 51%|\u2588\u2588\u2588\u2588\u2588     | 318M/629M [00:05&lt;00:04, 66.5MB/s]</pre> <pre>\r 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 326M/629M [00:05&lt;00:04, 67.1MB/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 333M/629M [00:05&lt;00:04, 67.6MB/s]</pre> <pre>\r 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 340M/629M [00:05&lt;00:04, 67.7MB/s]</pre> <pre>\r 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 348M/629M [00:05&lt;00:04, 68.3MB/s]</pre> <pre>\r 56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 355M/629M [00:05&lt;00:03, 68.6MB/s]</pre> <pre>\r 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 362M/629M [00:05&lt;00:03, 68.7MB/s]</pre> <pre>\r 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 370M/629M [00:05&lt;00:03, 69.1MB/s]</pre> <pre>\r 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 377M/629M [00:05&lt;00:03, 69.5MB/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 384M/629M [00:06&lt;00:03, 69.1MB/s]</pre> <pre>\r 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 392M/629M [00:06&lt;00:03, 69.6MB/s]</pre> <pre>\r 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 399M/629M [00:06&lt;00:04, 57.4MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 406M/629M [00:06&lt;00:04, 52.4MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 412M/629M [00:06&lt;00:04, 52.7MB/s]</pre> <pre>\r 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 418M/629M [00:06&lt;00:03, 53.2MB/s]</pre> <pre>\r 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 426M/629M [00:06&lt;00:03, 59.4MB/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 433M/629M [00:06&lt;00:03, 61.2MB/s]</pre> <pre>\r 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 439M/629M [00:07&lt;00:03, 62.7MB/s]</pre> <pre>\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 447M/629M [00:07&lt;00:02, 65.6MB/s]</pre> <pre>\r 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 454M/629M [00:07&lt;00:03, 55.5MB/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 460M/629M [00:07&lt;00:03, 55.4MB/s]</pre> <pre>\r 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 466M/629M [00:07&lt;00:03, 50.2MB/s]</pre> <pre>\r 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 472M/629M [00:07&lt;00:03, 50.9MB/s]</pre> <pre>\r 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 478M/629M [00:07&lt;00:03, 50.2MB/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 483M/629M [00:07&lt;00:03, 48.0MB/s]</pre> <pre>\r 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 490M/629M [00:08&lt;00:02, 53.9MB/s]</pre> <pre>\r 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 497M/629M [00:08&lt;00:02, 57.6MB/s]</pre> <pre>\r 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 504M/629M [00:08&lt;00:02, 61.4MB/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 512M/629M [00:08&lt;00:01, 63.6MB/s]</pre> <pre>\r 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 519M/629M [00:08&lt;00:01, 65.3MB/s]</pre> <pre>\r 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 526M/629M [00:08&lt;00:01, 66.8MB/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 533M/629M [00:08&lt;00:01, 56.4MB/s]</pre> <pre>\r 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 539M/629M [00:08&lt;00:01, 56.2MB/s]</pre> <pre>\r 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 547M/629M [00:08&lt;00:01, 59.8MB/s]</pre> <pre>\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 554M/629M [00:09&lt;00:01, 62.6MB/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 562M/629M [00:09&lt;00:01, 64.6MB/s]</pre> <pre>\r 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 569M/629M [00:09&lt;00:00, 66.1MB/s]</pre> <pre>\r 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 576M/629M [00:09&lt;00:00, 67.2MB/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 584M/629M [00:09&lt;00:00, 68.0MB/s]</pre> <pre>\r 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 591M/629M [00:09&lt;00:00, 50.0MB/s]</pre> <pre>\r 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 602M/629M [00:09&lt;00:00, 63.5MB/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 609M/629M [00:09&lt;00:00, 64.3MB/s]</pre> <pre>\r 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 617M/629M [00:10&lt;00:00, 66.5MB/s]</pre> <pre>\r 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 624M/629M [00:10&lt;00:00, 66.7MB/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 629M/629M [00:10&lt;00:00, 61.6MB/s]</pre> <pre>\n</pre> Out[3]: <pre>'/home/runner/work/HyperCoast/HyperCoast/docs/examples/data/neon.h5'</pre> <p>Load the dataset as a <code>xarray.Dataset</code> object.</p> In\u00a0[4]: Copied! <pre>dataset = hypercoast.read_neon(filepath)\ndataset\n</pre> dataset = hypercoast.read_neon(filepath) dataset Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 3GB\nDimensions:      (y: 1000, x: 1000, wavelength: 426)\nCoordinates:\n  * y            (y) float64 8kB 4.307e+06 4.307e+06 ... 4.306e+06 4.306e+06\n  * x            (x) float64 8kB 3.68e+05 3.68e+05 ... 3.69e+05 3.69e+05\n  * wavelength   (wavelength) float64 3kB 383.9 388.9 ... 2.507e+03 2.512e+03\nData variables:\n    reflectance  (y, x, wavelength) float64 3GB 0.1569 0.1206 0.1034 ... nan nan\nAttributes:\n    scale_factor:   10000.0\n    no_data_value:  -9999.0\n    crs:            EPSG:32618\n    transform:      (1.0, 0.0, 368000.0, 0.0, -1.0, 4307000.0)</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>y: 1000</li><li>x: 1000</li><li>wavelength: 426</li></ul></li><li>Coordinates: (3)<ul><li>y(y)float644.307e+06 4.307e+06 ... 4.306e+06<pre>array([4307000.      , 4306998.998999, 4306997.997998, ..., 4306002.002002,\n       4306001.001001, 4306000.      ])</pre></li><li>x(x)float643.68e+05 3.68e+05 ... 3.69e+05<pre>array([368000.      , 368001.001001, 368002.002002, ..., 368997.997998,\n       368998.998999, 369000.      ])</pre></li><li>wavelength(wavelength)float64383.9 388.9 ... 2.507e+03 2.512e+03<pre>array([ 383.88,  388.89,  393.9 , ..., 2502.17, 2507.17, 2512.18])</pre></li></ul></li><li>Data variables: (1)<ul><li>reflectance(y, x, wavelength)float640.1569 0.1206 0.1034 ... nan nanscale_factor :10000.0no_data_value :-9999.0crs :EPSG:32618transform :(1.0, 0.0, 368000.0, 0.0, -1.0, 4307000.0)<pre>array([[[0.1569, 0.1206, 0.1034, ..., 0.1512,    nan,    nan],\n        [0.1593, 0.118 , 0.105 , ...,    nan,    nan,    nan],\n        [0.1415, 0.1147, 0.1061, ..., 0.    , 0.    ,    nan],\n        ...,\n        [0.056 , 0.0319, 0.0292, ...,    nan,    nan,    nan],\n        [0.0604, 0.0412, 0.0257, ...,    nan,    nan,    nan],\n        [0.0723, 0.0444, 0.0366, ..., 0.7853,    nan,    nan]],\n\n       [[0.13  , 0.0988, 0.0842, ...,    nan,    nan,    nan],\n        [0.1515, 0.0961, 0.0826, ...,    nan,    nan,    nan],\n        [0.1431, 0.1253, 0.1069, ...,    nan,    nan,    nan],\n        ...,\n        [0.0586, 0.0411, 0.0224, ...,    nan,    nan,    nan],\n        [0.0467, 0.0424, 0.0289, ..., 0.4019,    nan,    nan],\n        [0.074 , 0.0453, 0.0301, ..., 0.7002,    nan,    nan]],\n\n       [[0.1026, 0.0716, 0.0623, ...,    nan,    nan,    nan],\n        [0.127 , 0.1103, 0.0986, ..., 0.7747,    nan,    nan],\n        [0.168 , 0.1335, 0.1359, ...,    nan,    nan,    nan],\n        ...,\n...\n        ...,\n        [0.0578, 0.0493, 0.0418, ...,    nan,    nan,    nan],\n        [0.1047, 0.0788, 0.057 , ...,    nan,    nan,    nan],\n        [0.0958, 0.0785, 0.0693, ...,    nan,    nan,    nan]],\n\n       [[0.0747, 0.0397, 0.0314, ...,    nan,    nan,    nan],\n        [0.065 , 0.041 , 0.0322, ..., 0.9747,    nan,    nan],\n        [0.0667, 0.0424, 0.0274, ...,    nan,    nan,    nan],\n        ...,\n        [0.1335, 0.1008, 0.0878, ..., 0.    ,    nan,    nan],\n        [0.1369, 0.0864, 0.0771, ...,    nan,    nan,    nan],\n        [0.1144, 0.0958, 0.0857, ...,    nan,    nan,    nan]],\n\n       [[0.0738, 0.0392, 0.031 , ...,    nan,    nan,    nan],\n        [0.0541, 0.0421, 0.0272, ...,    nan,    nan,    nan],\n        [0.0513, 0.0406, 0.0276, ...,    nan,    nan,    nan],\n        ...,\n        [0.082 , 0.0593, 0.0511, ...,    nan,    nan,    nan],\n        [0.0883, 0.0693, 0.0518, ...,    nan,    nan,    nan],\n        [0.1128, 0.1   , 0.0844, ..., 0.5833,    nan,    nan]]])</pre></li></ul></li><li>Indexes: (3)<ul><li>yPandasIndex<pre>PandasIndex(Index([        4307000.0, 4306998.998998999, 4306997.997997998,\n       4306996.996996997, 4306995.995995996, 4306994.994994995,\n       4306993.993993994, 4306992.992992993, 4306991.991991992,\n       4306990.990990991,\n       ...\n       4306009.009009009, 4306008.008008008, 4306007.007007007,\n       4306006.006006006, 4306005.005005005, 4306004.004004004,\n       4306003.003003003, 4306002.002002002, 4306001.001001001,\n               4306000.0],\n      dtype='float64', name='y', length=1000))</pre></li><li>xPandasIndex<pre>PandasIndex(Index([          368000.0,   368001.001001001, 368002.00200200203,\n         368003.003003003,   368004.004004004,   368005.005005005,\n       368006.00600600604,   368007.007007007,   368008.008008008,\n         368009.009009009,\n       ...\n         368990.990990991,   368991.991991992,   368992.992992993,\n       368993.99399399396,   368994.994994995,   368995.995995996,\n         368996.996996997,   368997.997997998,   368998.998998999,\n                 369000.0],\n      dtype='float64', name='x', length=1000))</pre></li><li>wavelengthPandasIndex<pre>PandasIndex(Index([ 383.88,  388.89,   393.9,  398.91,  403.92,  408.92,  413.93,  418.94,\n        423.95,  428.95,\n       ...\n       2467.11, 2472.12, 2477.13, 2482.13, 2487.14, 2492.15, 2497.16, 2502.17,\n       2507.17, 2512.18],\n      dtype='float64', name='wavelength', length=426))</pre></li></ul></li><li>Attributes: (4)scale_factor :10000.0no_data_value :-9999.0crs :EPSG:32618transform :(1.0, 0.0, 368000.0, 0.0, -1.0, 4307000.0)</li></ul> <p>Visualize the data interactively with HyperCoast.</p> In\u00a0[5]: Copied! <pre>m = hypercoast.Map()\nm.add_neon(filepath, wavelengths=[1000, 700, 500], vmin=0, vmax=0.5)\nm\n</pre> m = hypercoast.Map() m.add_neon(filepath, wavelengths=[1000, 700, 500], vmin=0, vmax=0.5) m Out[5]: In\u00a0[6]: Copied! <pre>m.set_center(-76.5134, 38.8973, 16)\n</pre> m.set_center(-76.5134, 38.8973, 16) In\u00a0[7]: Copied! <pre>m.add(\"spectral\")\n</pre> m.add(\"spectral\") <p></p>"},{"location":"examples/neon/#visualizing-neon-aop-hyperspectral-data-interactively-with-hypercoast","title":"Visualizing NEON AOP hyperspectral data interactively with HyperCoast\u00b6","text":"<p>This notebook demonstrates how to visualize NEON AOP hyperspectral data interactively with HyperCoast.</p>"},{"location":"examples/pace/","title":"Pace","text":"In\u00a0[1]: Copied! <pre># %pip install \"hypercoast[extra]\"\n</pre> # %pip install \"hypercoast[extra]\" In\u00a0[2]: Copied! <pre>import hypercoast\n</pre> import hypercoast <p>Download a sample PACE data file from here.</p> In\u00a0[3]: Copied! <pre>url = \"https://github.com/opengeos/datasets/releases/download/netcdf/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\"\n</pre> url = \"https://github.com/opengeos/datasets/releases/download/netcdf/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\" In\u00a0[4]: Copied! <pre>filepath = \"PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\"\nhypercoast.download_file(url)\n</pre> filepath = \"PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\" hypercoast.download_file(url) <pre>Downloading...\nFrom: https://github.com/opengeos/datasets/releases/download/netcdf/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\nTo: /home/runner/work/HyperCoast/HyperCoast/docs/examples/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc\n</pre> <pre>\r  0%|          | 0.00/192M [00:00&lt;?, ?B/s]</pre> <pre>\r  1%|          | 1.05M/192M [00:00&lt;01:09, 2.75MB/s]</pre> <pre>\r  1%|\u258f         | 2.62M/192M [00:00&lt;00:31, 6.05MB/s]</pre> <pre>\r  2%|\u258f         | 4.72M/192M [00:00&lt;00:19, 9.54MB/s]</pre> <pre>\r  4%|\u258d         | 7.34M/192M [00:00&lt;00:13, 13.6MB/s]</pre> <pre>\r  5%|\u258c         | 10.5M/192M [00:00&lt;00:10, 18.0MB/s]</pre> <pre>\r  7%|\u258b         | 14.2M/192M [00:00&lt;00:07, 22.8MB/s]</pre> <pre>\r 10%|\u2588         | 19.4M/192M [00:01&lt;00:05, 30.5MB/s]</pre> <pre>\r 13%|\u2588\u258e        | 25.7M/192M [00:01&lt;00:04, 39.1MB/s]</pre> <pre>\r 17%|\u2588\u258b        | 33.0M/192M [00:01&lt;00:03, 48.6MB/s]</pre> <pre>\r 21%|\u2588\u2588        | 40.4M/192M [00:01&lt;00:02, 55.7MB/s]</pre> <pre>\r 25%|\u2588\u2588\u258d       | 47.7M/192M [00:01&lt;00:02, 60.6MB/s]</pre> <pre>\r 29%|\u2588\u2588\u258a       | 55.1M/192M [00:01&lt;00:02, 64.1MB/s]</pre> <pre>\r 32%|\u2588\u2588\u2588\u258f      | 62.4M/192M [00:01&lt;00:01, 66.7MB/s]</pre> <pre>\r 36%|\u2588\u2588\u2588\u258c      | 69.7M/192M [00:01&lt;00:01, 68.5MB/s]</pre> <pre>\r 40%|\u2588\u2588\u2588\u2588      | 77.6M/192M [00:01&lt;00:01, 70.3MB/s]</pre> <pre>\r 44%|\u2588\u2588\u2588\u2588\u258d     | 84.9M/192M [00:01&lt;00:01, 69.1MB/s]</pre> <pre>\r 49%|\u2588\u2588\u2588\u2588\u258a     | 93.3M/192M [00:02&lt;00:01, 72.9MB/s]</pre> <pre>\r 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 101M/192M [00:02&lt;00:01, 73.4MB/s] </pre> <pre>\r 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 109M/192M [00:02&lt;00:01, 73.5MB/s]</pre> <pre>\r 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 117M/192M [00:02&lt;00:01, 73.2MB/s]</pre> <pre>\r 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 124M/192M [00:02&lt;00:00, 72.9MB/s]</pre> <pre>\r 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 132M/192M [00:02&lt;00:00, 74.1MB/s]</pre> <pre>\r 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 140M/192M [00:02&lt;00:00, 74.2MB/s]</pre> <pre>\r 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 148M/192M [00:02&lt;00:00, 74.0MB/s]</pre> <pre>\r 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 156M/192M [00:02&lt;00:00, 73.9MB/s]</pre> <pre>\r 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 164M/192M [00:03&lt;00:00, 74.1MB/s]</pre> <pre>\r 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 171M/192M [00:03&lt;00:00, 73.8MB/s]</pre> <pre>\r 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 179M/192M [00:03&lt;00:00, 73.9MB/s]</pre> <pre>\r 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 187M/192M [00:03&lt;00:00, 59.3MB/s]</pre> <pre>\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 192M/192M [00:03&lt;00:00, 55.4MB/s]</pre> <pre>\n</pre> Out[4]: <pre>'/home/runner/work/HyperCoast/HyperCoast/docs/examples/PACE_OCI.20240423T184658.L2.OC_AOP.V1_0_0.NRT.nc'</pre> <p>Load the dataset as a <code>xarray.Dataset</code> object.</p> In\u00a0[5]: Copied! <pre>dataset = hypercoast.read_pace(filepath)\n</pre> dataset = hypercoast.read_pace(filepath) In\u00a0[6]: Copied! <pre>hypercoast.viz_pace(dataset, wavelengths=[500, 510, 520, 530], ncols=2)\n</pre> hypercoast.viz_pace(dataset, wavelengths=[500, 510, 520, 530], ncols=2) <p>Add projection.</p> In\u00a0[7]: Copied! <pre>hypercoast.viz_pace(dataset, wavelengths=[500, 510, 520, 530], ncols=2, crs=\"default\")\n</pre> hypercoast.viz_pace(dataset, wavelengths=[500, 510, 520, 530], ncols=2, crs=\"default\") <p>Plot a spectral signature.</p> In\u00a0[8]: Copied! <pre>latitude = 25.493961\nlongitude = -91.25617\nhypercoast.filter_pace(dataset, latitude, longitude, return_plot=True)\n</pre> latitude = 25.493961 longitude = -91.25617 hypercoast.filter_pace(dataset, latitude, longitude, return_plot=True) <p>Plot multiple spectral signatures.</p> In\u00a0[9]: Copied! <pre>latitude = (25.49, 25.50)\nlongitude = (-92, -91.055)\nhypercoast.filter_pace(dataset, latitude, longitude, return_plot=True)\n</pre> latitude = (25.49, 25.50) longitude = (-92, -91.055) hypercoast.filter_pace(dataset, latitude, longitude, return_plot=True) <p>Single-band visualization.</p> In\u00a0[10]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"Hybrid\")\nwavelengths = [450]\nm.add_pace(dataset, wavelengths, colormap=\"jet\", vmin=0, vmax=0.02, layer_name=\"PACE\")\nm.add_colormap(cmap=\"jet\", vmin=0, vmax=0.02, label=\"Reflectance\")\nm.add(\"spectral\")\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"Hybrid\") wavelengths = [450] m.add_pace(dataset, wavelengths, colormap=\"jet\", vmin=0, vmax=0.02, layer_name=\"PACE\") m.add_colormap(cmap=\"jet\", vmin=0, vmax=0.02, label=\"Reflectance\") m.add(\"spectral\") m Out[10]: <p></p> <p>Multiple-band visualization.</p> In\u00a0[11]: Copied! <pre>m = hypercoast.Map()\nm.add_basemap(\"Hybrid\")\nwavelengths = [450, 550, 650]\nm.add_pace(\n    dataset, wavelengths, indexes=[3, 2, 1], vmin=0, vmax=0.02, layer_name=\"PACE\"\n)\nm.add(\"spectral\")\nm\n</pre> m = hypercoast.Map() m.add_basemap(\"Hybrid\") wavelengths = [450, 550, 650] m.add_pace(     dataset, wavelengths, indexes=[3, 2, 1], vmin=0, vmax=0.02, layer_name=\"PACE\" ) m.add(\"spectral\") m Out[11]: <p></p>"},{"location":"examples/pace/#visualizing-pace-data-interactively-with-hypercoast","title":"Visualizing PACE data interactively with HyperCoast\u00b6","text":"<p>This notebook demonstrates how to visualize Plankton, Aerosol, Cloud, ocean Ecosystem (PACE) data interactively with HyperCoast.</p>"},{"location":"examples/search_data/","title":"Search data","text":"In\u00a0[\u00a0]: Copied! <pre># %pip install \"hypercoast[extra]\"\n</pre> # %pip install \"hypercoast[extra]\" In\u00a0[\u00a0]: Copied! <pre>import hypercoast\n</pre> import hypercoast In\u00a0[\u00a0]: Copied! <pre>hypercoast.nasa_earth_login()\n</pre> hypercoast.nasa_earth_login() In\u00a0[\u00a0]: Copied! <pre>results, gdf = hypercoast.search_pace(\n    bounding_box=(-83, 25, -81, 28),\n    temporal=(\"2024-05-10\", \"2024-05-16\"),\n    count=10,  # use -1 to return all datasets\n    return_gdf=True,\n)\n</pre> results, gdf = hypercoast.search_pace(     bounding_box=(-83, 25, -81, 28),     temporal=(\"2024-05-10\", \"2024-05-16\"),     count=10,  # use -1 to return all datasets     return_gdf=True, ) In\u00a0[\u00a0]: Copied! <pre>gdf.explore()\n</pre> gdf.explore() In\u00a0[\u00a0]: Copied! <pre>hypercoast.download_pace(results[:2], out_dir=\"data\")\n</pre> hypercoast.download_pace(results[:2], out_dir=\"data\") In\u00a0[\u00a0]: Copied! <pre>results, gdf = hypercoast.search_emit(\n    bounding_box=(-83, 25, -81, 28),\n    temporal=(\"2024-04-01\", \"2024-05-16\"),\n    count=10,  # use -1 to return all datasets\n    return_gdf=True,\n)\n</pre> results, gdf = hypercoast.search_emit(     bounding_box=(-83, 25, -81, 28),     temporal=(\"2024-04-01\", \"2024-05-16\"),     count=10,  # use -1 to return all datasets     return_gdf=True, ) In\u00a0[\u00a0]: Copied! <pre>gdf.explore()\n</pre> gdf.explore() In\u00a0[\u00a0]: Copied! <pre>hypercoast.download_emit(results[:2], out_dir=\"data\")\n</pre> hypercoast.download_emit(results[:2], out_dir=\"data\") In\u00a0[\u00a0]: Copied! <pre>results, gdf = hypercoast.search_ecostress(\n    bbox=(-120.522, 34.4266, -120.2665, 34.5653),\n    temporal=(\"2023-04-01\", \"2023-04-02\"),\n    count=-1,  # use -1 to return all datasets\n    return_gdf=True,\n)\n</pre> results, gdf = hypercoast.search_ecostress(     bbox=(-120.522, 34.4266, -120.2665, 34.5653),     temporal=(\"2023-04-01\", \"2023-04-02\"),     count=-1,  # use -1 to return all datasets     return_gdf=True, ) In\u00a0[\u00a0]: Copied! <pre>gdf.explore()\n</pre> gdf.explore() In\u00a0[\u00a0]: Copied! <pre>hypercoast.download_ecostress(results[:5], out_dir=\"data\")\n</pre> hypercoast.download_ecostress(results[:5], out_dir=\"data\") In\u00a0[\u00a0]: Copied! <pre>m = hypercoast.Map(center=[27.25, -83.05], zoom=6)\nm.search_pace()\nm\n</pre> m = hypercoast.Map(center=[27.25, -83.05], zoom=6) m.search_pace() m In\u00a0[\u00a0]: Copied! <pre># m._NASA_DATA_GDF.head()\n</pre> # m._NASA_DATA_GDF.head() In\u00a0[\u00a0]: Copied! <pre># hypercoast.download_pace(m._NASA_DATA_RESULTS[:2], out_dir=\"data\")\n</pre> # hypercoast.download_pace(m._NASA_DATA_RESULTS[:2], out_dir=\"data\") <p>Search for EMIT data interactively.</p> In\u00a0[\u00a0]: Copied! <pre>m = hypercoast.Map(center=[27.25, -83.05], zoom=6)\nm.search_emit()\nm\n</pre> m = hypercoast.Map(center=[27.25, -83.05], zoom=6) m.search_emit() m In\u00a0[\u00a0]: Copied! <pre># m._NASA_DATA_GDF.head()\n</pre> # m._NASA_DATA_GDF.head() In\u00a0[\u00a0]: Copied! <pre># hypercoast.download_emit(m._NASA_DATA_RESULTS[:2], out_dir=\"data\")\n</pre> # hypercoast.download_emit(m._NASA_DATA_RESULTS[:2], out_dir=\"data\") <p>Search for ECOSTRESS data interactively.</p> In\u00a0[\u00a0]: Copied! <pre>m = hypercoast.Map(center=[34.5014, -120.4032], zoom=11)\nm.search_ecostress()\nm\n</pre> m = hypercoast.Map(center=[34.5014, -120.4032], zoom=11) m.search_ecostress() m In\u00a0[\u00a0]: Copied! <pre># m._NASA_DATA_GDF.head()\n</pre> # m._NASA_DATA_GDF.head() In\u00a0[\u00a0]: Copied! <pre># hypercoast.download_ecostress(m._NASA_DATA_RESULTS[:2], out_dir=\"data\")\n</pre> # hypercoast.download_ecostress(m._NASA_DATA_RESULTS[:2], out_dir=\"data\")"},{"location":"examples/search_data/#search-and-download-nasa-hyperspectral-data-with-hypercoast","title":"Search and download NASA hyperspectral data with HyperCoast\u00b6","text":"<p>This notebook demonstrates how to search and download NASA hyperspectral data (e.g., EMIT, PACE) and ECOSTRESS temperature data with HyperCoast.</p>"},{"location":"examples/search_data/#import-library","title":"Import library\u00b6","text":""},{"location":"examples/search_data/#search-for-pace-data","title":"Search for PACE data\u00b6","text":""},{"location":"examples/search_data/#download-pace-data","title":"Download PACE data\u00b6","text":"<p>Download the first 2 files</p>"},{"location":"examples/search_data/#search-for-emit-data","title":"Search for EMIT data\u00b6","text":""},{"location":"examples/search_data/#download-emit-data","title":"Download EMIT data\u00b6","text":"<p>Download the first 2 files</p>"},{"location":"examples/search_data/#download-ecostress-data","title":"Download ECOSTRESS data\u00b6","text":""},{"location":"examples/search_data/#interactive-search","title":"Interactive search\u00b6","text":"<p>Search for PACE data interactively.</p>"}]}